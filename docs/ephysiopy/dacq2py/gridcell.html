<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>ephysiopy.dacq2py.gridcell API documentation</title>
<meta name="description" content="Created on Tue Nov 20 14:33:39 2012 â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ephysiopy.dacq2py.gridcell</code></h1>
</header>
<section id="section-intro">
<p>Created on Tue Nov 20 14:33:39 2012</p>
<p>@author: robin</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Created on Tue Nov 20 14:33:39 2012

@author: robin
&#34;&#34;&#34;
import numpy as np
import scipy, scipy.io, scipy.signal
import skimage, skimage.morphology, skimage.measure, skimage.feature, skimage.segmentation
import matplotlib.pyplot as plt
import warnings
import matplotlib.cm as cm
from .utils import polar, rect
import mahotas
import collections

warnings.filterwarnings(&#34;ignore&#34;, message=&#34;invalid value encountered in sqrt&#34;)
warnings.filterwarnings(&#34;ignore&#34;, message=&#34;invalid value encountered in subtract&#34;)
warnings.filterwarnings(&#34;ignore&#34;, message=&#34;invalid value encountered in greater&#34;)
warnings.filterwarnings(&#34;ignore&#34;, message=&#34;invalid value encountered in true_divide&#34;)

class SAC(object):
        def __init__(self):
                pass
        def autoCorr2D(self, A, nodwell, tol=1e-10):
                &#39;&#39;&#39;
                Performs a spatial autocorrelation on A
                Inputs:
                        A - an n-dimensional array of ratemaps
                                A can be either 2 or 3 dimensional. In the former case it is 
                                simply the binned up ratemap where the two dimensions correspond
                                to x and y. In the latter case the first two dimensions are x
                                and y and the third is &#39;stack&#39; of ratemaps
                        nodwell - a boolean array corresponding the bins in the ratemap that
                                weren&#39;t visited. Usually this is generated as:
                                        nodwell = ~np.isfinite(A) NB use this form even if A is 3D
                        tol - values below this are set to zero to deal with v small values
                                thrown up by the fft
                &#39;&#39;&#39;

                if np.ndim(A) == 2:
                        m,n = np.shape(A)
                        o = 1
                        x = np.reshape(A, (m,n,o))
                        nodwell = np.reshape(nodwell, (m,n,o))
                elif np.ndim(A) == 3:
                        m,n,o = np.shape(A)
                        x = A.copy()
                
                x[nodwell] = 0
                # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
                Fx = np.fft.fft(np.fft.fft(x,2*m-1,axis=0),2*n-1,axis=1)
                FsumOfSquares_x = np.fft.fft(np.fft.fft(np.power(x,2),2*m-1,axis=0),2*n-1,axis=1)
                Fn = np.fft.fft(np.fft.fft(np.invert(nodwell).astype(int),2*m-1,axis=0),2*n-1,axis=1)
                # [Step 2] Multiply the relevant transforms and invert to obtain the
                # equivalent convolutions
                rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fx * np.conj(Fx),axis=1),axis=0)),axes=(0,1))
                sums_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(np.conj(Fx) * Fn,axis=1),axis=0)),axes=(0,1))
                sumOfSquares_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(FsumOfSquares_x),axis=1),axis=0)),axes=(0,1))
                N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(Fn),axis=1),axis=0)),axes=(0,1))
                # [Step 3] Account for rounding errors.
                rawCorr[np.abs(rawCorr) &lt; tol] = 0
                sums_x[np.abs(sums_x) &lt; tol] = 0
                sumOfSquares_x[np.abs(sumOfSquares_x) &lt; tol] = 0
                N = np.round(N)
                N[N&lt;=1] = np.nan
                # [Step 4] Compute correlation matrix
                mapStd = np.sqrt((sumOfSquares_x * N) - sums_x**2)
                mapCovar = (rawCorr * N) - sums_x * sums_x[::-1,:,:][:,::-1,:][:,:,:]

                return np.squeeze(mapCovar / mapStd / mapStd[::-1,:,:][:,::-1,:][:,:,:])

        def crossCorr2D(self, A, B, A_nodwell, B_nodwell, tol=1e-10):
                if np.ndim(A) != np.ndim(B):
                        raise ValueError(&#39;Both arrays must have the same dimensionality&#39;)
                if np.ndim(A) == 2:
                        ma, na = np.shape(A)
                        mb, nb = np.shape(B)
                        oa = ob = 1
                elif np.ndim(A) == 3:
                        [ma,na,oa] = np.shape(A)
                        [mb,nb,ob] = np.shape(B)
                A = np.reshape(A, (ma, na, oa))
                B = np.reshape(B, (mb, nb, ob))
#               import pdb
#               pdb.set_trace()
                A_nodwell = np.reshape(A_nodwell, (ma, na, oa))
                B_nodwell = np.reshape(B_nodwell, (mb, nb, ob))
                A[A_nodwell] = 0
                B[B_nodwell] = 0
                # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
                Fa = np.fft.fft(np.fft.fft(A,2*mb-1,axis=0),2*nb-1,axis=1)
                FsumOfSquares_a = np.fft.fft(np.fft.fft(np.power(A,2),2*mb-1,axis=0),2*nb-1,axis=1)
                Fn_a = np.fft.fft(np.fft.fft(np.invert(A_nodwell).astype(int),2*mb-1,axis=0),2*nb-1,axis=1)

                Fb = np.fft.fft(np.fft.fft(B,2*ma-1,axis=0),2*na-1,axis=1)
                FsumOfSquares_b = np.fft.fft(np.fft.fft(np.power(B,2),2*ma-1,axis=0),2*na-1,axis=1)
                Fn_b = np.fft.fft(np.fft.fft(np.invert(B_nodwell).astype(int),2*ma-1,axis=0),2*na-1,axis=1)
                # [Step 2] Multiply the relevant transforms and invert to obtain the
                # equivalent convolutions
                rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fb),axis=1),axis=0)))
                sums_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fn_b),axis=1),axis=0)))
                sums_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fb),axis=1),axis=0)))
                sumOfSquares_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(FsumOfSquares_a * np.conj(Fn_b),axis=1),axis=0)))
                sumOfSquares_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(FsumOfSquares_b),axis=1),axis=0)))
                N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fn_b),axis=1),axis=0)))
                # [Step 3] Account for rounding errors.
                rawCorr[np.abs(rawCorr) &lt; tol] = 0
                sums_a[np.abs(sums_a) &lt; tol] = 0
                sums_b[np.abs(sums_b) &lt; tol] = 0
                sumOfSquares_a[np.abs(sumOfSquares_a) &lt; tol] = 0
                sumOfSquares_b[np.abs(sumOfSquares_b) &lt; tol] = 0
                N = np.round(N)
                N[N&lt;=1] = np.nan
                # [Step 4] Compute correlation matrix
                mapStd_a = np.sqrt((sumOfSquares_a * N) - sums_a**2)
                mapStd_b = np.sqrt((sumOfSquares_b * N) - sums_b**2)
                mapCovar = (rawCorr * N) - sums_a * sums_b

                return np.squeeze(mapCovar / (mapStd_a * mapStd_b))

        def t_win_SAC(self, xy, spkIdx, ppm = 365, winSize=10, pos_sample_rate=50, nbins=71, boxcar=5, Pthresh=100, downsampfreq=50, plot=False):
                &#39;&#39;&#39;
                [Stage 0] Get some numbers
                &#39;&#39;&#39;
                xy = xy / ppm * 100
                n_samps = xy.shape[1]
                n_spks = len(spkIdx)
                winSizeBins = np.min([winSize * pos_sample_rate, n_samps])
                downsample = np.ceil(pos_sample_rate / downsampfreq) # factor by which positions are downsampled.
                Pthresh = Pthresh / downsample # take account of downsampling

                &#39;&#39;&#39;
                [Stage 1] Calculate number of spikes in the window for each spikeInd (ignoring spike itself)
                &#39;&#39;&#39;
                #1a. Loop preparation
                nSpikesInWin = np.zeros(n_spks, dtype=np.int)

                #1b. Keep looping until we have dealt with all spikes
                for i, s in enumerate(spkIdx):
                        t = np.searchsorted(spkIdx, (s, s + winSizeBins))
                        nSpikesInWin[i] = len(spkIdx[t[0]:t[1]]) - 1 # i.e. ignore ith spike

                &#39;&#39;&#39;
                [Stage 2] Prepare for main loop
                &#39;&#39;&#39;
                #2a. Work out offset inidices to be used when storing spike data
                off_spike = np.cumsum([nSpikesInWin])
                off_spike = np.pad(off_spike,(1,0),&#39;constant&#39;,constant_values=(0))

                #2b. Work out number of downsampled pos bins in window and offset indicies for storing data
                nPosInWindow = np.minimum(winSizeBins, n_samps - spkIdx)
                nDownsampInWin = np.floor((nPosInWindow-1)/downsample)+1

                off_dwell = np.cumsum(nDownsampInWin.astype(int))
                off_dwell = np.pad(off_dwell,(1,0),&#39;constant&#39;,constant_values=(0))
                

                #2c. Pre-allocate dwell and spike arrays, singles for speed
                dwell = np.zeros((2, off_dwell[-1]),dtype=np.single) * np.nan
                spike = np.zeros((2, off_spike[-1]), dtype=np.single) * np.nan

                filled_pvals = 0
                filled_svals = 0

                for i in range(n_spks):
                        # calculate dwell displacements
                        winInd_dwell = np.arange(spkIdx[i] + 1, np.minimum(spkIdx[i]+winSizeBins, n_samps), downsample, dtype=np.int)
                        WL = len(winInd_dwell)
                        dwell[:, filled_pvals:filled_pvals + WL] = np.rot90(np.array(np.rot90(xy[:, winInd_dwell]) - xy[:,spkIdx[i]]))
                        filled_pvals = filled_pvals + WL
                        # calculate spike displacements
                        winInd_spks = i + (spkIdx[i+1:n_spks] &lt; spkIdx[i]+winSizeBins).nonzero()[0]
                        WL = len(winInd_spks)
                        spike[:, filled_svals:filled_svals+WL] = np.rot90(np.array(np.rot90(xy[:, spkIdx[winInd_spks]]) - xy[:,spkIdx[i]]))
                        filled_svals = filled_svals + WL

                dwell = np.delete(dwell, np.isnan(dwell).nonzero()[1], axis=1)
                spike = np.delete(spike, np.isnan(spike).nonzero()[1], axis=1)

                dwell = np.hstack((dwell, -dwell))
                spike = np.hstack((spike, -spike))

                dwell_min = np.min(dwell, axis=1)
                dwell_max = np.max(dwell, axis=1)

                binsize = (dwell_max[1] - dwell_min[1]) / nbins

                dwell = np.round((dwell - np.ones_like(dwell) * dwell_min[:,np.newaxis]) / binsize)
                spike = np.round((spike - np.ones_like(spike) * dwell_min[:,np.newaxis]) / binsize)

                binsize = np.max(dwell, axis=1)
                binedges = np.array(((-0.5,-0.5),binsize+0.5)).T
                Hp = np.histogram2d(dwell[0,:], dwell[1,:], range=binedges, bins=binsize)[0]
                Hs = np.histogram2d(spike[0,:], spike[1,:], range=binedges, bins=binsize)[0]

#        # reverse y,x order
                Hp = np.swapaxes(Hp, 1, 0)
                Hs = np.swapaxes(Hs, 1, 0)

                fHp = self.__blur_image__(Hp, boxcar)
                fHs = self.__blur_image__(Hs, boxcar)

                H = fHs / fHp
                H[Hp &lt; Pthresh] = np.nan

                if plot:
                        plt.figure()
                        plt.imshow(H.T, interpolation=&#39;nearest&#39;)
                        plt.show()
                return H

        def getMeasures(self, A, maxima=&#39;centroid&#39;, field_extent_method=2, allProps=True, **kwargs):
                &#39;&#39;&#39;
                A clone of the Matlab version of this code in the m-file called
                autoCorrProps.m written by Caswell Barry and Daniel Manson and
                others
                Attempt to see how close a python instantiation replicates a
                Matlab one...
                &#39;&#39;&#39;
                A_tmp = A.copy()
                A_tmp[~np.isfinite(A)] = -1
                A_tmp[A_tmp &lt;= 0] = -1
                A_sz = np.array(np.shape(A))
                # [STAGE 1] find peaks &amp; identify 7 closest to centre
                if &#39;min_distance&#39; in kwargs.keys():
                        min_distance = kwargs.pop(&#39;min_distance&#39;)
                else:
                        min_distance = np.ceil(np.min(A_sz / 2) / 8.).astype(int)
                peaksMask = skimage.feature.peak_local_max(A_tmp, indices=False, min_distance=min_distance,exclude_border=False)
                peaksLabel = skimage.measure.label(peaksMask, connectivity=2)
                if maxima == &#39;centroid&#39;:
                        S = skimage.measure.regionprops(peaksLabel)
                        xyCoordPeaks = np.fliplr(np.array([(x[&#39;Centroid&#39;][1],x[&#39;Centroid&#39;][0]) for x in S]))
                elif maxima == &#39;single&#39;:
                        xyCoordPeaks = np.fliplr(np.rot90(np.array(np.nonzero(peaksLabel))))# flipped so xy instead of yx
                # Convert to a new reference frame which has the origin at the centre of the autocorr
                centralPoint = np.ceil(A_sz/2).astype(int)
                xyCoordPeaksCentral = xyCoordPeaks - centralPoint
                # calculate distance of peaks from centre and find 7 closest
                # NB one is central peak - dealt with later
                peaksDistToCentre = np.hypot(xyCoordPeaksCentral[:,1],xyCoordPeaksCentral[:,0])
                orderOfClose = np.argsort(peaksDistToCentre)
                #Get id and coordinates of closest peaks1
                # NB closest peak at index 0 will be centre
                closestPeaks = orderOfClose[0:np.min((7,len(orderOfClose)))]
                closestPeaksCoord = xyCoordPeaks[closestPeaks,:]
                closestPeaksCoord = np.floor(closestPeaksCoord).astype(np.int)
                # [Stage 2] Expand peak pixels into the surrounding half-height region
                if field_extent_method == 1:
                        peakLabel = np.zeros((A.shape[0], A.shape[1], len(closestPeaks)))
                        perimeterLabel = np.zeros_like(peakLabel)
                        for i in range(len(closestPeaks)):
                                peakLabel[:,:,i], perimeterLabel[:,:,i] = self.__findPeakExtent__(A, closestPeaks[i], closestPeaksCoord[i])
                        fieldsLabel = np.max(peakLabel,2)
                        fieldsMask = fieldsLabel &gt; 0
                elif field_extent_method == 2:
                        # 2a find the inverse drainage bin for each peak
                        fieldsLabel = skimage.morphology.watershed(image=-A_tmp, markers=peaksLabel)
#            fieldsLabel = skimage.segmentation.random_walker(-A, peaksLabel)
                        # 2b. Work out what threshold to use in each drainage-basin
                        nZones = np.max(fieldsLabel.ravel())
                        fieldIDs = fieldsLabel[closestPeaksCoord[:,0],closestPeaksCoord[:,1]]
                        thresholds = np.ones((nZones,1)) * np.inf
                        # set thresholds for each sub-field at half-maximum
                        thresholds[fieldIDs - 1, 0] = A[closestPeaksCoord[:,0],closestPeaksCoord[:,1]] / 2
                        fieldsMask = np.zeros((A.shape[0],A.shape[1],nZones))
                        for field in fieldIDs:
                                sub = fieldsLabel == field
                                fieldsMask[:,:, field-1] = np.logical_and(sub, A&gt;thresholds[field-1])
                                # TODO: the above step can fragment a sub-field in poorly formed SACs
                                # need to deal with this...perhaps by only retaining the largest
                                # sub-sub-field
                                labelled_sub_field = skimage.measure.label(fieldsMask[:,:, field-1], connectivity=2)
                                sub_props = skimage.measure.regionprops(labelled_sub_field)
                                if len(sub_props) &gt; 1:
                                        distFromCentre = []
                                        for s in range(len(sub_props)):
                                                centroid = sub_props[s][&#39;Centroid&#39;]
                                                distFromCentre.append(np.hypot(centroid[0]-A_sz[1],centroid[1]-A_sz[0]))
                                        idx = np.argmin(distFromCentre)
                                        tmp = np.zeros_like(A)
                                        tmp[sub_props[idx][&#39;Coordinates&#39;][:,0],sub_props[idx][&#39;Coordinates&#39;][:,1]] = 1
                                        fieldsMask[:,:, field-1] = tmp.astype(bool)
                        fieldsMask = np.max(fieldsMask,2).astype(bool)
                        fieldsLabel[~fieldsMask] = 0
                fieldPerim = mahotas.bwperim(fieldsMask)
                fieldsLabel = fieldsLabel.astype(int)
                # [Stage 3] Calculate a couple of metrics based on the closest peaks
                #Find the (mean) autoCorr value at the closest peak pixels
                nPixelsInLabel = np.bincount(fieldsLabel.ravel())
                sumRInLabel = np.bincount(fieldsLabel.ravel(), weights=A.ravel())
                meanRInLabel = sumRInLabel[closestPeaks+1] / nPixelsInLabel[closestPeaks+1]
                # get scale of grid
                closestPeakDistFromCentre = peaksDistToCentre[closestPeaks[1:]]
                scale = np.median(closestPeakDistFromCentre.ravel())
                # get orientation
                try:
                        orientation = self.getorientation(xyCoordPeaksCentral, closestPeaks)
                except:
                        orientation = np.nan
                # calculate gridness
                # THIS STEP MASKS THE MIDDLE AND OUTER PARTS OF THE SAC
                # 
                # crop to the central region of the image and remove central peak
                x = np.linspace(-centralPoint[0], centralPoint[0], A_sz[0])
                y = np.linspace(-centralPoint[1], centralPoint[1], A_sz[1])
                xx, yy = np.meshgrid(x, y, indexing = &#39;ij&#39;)
                dist2Centre = np.hypot(xx,yy)
                maxDistFromCentre = np.nan
                if len(closestPeaks) &gt;= 7:
                        maxDistFromCentre = np.max(dist2Centre[fieldsMask])
                if np.logical_or(np.isnan(maxDistFromCentre), maxDistFromCentre &gt; np.min(np.floor(A_sz/2))):
                        maxDistFromCentre = np.min(np.floor(A_sz/2))
                gridnessMaskAll = dist2Centre &lt;= maxDistFromCentre
                centreMask = fieldsLabel == fieldsLabel[centralPoint[0],centralPoint[1]]
                gridnessMask = np.logical_and(gridnessMaskAll, ~centreMask)
                W = np.ceil(maxDistFromCentre).astype(int)
                autoCorrMiddle = A.copy()
                autoCorrMiddle[~gridnessMask] = np.nan
                autoCorrMiddle = autoCorrMiddle[-W + centralPoint[0]:W + centralPoint[0],-W+centralPoint[1]:W+centralPoint[1]]
                # crop the edges of the middle if there are rows/ columns of nans
                if np.any(np.all(np.isnan(autoCorrMiddle), 1)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 1)))[0][0], 0)
                if np.any(np.all(np.isnan(autoCorrMiddle), 0)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 0)))[0][0], 1)
                if &#39;step&#39; in kwargs.keys():
                        step = kwargs.pop(&#39;step&#39;)
                else:
                        step = 30
                gridness, rotationCorrVals, rotationArr = self.getgridness(autoCorrMiddle, step=step)
                # attempt to fit an ellipse to the closest peaks
                if allProps:
                        try:
                                a = self.__fit_ellipse__(closestPeaksCoord[1:,0],closestPeaksCoord[1:,1])
                                im_centre = self.__ellipse_center__(a)
                                ellipse_axes = self.__ellipse_axis_length__(a)
                                ellipse_angle = self.__ellipse_angle_of_rotation__(a)
        #            ang =  ang + np.pi
                                ellipseXY = self.__getellipseXY__(ellipse_axes[0], ellipse_axes[1], ellipse_angle, im_centre)
                                # get the minimum containing circle based on the minor axis of the ellipse
                                circleXY = self.__getcircleXY__(im_centre, np.min(ellipse_axes))
                        except:
                                im_centre = centralPoint
                                ellipse_angle = np.nan
                                ellipse_axes = (np.nan, np.nan)
                                ellipseXY = centralPoint
                                circleXY = centralPoint
                else:
                        ellipseXY = None
                        circleXY = None
                        ellipse_axes = None
                        ellipse_angle = None
                        im_centre = None
                # collect all the following keywords into a dict for output
                dictKeys = (&#39;gridness&#39;,&#39;scale&#39;, &#39;orientation&#39;, &#39;closestPeaksCoord&#39;, &#39;gridnessMaskAll&#39;, &#39;gridnessMask&#39;,
                &#39;ellipse_axes&#39;, &#39;ellipse_angle&#39;, &#39;im_centre&#39;, &#39;rotationArr&#39;,&#39;rotationCorrVals&#39;)
                outDict = dict.fromkeys(dictKeys,np.nan)
                for thiskey in outDict.keys():
                        outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
                return outDict

        def getextrema(self, rotationArray):
                &#39;&#39;&#39;
                Uses peak_local_max to find the extrema in the rotational correlation
                plot used to calculate gridness
                NB: requires a rotation array that spans values from 0 to 180 degrees
                &#39;&#39;&#39;
                maxima = skimage.feature.peak_local_max(rotationArray)
                minima = skimage.feature.peak_local_max(-rotationArray)
                return maxima, minima

        def getorientation(self, peakCoords, closestPeakIdx):
                if len(closestPeakIdx) == 1:
                        return np.nan
                else:
                        closestPeaksCoordCentral = peakCoords[closestPeakIdx[1::]]
                        theta = polar(closestPeaksCoordCentral[:,1], -closestPeaksCoordCentral[:,0], deg=1)[1]
                        return np.sort(theta.compress(theta&gt;0))[0]

        def getgridness(self, image, step=30):
                #TODO: add options in here for whether the full range of correlations are wanted
                # or whether a reduced set is wanted (i.e. at the 30-tuples)
                rotationalCorrVals = collections.OrderedDict.fromkeys(np.arange(0,181,step),np.nan)
                rotationArr = np.zeros(len(rotationalCorrVals)) * np.nan
                # autoCorrMiddle needs to be rescaled or the image rotation falls down
                # as values are cropped to lie between 0 and 1.0
                in_range = (np.nanmin(image), np.nanmax(image))
                out_range = (0, 1)
                autoCorrMiddleRescaled = skimage.exposure.rescale_intensity(image, in_range, out_range)
                origNanIdx = np.isnan(autoCorrMiddleRescaled.ravel())
                for idx, angle in enumerate(rotationalCorrVals.keys()):
                        rotatedA = skimage.transform.rotate(autoCorrMiddleRescaled, angle=angle, cval=np.nan, order=3)
                        # ignore nans
                        rotatedNanIdx = np.isnan(rotatedA.ravel())
                        allNans = np.logical_or(origNanIdx, rotatedNanIdx)
                        # get the correlation between the original and rotated images and assign
                        rotationalCorrVals[angle] = scipy.stats.pearsonr(autoCorrMiddleRescaled.ravel()[~allNans], rotatedA.ravel()[~allNans])[0]
                        rotationArr[idx] = rotationalCorrVals[angle]
                gridscore = np.min((rotationalCorrVals[60],rotationalCorrVals[120])) - np.max((rotationalCorrVals[150],rotationalCorrVals[30],rotationalCorrVals[90]))
                return gridscore, rotationalCorrVals, rotationArr

        def show(self, A, inDict, ax=None, **kwargs):
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                Am = A.copy()
                Am[~inDict[&#39;gridnessMaskAll&#39;]] = np.nan
                Am = np.ma.masked_invalid(np.atleast_2d(Am))
                ret = ax.imshow(A, cmap=cm.gray_r, interpolation=&#39;nearest&#39;)
                cmap = plt.cm.jet
                cmap.set_bad(&#39;w&#39;, 0)
                ax.pcolormesh(Am, cmap=cmap, edgecolors=&#39;face&#39;)
                # horizontal green line at 3 o&#39;clock
                ax.plot((inDict[&#39;closestPeaksCoord&#39;][0,1],np.max(inDict[&#39;closestPeaksCoord&#39;][:,1])),
                                  (inDict[&#39;closestPeaksCoord&#39;][0,0],inDict[&#39;closestPeaksCoord&#39;][0,0]),&#39;-g&#39;, **kwargs)
                mag = inDict[&#39;scale&#39;] * 0.5
                th = np.linspace(0, inDict[&#39;orientation&#39;], 50)
                [x, y] = rect(mag, th, deg=1)
                # angle subtended by orientation
                ax.plot(x + (inDict[&#39;gridnessMask&#39;].shape[1] / 2), (inDict[&#39;gridnessMask&#39;].shape[0] / 2) - y, &#39;r&#39;, **kwargs)
                # plot lines from centre to peaks above middle
                for p in inDict[&#39;closestPeaksCoord&#39;]:
                        if p[0] &lt;= inDict[&#39;gridnessMask&#39;].shape[0] / 2:
                                ax.plot((inDict[&#39;gridnessMask&#39;].shape[1] / 2,p[1]),(inDict[&#39;gridnessMask&#39;].shape[0] / 2,p[0]),&#39;k&#39;, **kwargs)
                all_ax = ax.axes
                x_ax = all_ax.get_xaxis()
                x_ax.set_tick_params(which=&#39;both&#39;, bottom=False, labelbottom=False,
                                                         top=False)
                y_ax = all_ax.get_yaxis()
                y_ax.set_tick_params(which=&#39;both&#39;, left=False, labelleft=False,
                                                         right=False)
                all_ax.set_aspect(&#39;equal&#39;)
                all_ax.set_xlim((0.5, inDict[&#39;gridnessMask&#39;].shape[1]-1.5))
                all_ax.set_ylim((inDict[&#39;gridnessMask&#39;].shape[0]-.5, -.5))
                plt.setp(ax.get_xticklabels(), visible=False)
                plt.setp(ax.get_yticklabels(), visible=False)
                ax.axes.get_xaxis().set_visible(False)
                ax.axes.get_yaxis().set_visible(False)
                ax.spines[&#39;right&#39;].set_visible(False)
                ax.spines[&#39;top&#39;].set_visible(False)
                ax.spines[&#39;bottom&#39;].set_visible(False)
                ax.spines[&#39;left&#39;].set_visible(False)
                if &#34;show_gridscore&#34; in kwargs.keys():
                        ax.annotate(&#39;{:.2f}&#39;.format(inDict[&#39;gridness&#39;]), (0.9,0.15), \
                                xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)
                return ret

        def deformSAC(self, A, circleXY, ellipseXY):
                A[np.isnan(A)] = 0
                if circleXY.shape[0] == 2:
                        circleXY = circleXY.T
                if ellipseXY.shape[0] == 2:
                        ellipseXY = ellipseXY.T
                tform = skimage.transform.AffineTransform()
                tform.estimate(ellipseXY, circleXY)
                &#39;&#39;&#39;
                the transformation algorithms used here crop values &lt; 0 to 0. Need to
                rescale the SAC values before doing the deformation and then rescale
                again so the values assume the same range as in the unadulterated SAC
                &#39;&#39;&#39;
                SACmin = np.nanmin(A.flatten())#should be 1
                SACmax = np.nanmax(A.flatten())
                AA = A + 1
                deformedSAC = skimage.transform.warp(AA / np.nanmax(AA.flatten()), inverse_map=tform.inverse, cval=0)
                return skimage.exposure.rescale_intensity(deformedSAC, out_range=(SACmin,SACmax))

        def __getcircleXY__(self, centre, radius):
                &#39;&#39;&#39;
                function XY = getcircleXY(centre, radius):
                given the origin (1x2 array) and radius this returns 100 x and y points
                for plotting of a circle
                &#39;&#39;&#39;
                npts = 100
                t = np.linspace(0+(np.pi/4), (2*np.pi)+(np.pi/4), npts)
                r = np.repeat(radius, npts)
                x = r * np.cos(t) + centre[1]
                y = r * np.sin(t) + centre[0]
                return np.array((x,y))

        def __getellipseXY__(self, a, b, ang, im_centre):
                &#39;&#39;&#39;
                function XY = getellipseXY(a, b, ang, im_centre):
                angles are in radians
                given the lengths of the major and minor axes of an ellipse (a and b), the angle of
                rotation and the origin (1x2 array) this returns 100 x and y points for
                plotting of an ellipse
                &#39;&#39;&#39;
                pts = 100
                cos_a, sin_a = np.cos(ang), np.sin(ang)
                theta = np.linspace(0, 2*np.pi, pts)
                X = a*np.cos(theta)*cos_a - sin_a*b*np.sin(theta) + im_centre[1]
                Y = a*np.cos(theta)*sin_a + cos_a*b*np.sin(theta) + im_centre[0]
                return np.array((X,Y))

        def __fit_ellipse__(self, x, y):
                x = x[:,np.newaxis]
                y = y[:,np.newaxis]
                D =  np.hstack((x*x, x*y, y*y, x, y, np.ones_like(x)))
                S = np.dot(D.T,D)
                C = np.zeros([6,6])
                C[0,2] = C[2,0] = 2; C[1,1] = -1
                E, V =  np.linalg.eig(np.dot(np.linalg.inv(S), C))
                n = np.argmax(np.abs(E))
                a = V[:,n]
                return a

        def __ellipse_center__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                num = b*b-a*c
                x0=(c*d-b*f)/num
                y0=(a*f-b*d)/num
                return np.array([x0,y0])

        def __ellipse_angle_of_rotation__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                return 0.5*np.arctan(2*b/(a-c))

        def __ellipse_axis_length__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                _up = 2*(a*f*f+c*d*d+g*b*b-2*b*d*f-a*c*g)
                down1=(b*b-a*c)*( (c-a)*np.sqrt(1+4*b*b/((a-c)*(a-c)))-(c+a))
                down2=(b*b-a*c)*( (a-c)*np.sqrt(1+4*b*b/((a-c)*(a-c)))-(c+a))
                res1=np.sqrt(_up/np.abs(down1))
                res2=np.sqrt(_up/np.abs(down2))
                return np.array([res1, res2])

        def __blur_image__(self, im, n, ny=None, ftype=&#39;box&#39;):
                &#34;&#34;&#34; blurs the image by convolving with a filter (&#39;gauss&#39; or &#39;box&#39;) of
                        size n. The optional keyword argument ny allows for a different
                        size in the y direction.
                &#34;&#34;&#34;
                #g = gauss_kern(n, sizey=ny)quit
                # check for dimensionality of image to be blurred and form correct filter
                if ftype == &#39;box&#39;:
                        if np.ndim(im) == 1:
                                g = scipy.signal.boxcar(n) / float(n)
                        elif np.ndim(im) == 2:
                                g = scipy.signal.boxcar([n, n]) / float(n)
                elif ftype == &#39;gauss&#39;:
                        g = self.gauss_kern(n, sizey=ny)
                        if np.ndim(im) == 1:
                                g = g[n, :]
                improc = scipy.signal.convolve(im, g, mode=&#39;same&#39;)
                return improc

        def __findPeakExtent__(self, A, peakID, peakCoord):
                &#39;&#39;&#39;
                Finds extent of field that belongs to each peak - defined as area
                in half-height and also perimieter.
                NB - peakCoord must by m,n pair in normal matrix coords
                &#39;&#39;&#39;
                peakLabel = np.zeros((A.shape[0], A.shape[1]))
                perimeterLabel = np.zeros_like(peakLabel)

                # define threshold to use - currently this is half-height
                halfHeight = A[peakCoord[1], peakCoord[0]] * .5
                aboveHalfHeightLabel = scipy.ndimage.label(A &gt; halfHeight, structure=np.ones((3,3)))[0]
                peakIDTmp = aboveHalfHeightLabel[peakCoord[1], peakCoord[0]]
                peakLabel[aboveHalfHeightLabel == peakIDTmp] = peakID
                perimeterLabel[mahotas.bwperim(aboveHalfHeightLabel==peakIDTmp)] = peakID
                return peakLabel, perimeterLabel</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ephysiopy.dacq2py.gridcell.SAC"><code class="flex name class">
<span>class <span class="ident">SAC</span></span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SAC(object):
        def __init__(self):
                pass
        def autoCorr2D(self, A, nodwell, tol=1e-10):
                &#39;&#39;&#39;
                Performs a spatial autocorrelation on A
                Inputs:
                        A - an n-dimensional array of ratemaps
                                A can be either 2 or 3 dimensional. In the former case it is 
                                simply the binned up ratemap where the two dimensions correspond
                                to x and y. In the latter case the first two dimensions are x
                                and y and the third is &#39;stack&#39; of ratemaps
                        nodwell - a boolean array corresponding the bins in the ratemap that
                                weren&#39;t visited. Usually this is generated as:
                                        nodwell = ~np.isfinite(A) NB use this form even if A is 3D
                        tol - values below this are set to zero to deal with v small values
                                thrown up by the fft
                &#39;&#39;&#39;

                if np.ndim(A) == 2:
                        m,n = np.shape(A)
                        o = 1
                        x = np.reshape(A, (m,n,o))
                        nodwell = np.reshape(nodwell, (m,n,o))
                elif np.ndim(A) == 3:
                        m,n,o = np.shape(A)
                        x = A.copy()
                
                x[nodwell] = 0
                # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
                Fx = np.fft.fft(np.fft.fft(x,2*m-1,axis=0),2*n-1,axis=1)
                FsumOfSquares_x = np.fft.fft(np.fft.fft(np.power(x,2),2*m-1,axis=0),2*n-1,axis=1)
                Fn = np.fft.fft(np.fft.fft(np.invert(nodwell).astype(int),2*m-1,axis=0),2*n-1,axis=1)
                # [Step 2] Multiply the relevant transforms and invert to obtain the
                # equivalent convolutions
                rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fx * np.conj(Fx),axis=1),axis=0)),axes=(0,1))
                sums_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(np.conj(Fx) * Fn,axis=1),axis=0)),axes=(0,1))
                sumOfSquares_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(FsumOfSquares_x),axis=1),axis=0)),axes=(0,1))
                N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(Fn),axis=1),axis=0)),axes=(0,1))
                # [Step 3] Account for rounding errors.
                rawCorr[np.abs(rawCorr) &lt; tol] = 0
                sums_x[np.abs(sums_x) &lt; tol] = 0
                sumOfSquares_x[np.abs(sumOfSquares_x) &lt; tol] = 0
                N = np.round(N)
                N[N&lt;=1] = np.nan
                # [Step 4] Compute correlation matrix
                mapStd = np.sqrt((sumOfSquares_x * N) - sums_x**2)
                mapCovar = (rawCorr * N) - sums_x * sums_x[::-1,:,:][:,::-1,:][:,:,:]

                return np.squeeze(mapCovar / mapStd / mapStd[::-1,:,:][:,::-1,:][:,:,:])

        def crossCorr2D(self, A, B, A_nodwell, B_nodwell, tol=1e-10):
                if np.ndim(A) != np.ndim(B):
                        raise ValueError(&#39;Both arrays must have the same dimensionality&#39;)
                if np.ndim(A) == 2:
                        ma, na = np.shape(A)
                        mb, nb = np.shape(B)
                        oa = ob = 1
                elif np.ndim(A) == 3:
                        [ma,na,oa] = np.shape(A)
                        [mb,nb,ob] = np.shape(B)
                A = np.reshape(A, (ma, na, oa))
                B = np.reshape(B, (mb, nb, ob))
#               import pdb
#               pdb.set_trace()
                A_nodwell = np.reshape(A_nodwell, (ma, na, oa))
                B_nodwell = np.reshape(B_nodwell, (mb, nb, ob))
                A[A_nodwell] = 0
                B[B_nodwell] = 0
                # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
                Fa = np.fft.fft(np.fft.fft(A,2*mb-1,axis=0),2*nb-1,axis=1)
                FsumOfSquares_a = np.fft.fft(np.fft.fft(np.power(A,2),2*mb-1,axis=0),2*nb-1,axis=1)
                Fn_a = np.fft.fft(np.fft.fft(np.invert(A_nodwell).astype(int),2*mb-1,axis=0),2*nb-1,axis=1)

                Fb = np.fft.fft(np.fft.fft(B,2*ma-1,axis=0),2*na-1,axis=1)
                FsumOfSquares_b = np.fft.fft(np.fft.fft(np.power(B,2),2*ma-1,axis=0),2*na-1,axis=1)
                Fn_b = np.fft.fft(np.fft.fft(np.invert(B_nodwell).astype(int),2*ma-1,axis=0),2*na-1,axis=1)
                # [Step 2] Multiply the relevant transforms and invert to obtain the
                # equivalent convolutions
                rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fb),axis=1),axis=0)))
                sums_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fn_b),axis=1),axis=0)))
                sums_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fb),axis=1),axis=0)))
                sumOfSquares_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(FsumOfSquares_a * np.conj(Fn_b),axis=1),axis=0)))
                sumOfSquares_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(FsumOfSquares_b),axis=1),axis=0)))
                N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fn_b),axis=1),axis=0)))
                # [Step 3] Account for rounding errors.
                rawCorr[np.abs(rawCorr) &lt; tol] = 0
                sums_a[np.abs(sums_a) &lt; tol] = 0
                sums_b[np.abs(sums_b) &lt; tol] = 0
                sumOfSquares_a[np.abs(sumOfSquares_a) &lt; tol] = 0
                sumOfSquares_b[np.abs(sumOfSquares_b) &lt; tol] = 0
                N = np.round(N)
                N[N&lt;=1] = np.nan
                # [Step 4] Compute correlation matrix
                mapStd_a = np.sqrt((sumOfSquares_a * N) - sums_a**2)
                mapStd_b = np.sqrt((sumOfSquares_b * N) - sums_b**2)
                mapCovar = (rawCorr * N) - sums_a * sums_b

                return np.squeeze(mapCovar / (mapStd_a * mapStd_b))

        def t_win_SAC(self, xy, spkIdx, ppm = 365, winSize=10, pos_sample_rate=50, nbins=71, boxcar=5, Pthresh=100, downsampfreq=50, plot=False):
                &#39;&#39;&#39;
                [Stage 0] Get some numbers
                &#39;&#39;&#39;
                xy = xy / ppm * 100
                n_samps = xy.shape[1]
                n_spks = len(spkIdx)
                winSizeBins = np.min([winSize * pos_sample_rate, n_samps])
                downsample = np.ceil(pos_sample_rate / downsampfreq) # factor by which positions are downsampled.
                Pthresh = Pthresh / downsample # take account of downsampling

                &#39;&#39;&#39;
                [Stage 1] Calculate number of spikes in the window for each spikeInd (ignoring spike itself)
                &#39;&#39;&#39;
                #1a. Loop preparation
                nSpikesInWin = np.zeros(n_spks, dtype=np.int)

                #1b. Keep looping until we have dealt with all spikes
                for i, s in enumerate(spkIdx):
                        t = np.searchsorted(spkIdx, (s, s + winSizeBins))
                        nSpikesInWin[i] = len(spkIdx[t[0]:t[1]]) - 1 # i.e. ignore ith spike

                &#39;&#39;&#39;
                [Stage 2] Prepare for main loop
                &#39;&#39;&#39;
                #2a. Work out offset inidices to be used when storing spike data
                off_spike = np.cumsum([nSpikesInWin])
                off_spike = np.pad(off_spike,(1,0),&#39;constant&#39;,constant_values=(0))

                #2b. Work out number of downsampled pos bins in window and offset indicies for storing data
                nPosInWindow = np.minimum(winSizeBins, n_samps - spkIdx)
                nDownsampInWin = np.floor((nPosInWindow-1)/downsample)+1

                off_dwell = np.cumsum(nDownsampInWin.astype(int))
                off_dwell = np.pad(off_dwell,(1,0),&#39;constant&#39;,constant_values=(0))
                

                #2c. Pre-allocate dwell and spike arrays, singles for speed
                dwell = np.zeros((2, off_dwell[-1]),dtype=np.single) * np.nan
                spike = np.zeros((2, off_spike[-1]), dtype=np.single) * np.nan

                filled_pvals = 0
                filled_svals = 0

                for i in range(n_spks):
                        # calculate dwell displacements
                        winInd_dwell = np.arange(spkIdx[i] + 1, np.minimum(spkIdx[i]+winSizeBins, n_samps), downsample, dtype=np.int)
                        WL = len(winInd_dwell)
                        dwell[:, filled_pvals:filled_pvals + WL] = np.rot90(np.array(np.rot90(xy[:, winInd_dwell]) - xy[:,spkIdx[i]]))
                        filled_pvals = filled_pvals + WL
                        # calculate spike displacements
                        winInd_spks = i + (spkIdx[i+1:n_spks] &lt; spkIdx[i]+winSizeBins).nonzero()[0]
                        WL = len(winInd_spks)
                        spike[:, filled_svals:filled_svals+WL] = np.rot90(np.array(np.rot90(xy[:, spkIdx[winInd_spks]]) - xy[:,spkIdx[i]]))
                        filled_svals = filled_svals + WL

                dwell = np.delete(dwell, np.isnan(dwell).nonzero()[1], axis=1)
                spike = np.delete(spike, np.isnan(spike).nonzero()[1], axis=1)

                dwell = np.hstack((dwell, -dwell))
                spike = np.hstack((spike, -spike))

                dwell_min = np.min(dwell, axis=1)
                dwell_max = np.max(dwell, axis=1)

                binsize = (dwell_max[1] - dwell_min[1]) / nbins

                dwell = np.round((dwell - np.ones_like(dwell) * dwell_min[:,np.newaxis]) / binsize)
                spike = np.round((spike - np.ones_like(spike) * dwell_min[:,np.newaxis]) / binsize)

                binsize = np.max(dwell, axis=1)
                binedges = np.array(((-0.5,-0.5),binsize+0.5)).T
                Hp = np.histogram2d(dwell[0,:], dwell[1,:], range=binedges, bins=binsize)[0]
                Hs = np.histogram2d(spike[0,:], spike[1,:], range=binedges, bins=binsize)[0]

#        # reverse y,x order
                Hp = np.swapaxes(Hp, 1, 0)
                Hs = np.swapaxes(Hs, 1, 0)

                fHp = self.__blur_image__(Hp, boxcar)
                fHs = self.__blur_image__(Hs, boxcar)

                H = fHs / fHp
                H[Hp &lt; Pthresh] = np.nan

                if plot:
                        plt.figure()
                        plt.imshow(H.T, interpolation=&#39;nearest&#39;)
                        plt.show()
                return H

        def getMeasures(self, A, maxima=&#39;centroid&#39;, field_extent_method=2, allProps=True, **kwargs):
                &#39;&#39;&#39;
                A clone of the Matlab version of this code in the m-file called
                autoCorrProps.m written by Caswell Barry and Daniel Manson and
                others
                Attempt to see how close a python instantiation replicates a
                Matlab one...
                &#39;&#39;&#39;
                A_tmp = A.copy()
                A_tmp[~np.isfinite(A)] = -1
                A_tmp[A_tmp &lt;= 0] = -1
                A_sz = np.array(np.shape(A))
                # [STAGE 1] find peaks &amp; identify 7 closest to centre
                if &#39;min_distance&#39; in kwargs.keys():
                        min_distance = kwargs.pop(&#39;min_distance&#39;)
                else:
                        min_distance = np.ceil(np.min(A_sz / 2) / 8.).astype(int)
                peaksMask = skimage.feature.peak_local_max(A_tmp, indices=False, min_distance=min_distance,exclude_border=False)
                peaksLabel = skimage.measure.label(peaksMask, connectivity=2)
                if maxima == &#39;centroid&#39;:
                        S = skimage.measure.regionprops(peaksLabel)
                        xyCoordPeaks = np.fliplr(np.array([(x[&#39;Centroid&#39;][1],x[&#39;Centroid&#39;][0]) for x in S]))
                elif maxima == &#39;single&#39;:
                        xyCoordPeaks = np.fliplr(np.rot90(np.array(np.nonzero(peaksLabel))))# flipped so xy instead of yx
                # Convert to a new reference frame which has the origin at the centre of the autocorr
                centralPoint = np.ceil(A_sz/2).astype(int)
                xyCoordPeaksCentral = xyCoordPeaks - centralPoint
                # calculate distance of peaks from centre and find 7 closest
                # NB one is central peak - dealt with later
                peaksDistToCentre = np.hypot(xyCoordPeaksCentral[:,1],xyCoordPeaksCentral[:,0])
                orderOfClose = np.argsort(peaksDistToCentre)
                #Get id and coordinates of closest peaks1
                # NB closest peak at index 0 will be centre
                closestPeaks = orderOfClose[0:np.min((7,len(orderOfClose)))]
                closestPeaksCoord = xyCoordPeaks[closestPeaks,:]
                closestPeaksCoord = np.floor(closestPeaksCoord).astype(np.int)
                # [Stage 2] Expand peak pixels into the surrounding half-height region
                if field_extent_method == 1:
                        peakLabel = np.zeros((A.shape[0], A.shape[1], len(closestPeaks)))
                        perimeterLabel = np.zeros_like(peakLabel)
                        for i in range(len(closestPeaks)):
                                peakLabel[:,:,i], perimeterLabel[:,:,i] = self.__findPeakExtent__(A, closestPeaks[i], closestPeaksCoord[i])
                        fieldsLabel = np.max(peakLabel,2)
                        fieldsMask = fieldsLabel &gt; 0
                elif field_extent_method == 2:
                        # 2a find the inverse drainage bin for each peak
                        fieldsLabel = skimage.morphology.watershed(image=-A_tmp, markers=peaksLabel)
#            fieldsLabel = skimage.segmentation.random_walker(-A, peaksLabel)
                        # 2b. Work out what threshold to use in each drainage-basin
                        nZones = np.max(fieldsLabel.ravel())
                        fieldIDs = fieldsLabel[closestPeaksCoord[:,0],closestPeaksCoord[:,1]]
                        thresholds = np.ones((nZones,1)) * np.inf
                        # set thresholds for each sub-field at half-maximum
                        thresholds[fieldIDs - 1, 0] = A[closestPeaksCoord[:,0],closestPeaksCoord[:,1]] / 2
                        fieldsMask = np.zeros((A.shape[0],A.shape[1],nZones))
                        for field in fieldIDs:
                                sub = fieldsLabel == field
                                fieldsMask[:,:, field-1] = np.logical_and(sub, A&gt;thresholds[field-1])
                                # TODO: the above step can fragment a sub-field in poorly formed SACs
                                # need to deal with this...perhaps by only retaining the largest
                                # sub-sub-field
                                labelled_sub_field = skimage.measure.label(fieldsMask[:,:, field-1], connectivity=2)
                                sub_props = skimage.measure.regionprops(labelled_sub_field)
                                if len(sub_props) &gt; 1:
                                        distFromCentre = []
                                        for s in range(len(sub_props)):
                                                centroid = sub_props[s][&#39;Centroid&#39;]
                                                distFromCentre.append(np.hypot(centroid[0]-A_sz[1],centroid[1]-A_sz[0]))
                                        idx = np.argmin(distFromCentre)
                                        tmp = np.zeros_like(A)
                                        tmp[sub_props[idx][&#39;Coordinates&#39;][:,0],sub_props[idx][&#39;Coordinates&#39;][:,1]] = 1
                                        fieldsMask[:,:, field-1] = tmp.astype(bool)
                        fieldsMask = np.max(fieldsMask,2).astype(bool)
                        fieldsLabel[~fieldsMask] = 0
                fieldPerim = mahotas.bwperim(fieldsMask)
                fieldsLabel = fieldsLabel.astype(int)
                # [Stage 3] Calculate a couple of metrics based on the closest peaks
                #Find the (mean) autoCorr value at the closest peak pixels
                nPixelsInLabel = np.bincount(fieldsLabel.ravel())
                sumRInLabel = np.bincount(fieldsLabel.ravel(), weights=A.ravel())
                meanRInLabel = sumRInLabel[closestPeaks+1] / nPixelsInLabel[closestPeaks+1]
                # get scale of grid
                closestPeakDistFromCentre = peaksDistToCentre[closestPeaks[1:]]
                scale = np.median(closestPeakDistFromCentre.ravel())
                # get orientation
                try:
                        orientation = self.getorientation(xyCoordPeaksCentral, closestPeaks)
                except:
                        orientation = np.nan
                # calculate gridness
                # THIS STEP MASKS THE MIDDLE AND OUTER PARTS OF THE SAC
                # 
                # crop to the central region of the image and remove central peak
                x = np.linspace(-centralPoint[0], centralPoint[0], A_sz[0])
                y = np.linspace(-centralPoint[1], centralPoint[1], A_sz[1])
                xx, yy = np.meshgrid(x, y, indexing = &#39;ij&#39;)
                dist2Centre = np.hypot(xx,yy)
                maxDistFromCentre = np.nan
                if len(closestPeaks) &gt;= 7:
                        maxDistFromCentre = np.max(dist2Centre[fieldsMask])
                if np.logical_or(np.isnan(maxDistFromCentre), maxDistFromCentre &gt; np.min(np.floor(A_sz/2))):
                        maxDistFromCentre = np.min(np.floor(A_sz/2))
                gridnessMaskAll = dist2Centre &lt;= maxDistFromCentre
                centreMask = fieldsLabel == fieldsLabel[centralPoint[0],centralPoint[1]]
                gridnessMask = np.logical_and(gridnessMaskAll, ~centreMask)
                W = np.ceil(maxDistFromCentre).astype(int)
                autoCorrMiddle = A.copy()
                autoCorrMiddle[~gridnessMask] = np.nan
                autoCorrMiddle = autoCorrMiddle[-W + centralPoint[0]:W + centralPoint[0],-W+centralPoint[1]:W+centralPoint[1]]
                # crop the edges of the middle if there are rows/ columns of nans
                if np.any(np.all(np.isnan(autoCorrMiddle), 1)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 1)))[0][0], 0)
                if np.any(np.all(np.isnan(autoCorrMiddle), 0)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 0)))[0][0], 1)
                if &#39;step&#39; in kwargs.keys():
                        step = kwargs.pop(&#39;step&#39;)
                else:
                        step = 30
                gridness, rotationCorrVals, rotationArr = self.getgridness(autoCorrMiddle, step=step)
                # attempt to fit an ellipse to the closest peaks
                if allProps:
                        try:
                                a = self.__fit_ellipse__(closestPeaksCoord[1:,0],closestPeaksCoord[1:,1])
                                im_centre = self.__ellipse_center__(a)
                                ellipse_axes = self.__ellipse_axis_length__(a)
                                ellipse_angle = self.__ellipse_angle_of_rotation__(a)
        #            ang =  ang + np.pi
                                ellipseXY = self.__getellipseXY__(ellipse_axes[0], ellipse_axes[1], ellipse_angle, im_centre)
                                # get the minimum containing circle based on the minor axis of the ellipse
                                circleXY = self.__getcircleXY__(im_centre, np.min(ellipse_axes))
                        except:
                                im_centre = centralPoint
                                ellipse_angle = np.nan
                                ellipse_axes = (np.nan, np.nan)
                                ellipseXY = centralPoint
                                circleXY = centralPoint
                else:
                        ellipseXY = None
                        circleXY = None
                        ellipse_axes = None
                        ellipse_angle = None
                        im_centre = None
                # collect all the following keywords into a dict for output
                dictKeys = (&#39;gridness&#39;,&#39;scale&#39;, &#39;orientation&#39;, &#39;closestPeaksCoord&#39;, &#39;gridnessMaskAll&#39;, &#39;gridnessMask&#39;,
                &#39;ellipse_axes&#39;, &#39;ellipse_angle&#39;, &#39;im_centre&#39;, &#39;rotationArr&#39;,&#39;rotationCorrVals&#39;)
                outDict = dict.fromkeys(dictKeys,np.nan)
                for thiskey in outDict.keys():
                        outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
                return outDict

        def getextrema(self, rotationArray):
                &#39;&#39;&#39;
                Uses peak_local_max to find the extrema in the rotational correlation
                plot used to calculate gridness
                NB: requires a rotation array that spans values from 0 to 180 degrees
                &#39;&#39;&#39;
                maxima = skimage.feature.peak_local_max(rotationArray)
                minima = skimage.feature.peak_local_max(-rotationArray)
                return maxima, minima

        def getorientation(self, peakCoords, closestPeakIdx):
                if len(closestPeakIdx) == 1:
                        return np.nan
                else:
                        closestPeaksCoordCentral = peakCoords[closestPeakIdx[1::]]
                        theta = polar(closestPeaksCoordCentral[:,1], -closestPeaksCoordCentral[:,0], deg=1)[1]
                        return np.sort(theta.compress(theta&gt;0))[0]

        def getgridness(self, image, step=30):
                #TODO: add options in here for whether the full range of correlations are wanted
                # or whether a reduced set is wanted (i.e. at the 30-tuples)
                rotationalCorrVals = collections.OrderedDict.fromkeys(np.arange(0,181,step),np.nan)
                rotationArr = np.zeros(len(rotationalCorrVals)) * np.nan
                # autoCorrMiddle needs to be rescaled or the image rotation falls down
                # as values are cropped to lie between 0 and 1.0
                in_range = (np.nanmin(image), np.nanmax(image))
                out_range = (0, 1)
                autoCorrMiddleRescaled = skimage.exposure.rescale_intensity(image, in_range, out_range)
                origNanIdx = np.isnan(autoCorrMiddleRescaled.ravel())
                for idx, angle in enumerate(rotationalCorrVals.keys()):
                        rotatedA = skimage.transform.rotate(autoCorrMiddleRescaled, angle=angle, cval=np.nan, order=3)
                        # ignore nans
                        rotatedNanIdx = np.isnan(rotatedA.ravel())
                        allNans = np.logical_or(origNanIdx, rotatedNanIdx)
                        # get the correlation between the original and rotated images and assign
                        rotationalCorrVals[angle] = scipy.stats.pearsonr(autoCorrMiddleRescaled.ravel()[~allNans], rotatedA.ravel()[~allNans])[0]
                        rotationArr[idx] = rotationalCorrVals[angle]
                gridscore = np.min((rotationalCorrVals[60],rotationalCorrVals[120])) - np.max((rotationalCorrVals[150],rotationalCorrVals[30],rotationalCorrVals[90]))
                return gridscore, rotationalCorrVals, rotationArr

        def show(self, A, inDict, ax=None, **kwargs):
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                Am = A.copy()
                Am[~inDict[&#39;gridnessMaskAll&#39;]] = np.nan
                Am = np.ma.masked_invalid(np.atleast_2d(Am))
                ret = ax.imshow(A, cmap=cm.gray_r, interpolation=&#39;nearest&#39;)
                cmap = plt.cm.jet
                cmap.set_bad(&#39;w&#39;, 0)
                ax.pcolormesh(Am, cmap=cmap, edgecolors=&#39;face&#39;)
                # horizontal green line at 3 o&#39;clock
                ax.plot((inDict[&#39;closestPeaksCoord&#39;][0,1],np.max(inDict[&#39;closestPeaksCoord&#39;][:,1])),
                                  (inDict[&#39;closestPeaksCoord&#39;][0,0],inDict[&#39;closestPeaksCoord&#39;][0,0]),&#39;-g&#39;, **kwargs)
                mag = inDict[&#39;scale&#39;] * 0.5
                th = np.linspace(0, inDict[&#39;orientation&#39;], 50)
                [x, y] = rect(mag, th, deg=1)
                # angle subtended by orientation
                ax.plot(x + (inDict[&#39;gridnessMask&#39;].shape[1] / 2), (inDict[&#39;gridnessMask&#39;].shape[0] / 2) - y, &#39;r&#39;, **kwargs)
                # plot lines from centre to peaks above middle
                for p in inDict[&#39;closestPeaksCoord&#39;]:
                        if p[0] &lt;= inDict[&#39;gridnessMask&#39;].shape[0] / 2:
                                ax.plot((inDict[&#39;gridnessMask&#39;].shape[1] / 2,p[1]),(inDict[&#39;gridnessMask&#39;].shape[0] / 2,p[0]),&#39;k&#39;, **kwargs)
                all_ax = ax.axes
                x_ax = all_ax.get_xaxis()
                x_ax.set_tick_params(which=&#39;both&#39;, bottom=False, labelbottom=False,
                                                         top=False)
                y_ax = all_ax.get_yaxis()
                y_ax.set_tick_params(which=&#39;both&#39;, left=False, labelleft=False,
                                                         right=False)
                all_ax.set_aspect(&#39;equal&#39;)
                all_ax.set_xlim((0.5, inDict[&#39;gridnessMask&#39;].shape[1]-1.5))
                all_ax.set_ylim((inDict[&#39;gridnessMask&#39;].shape[0]-.5, -.5))
                plt.setp(ax.get_xticklabels(), visible=False)
                plt.setp(ax.get_yticklabels(), visible=False)
                ax.axes.get_xaxis().set_visible(False)
                ax.axes.get_yaxis().set_visible(False)
                ax.spines[&#39;right&#39;].set_visible(False)
                ax.spines[&#39;top&#39;].set_visible(False)
                ax.spines[&#39;bottom&#39;].set_visible(False)
                ax.spines[&#39;left&#39;].set_visible(False)
                if &#34;show_gridscore&#34; in kwargs.keys():
                        ax.annotate(&#39;{:.2f}&#39;.format(inDict[&#39;gridness&#39;]), (0.9,0.15), \
                                xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)
                return ret

        def deformSAC(self, A, circleXY, ellipseXY):
                A[np.isnan(A)] = 0
                if circleXY.shape[0] == 2:
                        circleXY = circleXY.T
                if ellipseXY.shape[0] == 2:
                        ellipseXY = ellipseXY.T
                tform = skimage.transform.AffineTransform()
                tform.estimate(ellipseXY, circleXY)
                &#39;&#39;&#39;
                the transformation algorithms used here crop values &lt; 0 to 0. Need to
                rescale the SAC values before doing the deformation and then rescale
                again so the values assume the same range as in the unadulterated SAC
                &#39;&#39;&#39;
                SACmin = np.nanmin(A.flatten())#should be 1
                SACmax = np.nanmax(A.flatten())
                AA = A + 1
                deformedSAC = skimage.transform.warp(AA / np.nanmax(AA.flatten()), inverse_map=tform.inverse, cval=0)
                return skimage.exposure.rescale_intensity(deformedSAC, out_range=(SACmin,SACmax))

        def __getcircleXY__(self, centre, radius):
                &#39;&#39;&#39;
                function XY = getcircleXY(centre, radius):
                given the origin (1x2 array) and radius this returns 100 x and y points
                for plotting of a circle
                &#39;&#39;&#39;
                npts = 100
                t = np.linspace(0+(np.pi/4), (2*np.pi)+(np.pi/4), npts)
                r = np.repeat(radius, npts)
                x = r * np.cos(t) + centre[1]
                y = r * np.sin(t) + centre[0]
                return np.array((x,y))

        def __getellipseXY__(self, a, b, ang, im_centre):
                &#39;&#39;&#39;
                function XY = getellipseXY(a, b, ang, im_centre):
                angles are in radians
                given the lengths of the major and minor axes of an ellipse (a and b), the angle of
                rotation and the origin (1x2 array) this returns 100 x and y points for
                plotting of an ellipse
                &#39;&#39;&#39;
                pts = 100
                cos_a, sin_a = np.cos(ang), np.sin(ang)
                theta = np.linspace(0, 2*np.pi, pts)
                X = a*np.cos(theta)*cos_a - sin_a*b*np.sin(theta) + im_centre[1]
                Y = a*np.cos(theta)*sin_a + cos_a*b*np.sin(theta) + im_centre[0]
                return np.array((X,Y))

        def __fit_ellipse__(self, x, y):
                x = x[:,np.newaxis]
                y = y[:,np.newaxis]
                D =  np.hstack((x*x, x*y, y*y, x, y, np.ones_like(x)))
                S = np.dot(D.T,D)
                C = np.zeros([6,6])
                C[0,2] = C[2,0] = 2; C[1,1] = -1
                E, V =  np.linalg.eig(np.dot(np.linalg.inv(S), C))
                n = np.argmax(np.abs(E))
                a = V[:,n]
                return a

        def __ellipse_center__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                num = b*b-a*c
                x0=(c*d-b*f)/num
                y0=(a*f-b*d)/num
                return np.array([x0,y0])

        def __ellipse_angle_of_rotation__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                return 0.5*np.arctan(2*b/(a-c))

        def __ellipse_axis_length__(self, a):
                b,c,d,f,g,a = a[1]/2, a[2], a[3]/2, a[4]/2, a[5], a[0]
                _up = 2*(a*f*f+c*d*d+g*b*b-2*b*d*f-a*c*g)
                down1=(b*b-a*c)*( (c-a)*np.sqrt(1+4*b*b/((a-c)*(a-c)))-(c+a))
                down2=(b*b-a*c)*( (a-c)*np.sqrt(1+4*b*b/((a-c)*(a-c)))-(c+a))
                res1=np.sqrt(_up/np.abs(down1))
                res2=np.sqrt(_up/np.abs(down2))
                return np.array([res1, res2])

        def __blur_image__(self, im, n, ny=None, ftype=&#39;box&#39;):
                &#34;&#34;&#34; blurs the image by convolving with a filter (&#39;gauss&#39; or &#39;box&#39;) of
                        size n. The optional keyword argument ny allows for a different
                        size in the y direction.
                &#34;&#34;&#34;
                #g = gauss_kern(n, sizey=ny)quit
                # check for dimensionality of image to be blurred and form correct filter
                if ftype == &#39;box&#39;:
                        if np.ndim(im) == 1:
                                g = scipy.signal.boxcar(n) / float(n)
                        elif np.ndim(im) == 2:
                                g = scipy.signal.boxcar([n, n]) / float(n)
                elif ftype == &#39;gauss&#39;:
                        g = self.gauss_kern(n, sizey=ny)
                        if np.ndim(im) == 1:
                                g = g[n, :]
                improc = scipy.signal.convolve(im, g, mode=&#39;same&#39;)
                return improc

        def __findPeakExtent__(self, A, peakID, peakCoord):
                &#39;&#39;&#39;
                Finds extent of field that belongs to each peak - defined as area
                in half-height and also perimieter.
                NB - peakCoord must by m,n pair in normal matrix coords
                &#39;&#39;&#39;
                peakLabel = np.zeros((A.shape[0], A.shape[1]))
                perimeterLabel = np.zeros_like(peakLabel)

                # define threshold to use - currently this is half-height
                halfHeight = A[peakCoord[1], peakCoord[0]] * .5
                aboveHalfHeightLabel = scipy.ndimage.label(A &gt; halfHeight, structure=np.ones((3,3)))[0]
                peakIDTmp = aboveHalfHeightLabel[peakCoord[1], peakCoord[0]]
                peakLabel[aboveHalfHeightLabel == peakIDTmp] = peakID
                perimeterLabel[mahotas.bwperim(aboveHalfHeightLabel==peakIDTmp)] = peakID
                return peakLabel, perimeterLabel</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ephysiopy.dacq2py.dacq2py_util.Trial" href="dacq2py_util.html#ephysiopy.dacq2py.dacq2py_util.Trial">Trial</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ephysiopy.dacq2py.gridcell.SAC.autoCorr2D"><code class="name flex">
<span>def <span class="ident">autoCorr2D</span></span>(<span>self, A, nodwell, tol=1e-10)</span>
</code></dt>
<dd>
<section class="desc"><p>Performs a spatial autocorrelation on A</p>
<h2 id="inputs">Inputs</h2>
<p>A - an n-dimensional array of ratemaps
A can be either 2 or 3 dimensional. In the former case it is
simply the binned up ratemap where the two dimensions correspond
to x and y. In the latter case the first two dimensions are x
and y and the third is 'stack' of ratemaps
nodwell - a boolean array corresponding the bins in the ratemap that
weren't visited. Usually this is generated as:
nodwell = ~np.isfinite(A) NB use this form even if A is 3D
tol - values below this are set to zero to deal with v small values
thrown up by the fft</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def autoCorr2D(self, A, nodwell, tol=1e-10):
        &#39;&#39;&#39;
        Performs a spatial autocorrelation on A
        Inputs:
                A - an n-dimensional array of ratemaps
                        A can be either 2 or 3 dimensional. In the former case it is 
                        simply the binned up ratemap where the two dimensions correspond
                        to x and y. In the latter case the first two dimensions are x
                        and y and the third is &#39;stack&#39; of ratemaps
                nodwell - a boolean array corresponding the bins in the ratemap that
                        weren&#39;t visited. Usually this is generated as:
                                nodwell = ~np.isfinite(A) NB use this form even if A is 3D
                tol - values below this are set to zero to deal with v small values
                        thrown up by the fft
        &#39;&#39;&#39;

        if np.ndim(A) == 2:
                m,n = np.shape(A)
                o = 1
                x = np.reshape(A, (m,n,o))
                nodwell = np.reshape(nodwell, (m,n,o))
        elif np.ndim(A) == 3:
                m,n,o = np.shape(A)
                x = A.copy()
        
        x[nodwell] = 0
        # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
        Fx = np.fft.fft(np.fft.fft(x,2*m-1,axis=0),2*n-1,axis=1)
        FsumOfSquares_x = np.fft.fft(np.fft.fft(np.power(x,2),2*m-1,axis=0),2*n-1,axis=1)
        Fn = np.fft.fft(np.fft.fft(np.invert(nodwell).astype(int),2*m-1,axis=0),2*n-1,axis=1)
        # [Step 2] Multiply the relevant transforms and invert to obtain the
        # equivalent convolutions
        rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fx * np.conj(Fx),axis=1),axis=0)),axes=(0,1))
        sums_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(np.conj(Fx) * Fn,axis=1),axis=0)),axes=(0,1))
        sumOfSquares_x = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(FsumOfSquares_x),axis=1),axis=0)),axes=(0,1))
        N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn * np.conj(Fn),axis=1),axis=0)),axes=(0,1))
        # [Step 3] Account for rounding errors.
        rawCorr[np.abs(rawCorr) &lt; tol] = 0
        sums_x[np.abs(sums_x) &lt; tol] = 0
        sumOfSquares_x[np.abs(sumOfSquares_x) &lt; tol] = 0
        N = np.round(N)
        N[N&lt;=1] = np.nan
        # [Step 4] Compute correlation matrix
        mapStd = np.sqrt((sumOfSquares_x * N) - sums_x**2)
        mapCovar = (rawCorr * N) - sums_x * sums_x[::-1,:,:][:,::-1,:][:,:,:]

        return np.squeeze(mapCovar / mapStd / mapStd[::-1,:,:][:,::-1,:][:,:,:])</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.crossCorr2D"><code class="name flex">
<span>def <span class="ident">crossCorr2D</span></span>(<span>self, A, B, A_nodwell, B_nodwell, tol=1e-10)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def crossCorr2D(self, A, B, A_nodwell, B_nodwell, tol=1e-10):
                if np.ndim(A) != np.ndim(B):
                        raise ValueError(&#39;Both arrays must have the same dimensionality&#39;)
                if np.ndim(A) == 2:
                        ma, na = np.shape(A)
                        mb, nb = np.shape(B)
                        oa = ob = 1
                elif np.ndim(A) == 3:
                        [ma,na,oa] = np.shape(A)
                        [mb,nb,ob] = np.shape(B)
                A = np.reshape(A, (ma, na, oa))
                B = np.reshape(B, (mb, nb, ob))
#               import pdb
#               pdb.set_trace()
                A_nodwell = np.reshape(A_nodwell, (ma, na, oa))
                B_nodwell = np.reshape(B_nodwell, (mb, nb, ob))
                A[A_nodwell] = 0
                B[B_nodwell] = 0
                # [Step 1] Obtain FFTs of x, the sum of squares and bins visited
                Fa = np.fft.fft(np.fft.fft(A,2*mb-1,axis=0),2*nb-1,axis=1)
                FsumOfSquares_a = np.fft.fft(np.fft.fft(np.power(A,2),2*mb-1,axis=0),2*nb-1,axis=1)
                Fn_a = np.fft.fft(np.fft.fft(np.invert(A_nodwell).astype(int),2*mb-1,axis=0),2*nb-1,axis=1)

                Fb = np.fft.fft(np.fft.fft(B,2*ma-1,axis=0),2*na-1,axis=1)
                FsumOfSquares_b = np.fft.fft(np.fft.fft(np.power(B,2),2*ma-1,axis=0),2*na-1,axis=1)
                Fn_b = np.fft.fft(np.fft.fft(np.invert(B_nodwell).astype(int),2*ma-1,axis=0),2*na-1,axis=1)
                # [Step 2] Multiply the relevant transforms and invert to obtain the
                # equivalent convolutions
                rawCorr = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fb),axis=1),axis=0)))
                sums_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fa * np.conj(Fn_b),axis=1),axis=0)))
                sums_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fb),axis=1),axis=0)))
                sumOfSquares_a = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(FsumOfSquares_a * np.conj(Fn_b),axis=1),axis=0)))
                sumOfSquares_b = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(FsumOfSquares_b),axis=1),axis=0)))
                N = np.fft.fftshift(np.real(np.fft.ifft(np.fft.ifft(Fn_a * np.conj(Fn_b),axis=1),axis=0)))
                # [Step 3] Account for rounding errors.
                rawCorr[np.abs(rawCorr) &lt; tol] = 0
                sums_a[np.abs(sums_a) &lt; tol] = 0
                sums_b[np.abs(sums_b) &lt; tol] = 0
                sumOfSquares_a[np.abs(sumOfSquares_a) &lt; tol] = 0
                sumOfSquares_b[np.abs(sumOfSquares_b) &lt; tol] = 0
                N = np.round(N)
                N[N&lt;=1] = np.nan
                # [Step 4] Compute correlation matrix
                mapStd_a = np.sqrt((sumOfSquares_a * N) - sums_a**2)
                mapStd_b = np.sqrt((sumOfSquares_b * N) - sums_b**2)
                mapCovar = (rawCorr * N) - sums_a * sums_b

                return np.squeeze(mapCovar / (mapStd_a * mapStd_b))</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.deformSAC"><code class="name flex">
<span>def <span class="ident">deformSAC</span></span>(<span>self, A, circleXY, ellipseXY)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deformSAC(self, A, circleXY, ellipseXY):
        A[np.isnan(A)] = 0
        if circleXY.shape[0] == 2:
                circleXY = circleXY.T
        if ellipseXY.shape[0] == 2:
                ellipseXY = ellipseXY.T
        tform = skimage.transform.AffineTransform()
        tform.estimate(ellipseXY, circleXY)
        &#39;&#39;&#39;
        the transformation algorithms used here crop values &lt; 0 to 0. Need to
        rescale the SAC values before doing the deformation and then rescale
        again so the values assume the same range as in the unadulterated SAC
        &#39;&#39;&#39;
        SACmin = np.nanmin(A.flatten())#should be 1
        SACmax = np.nanmax(A.flatten())
        AA = A + 1
        deformedSAC = skimage.transform.warp(AA / np.nanmax(AA.flatten()), inverse_map=tform.inverse, cval=0)
        return skimage.exposure.rescale_intensity(deformedSAC, out_range=(SACmin,SACmax))</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.getMeasures"><code class="name flex">
<span>def <span class="ident">getMeasures</span></span>(<span>self, A, maxima='centroid', field_extent_method=2, allProps=True, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>A clone of the Matlab version of this code in the m-file called
autoCorrProps.m written by Caswell Barry and Daniel Manson and
others
Attempt to see how close a python instantiation replicates a
Matlab one&hellip;</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def getMeasures(self, A, maxima=&#39;centroid&#39;, field_extent_method=2, allProps=True, **kwargs):
                &#39;&#39;&#39;
                A clone of the Matlab version of this code in the m-file called
                autoCorrProps.m written by Caswell Barry and Daniel Manson and
                others
                Attempt to see how close a python instantiation replicates a
                Matlab one...
                &#39;&#39;&#39;
                A_tmp = A.copy()
                A_tmp[~np.isfinite(A)] = -1
                A_tmp[A_tmp &lt;= 0] = -1
                A_sz = np.array(np.shape(A))
                # [STAGE 1] find peaks &amp; identify 7 closest to centre
                if &#39;min_distance&#39; in kwargs.keys():
                        min_distance = kwargs.pop(&#39;min_distance&#39;)
                else:
                        min_distance = np.ceil(np.min(A_sz / 2) / 8.).astype(int)
                peaksMask = skimage.feature.peak_local_max(A_tmp, indices=False, min_distance=min_distance,exclude_border=False)
                peaksLabel = skimage.measure.label(peaksMask, connectivity=2)
                if maxima == &#39;centroid&#39;:
                        S = skimage.measure.regionprops(peaksLabel)
                        xyCoordPeaks = np.fliplr(np.array([(x[&#39;Centroid&#39;][1],x[&#39;Centroid&#39;][0]) for x in S]))
                elif maxima == &#39;single&#39;:
                        xyCoordPeaks = np.fliplr(np.rot90(np.array(np.nonzero(peaksLabel))))# flipped so xy instead of yx
                # Convert to a new reference frame which has the origin at the centre of the autocorr
                centralPoint = np.ceil(A_sz/2).astype(int)
                xyCoordPeaksCentral = xyCoordPeaks - centralPoint
                # calculate distance of peaks from centre and find 7 closest
                # NB one is central peak - dealt with later
                peaksDistToCentre = np.hypot(xyCoordPeaksCentral[:,1],xyCoordPeaksCentral[:,0])
                orderOfClose = np.argsort(peaksDistToCentre)
                #Get id and coordinates of closest peaks1
                # NB closest peak at index 0 will be centre
                closestPeaks = orderOfClose[0:np.min((7,len(orderOfClose)))]
                closestPeaksCoord = xyCoordPeaks[closestPeaks,:]
                closestPeaksCoord = np.floor(closestPeaksCoord).astype(np.int)
                # [Stage 2] Expand peak pixels into the surrounding half-height region
                if field_extent_method == 1:
                        peakLabel = np.zeros((A.shape[0], A.shape[1], len(closestPeaks)))
                        perimeterLabel = np.zeros_like(peakLabel)
                        for i in range(len(closestPeaks)):
                                peakLabel[:,:,i], perimeterLabel[:,:,i] = self.__findPeakExtent__(A, closestPeaks[i], closestPeaksCoord[i])
                        fieldsLabel = np.max(peakLabel,2)
                        fieldsMask = fieldsLabel &gt; 0
                elif field_extent_method == 2:
                        # 2a find the inverse drainage bin for each peak
                        fieldsLabel = skimage.morphology.watershed(image=-A_tmp, markers=peaksLabel)
#            fieldsLabel = skimage.segmentation.random_walker(-A, peaksLabel)
                        # 2b. Work out what threshold to use in each drainage-basin
                        nZones = np.max(fieldsLabel.ravel())
                        fieldIDs = fieldsLabel[closestPeaksCoord[:,0],closestPeaksCoord[:,1]]
                        thresholds = np.ones((nZones,1)) * np.inf
                        # set thresholds for each sub-field at half-maximum
                        thresholds[fieldIDs - 1, 0] = A[closestPeaksCoord[:,0],closestPeaksCoord[:,1]] / 2
                        fieldsMask = np.zeros((A.shape[0],A.shape[1],nZones))
                        for field in fieldIDs:
                                sub = fieldsLabel == field
                                fieldsMask[:,:, field-1] = np.logical_and(sub, A&gt;thresholds[field-1])
                                # TODO: the above step can fragment a sub-field in poorly formed SACs
                                # need to deal with this...perhaps by only retaining the largest
                                # sub-sub-field
                                labelled_sub_field = skimage.measure.label(fieldsMask[:,:, field-1], connectivity=2)
                                sub_props = skimage.measure.regionprops(labelled_sub_field)
                                if len(sub_props) &gt; 1:
                                        distFromCentre = []
                                        for s in range(len(sub_props)):
                                                centroid = sub_props[s][&#39;Centroid&#39;]
                                                distFromCentre.append(np.hypot(centroid[0]-A_sz[1],centroid[1]-A_sz[0]))
                                        idx = np.argmin(distFromCentre)
                                        tmp = np.zeros_like(A)
                                        tmp[sub_props[idx][&#39;Coordinates&#39;][:,0],sub_props[idx][&#39;Coordinates&#39;][:,1]] = 1
                                        fieldsMask[:,:, field-1] = tmp.astype(bool)
                        fieldsMask = np.max(fieldsMask,2).astype(bool)
                        fieldsLabel[~fieldsMask] = 0
                fieldPerim = mahotas.bwperim(fieldsMask)
                fieldsLabel = fieldsLabel.astype(int)
                # [Stage 3] Calculate a couple of metrics based on the closest peaks
                #Find the (mean) autoCorr value at the closest peak pixels
                nPixelsInLabel = np.bincount(fieldsLabel.ravel())
                sumRInLabel = np.bincount(fieldsLabel.ravel(), weights=A.ravel())
                meanRInLabel = sumRInLabel[closestPeaks+1] / nPixelsInLabel[closestPeaks+1]
                # get scale of grid
                closestPeakDistFromCentre = peaksDistToCentre[closestPeaks[1:]]
                scale = np.median(closestPeakDistFromCentre.ravel())
                # get orientation
                try:
                        orientation = self.getorientation(xyCoordPeaksCentral, closestPeaks)
                except:
                        orientation = np.nan
                # calculate gridness
                # THIS STEP MASKS THE MIDDLE AND OUTER PARTS OF THE SAC
                # 
                # crop to the central region of the image and remove central peak
                x = np.linspace(-centralPoint[0], centralPoint[0], A_sz[0])
                y = np.linspace(-centralPoint[1], centralPoint[1], A_sz[1])
                xx, yy = np.meshgrid(x, y, indexing = &#39;ij&#39;)
                dist2Centre = np.hypot(xx,yy)
                maxDistFromCentre = np.nan
                if len(closestPeaks) &gt;= 7:
                        maxDistFromCentre = np.max(dist2Centre[fieldsMask])
                if np.logical_or(np.isnan(maxDistFromCentre), maxDistFromCentre &gt; np.min(np.floor(A_sz/2))):
                        maxDistFromCentre = np.min(np.floor(A_sz/2))
                gridnessMaskAll = dist2Centre &lt;= maxDistFromCentre
                centreMask = fieldsLabel == fieldsLabel[centralPoint[0],centralPoint[1]]
                gridnessMask = np.logical_and(gridnessMaskAll, ~centreMask)
                W = np.ceil(maxDistFromCentre).astype(int)
                autoCorrMiddle = A.copy()
                autoCorrMiddle[~gridnessMask] = np.nan
                autoCorrMiddle = autoCorrMiddle[-W + centralPoint[0]:W + centralPoint[0],-W+centralPoint[1]:W+centralPoint[1]]
                # crop the edges of the middle if there are rows/ columns of nans
                if np.any(np.all(np.isnan(autoCorrMiddle), 1)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 1)))[0][0], 0)
                if np.any(np.all(np.isnan(autoCorrMiddle), 0)):
                        autoCorrMiddle = np.delete(autoCorrMiddle, np.nonzero((np.all(np.isnan(autoCorrMiddle), 0)))[0][0], 1)
                if &#39;step&#39; in kwargs.keys():
                        step = kwargs.pop(&#39;step&#39;)
                else:
                        step = 30
                gridness, rotationCorrVals, rotationArr = self.getgridness(autoCorrMiddle, step=step)
                # attempt to fit an ellipse to the closest peaks
                if allProps:
                        try:
                                a = self.__fit_ellipse__(closestPeaksCoord[1:,0],closestPeaksCoord[1:,1])
                                im_centre = self.__ellipse_center__(a)
                                ellipse_axes = self.__ellipse_axis_length__(a)
                                ellipse_angle = self.__ellipse_angle_of_rotation__(a)
        #            ang =  ang + np.pi
                                ellipseXY = self.__getellipseXY__(ellipse_axes[0], ellipse_axes[1], ellipse_angle, im_centre)
                                # get the minimum containing circle based on the minor axis of the ellipse
                                circleXY = self.__getcircleXY__(im_centre, np.min(ellipse_axes))
                        except:
                                im_centre = centralPoint
                                ellipse_angle = np.nan
                                ellipse_axes = (np.nan, np.nan)
                                ellipseXY = centralPoint
                                circleXY = centralPoint
                else:
                        ellipseXY = None
                        circleXY = None
                        ellipse_axes = None
                        ellipse_angle = None
                        im_centre = None
                # collect all the following keywords into a dict for output
                dictKeys = (&#39;gridness&#39;,&#39;scale&#39;, &#39;orientation&#39;, &#39;closestPeaksCoord&#39;, &#39;gridnessMaskAll&#39;, &#39;gridnessMask&#39;,
                &#39;ellipse_axes&#39;, &#39;ellipse_angle&#39;, &#39;im_centre&#39;, &#39;rotationArr&#39;,&#39;rotationCorrVals&#39;)
                outDict = dict.fromkeys(dictKeys,np.nan)
                for thiskey in outDict.keys():
                        outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
                return outDict</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.getextrema"><code class="name flex">
<span>def <span class="ident">getextrema</span></span>(<span>self, rotationArray)</span>
</code></dt>
<dd>
<section class="desc"><p>Uses peak_local_max to find the extrema in the rotational correlation
plot used to calculate gridness
NB: requires a rotation array that spans values from 0 to 180 degrees</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getextrema(self, rotationArray):
        &#39;&#39;&#39;
        Uses peak_local_max to find the extrema in the rotational correlation
        plot used to calculate gridness
        NB: requires a rotation array that spans values from 0 to 180 degrees
        &#39;&#39;&#39;
        maxima = skimage.feature.peak_local_max(rotationArray)
        minima = skimage.feature.peak_local_max(-rotationArray)
        return maxima, minima</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.getgridness"><code class="name flex">
<span>def <span class="ident">getgridness</span></span>(<span>self, image, step=30)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getgridness(self, image, step=30):
        #TODO: add options in here for whether the full range of correlations are wanted
        # or whether a reduced set is wanted (i.e. at the 30-tuples)
        rotationalCorrVals = collections.OrderedDict.fromkeys(np.arange(0,181,step),np.nan)
        rotationArr = np.zeros(len(rotationalCorrVals)) * np.nan
        # autoCorrMiddle needs to be rescaled or the image rotation falls down
        # as values are cropped to lie between 0 and 1.0
        in_range = (np.nanmin(image), np.nanmax(image))
        out_range = (0, 1)
        autoCorrMiddleRescaled = skimage.exposure.rescale_intensity(image, in_range, out_range)
        origNanIdx = np.isnan(autoCorrMiddleRescaled.ravel())
        for idx, angle in enumerate(rotationalCorrVals.keys()):
                rotatedA = skimage.transform.rotate(autoCorrMiddleRescaled, angle=angle, cval=np.nan, order=3)
                # ignore nans
                rotatedNanIdx = np.isnan(rotatedA.ravel())
                allNans = np.logical_or(origNanIdx, rotatedNanIdx)
                # get the correlation between the original and rotated images and assign
                rotationalCorrVals[angle] = scipy.stats.pearsonr(autoCorrMiddleRescaled.ravel()[~allNans], rotatedA.ravel()[~allNans])[0]
                rotationArr[idx] = rotationalCorrVals[angle]
        gridscore = np.min((rotationalCorrVals[60],rotationalCorrVals[120])) - np.max((rotationalCorrVals[150],rotationalCorrVals[30],rotationalCorrVals[90]))
        return gridscore, rotationalCorrVals, rotationArr</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.getorientation"><code class="name flex">
<span>def <span class="ident">getorientation</span></span>(<span>self, peakCoords, closestPeakIdx)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getorientation(self, peakCoords, closestPeakIdx):
        if len(closestPeakIdx) == 1:
                return np.nan
        else:
                closestPeaksCoordCentral = peakCoords[closestPeakIdx[1::]]
                theta = polar(closestPeaksCoordCentral[:,1], -closestPeaksCoordCentral[:,0], deg=1)[1]
                return np.sort(theta.compress(theta&gt;0))[0]</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self, A, inDict, ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(self, A, inDict, ax=None, **kwargs):
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        Am = A.copy()
        Am[~inDict[&#39;gridnessMaskAll&#39;]] = np.nan
        Am = np.ma.masked_invalid(np.atleast_2d(Am))
        ret = ax.imshow(A, cmap=cm.gray_r, interpolation=&#39;nearest&#39;)
        cmap = plt.cm.jet
        cmap.set_bad(&#39;w&#39;, 0)
        ax.pcolormesh(Am, cmap=cmap, edgecolors=&#39;face&#39;)
        # horizontal green line at 3 o&#39;clock
        ax.plot((inDict[&#39;closestPeaksCoord&#39;][0,1],np.max(inDict[&#39;closestPeaksCoord&#39;][:,1])),
                          (inDict[&#39;closestPeaksCoord&#39;][0,0],inDict[&#39;closestPeaksCoord&#39;][0,0]),&#39;-g&#39;, **kwargs)
        mag = inDict[&#39;scale&#39;] * 0.5
        th = np.linspace(0, inDict[&#39;orientation&#39;], 50)
        [x, y] = rect(mag, th, deg=1)
        # angle subtended by orientation
        ax.plot(x + (inDict[&#39;gridnessMask&#39;].shape[1] / 2), (inDict[&#39;gridnessMask&#39;].shape[0] / 2) - y, &#39;r&#39;, **kwargs)
        # plot lines from centre to peaks above middle
        for p in inDict[&#39;closestPeaksCoord&#39;]:
                if p[0] &lt;= inDict[&#39;gridnessMask&#39;].shape[0] / 2:
                        ax.plot((inDict[&#39;gridnessMask&#39;].shape[1] / 2,p[1]),(inDict[&#39;gridnessMask&#39;].shape[0] / 2,p[0]),&#39;k&#39;, **kwargs)
        all_ax = ax.axes
        x_ax = all_ax.get_xaxis()
        x_ax.set_tick_params(which=&#39;both&#39;, bottom=False, labelbottom=False,
                                                 top=False)
        y_ax = all_ax.get_yaxis()
        y_ax.set_tick_params(which=&#39;both&#39;, left=False, labelleft=False,
                                                 right=False)
        all_ax.set_aspect(&#39;equal&#39;)
        all_ax.set_xlim((0.5, inDict[&#39;gridnessMask&#39;].shape[1]-1.5))
        all_ax.set_ylim((inDict[&#39;gridnessMask&#39;].shape[0]-.5, -.5))
        plt.setp(ax.get_xticklabels(), visible=False)
        plt.setp(ax.get_yticklabels(), visible=False)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        ax.spines[&#39;right&#39;].set_visible(False)
        ax.spines[&#39;top&#39;].set_visible(False)
        ax.spines[&#39;bottom&#39;].set_visible(False)
        ax.spines[&#39;left&#39;].set_visible(False)
        if &#34;show_gridscore&#34; in kwargs.keys():
                ax.annotate(&#39;{:.2f}&#39;.format(inDict[&#39;gridness&#39;]), (0.9,0.15), \
                        xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)
        return ret</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.gridcell.SAC.t_win_SAC"><code class="name flex">
<span>def <span class="ident">t_win_SAC</span></span>(<span>self, xy, spkIdx, ppm=365, winSize=10, pos_sample_rate=50, nbins=71, boxcar=5, Pthresh=100, downsampfreq=50, plot=False)</span>
</code></dt>
<dd>
<section class="desc"><p>[Stage 0] Get some numbers</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def t_win_SAC(self, xy, spkIdx, ppm = 365, winSize=10, pos_sample_rate=50, nbins=71, boxcar=5, Pthresh=100, downsampfreq=50, plot=False):
                &#39;&#39;&#39;
                [Stage 0] Get some numbers
                &#39;&#39;&#39;
                xy = xy / ppm * 100
                n_samps = xy.shape[1]
                n_spks = len(spkIdx)
                winSizeBins = np.min([winSize * pos_sample_rate, n_samps])
                downsample = np.ceil(pos_sample_rate / downsampfreq) # factor by which positions are downsampled.
                Pthresh = Pthresh / downsample # take account of downsampling

                &#39;&#39;&#39;
                [Stage 1] Calculate number of spikes in the window for each spikeInd (ignoring spike itself)
                &#39;&#39;&#39;
                #1a. Loop preparation
                nSpikesInWin = np.zeros(n_spks, dtype=np.int)

                #1b. Keep looping until we have dealt with all spikes
                for i, s in enumerate(spkIdx):
                        t = np.searchsorted(spkIdx, (s, s + winSizeBins))
                        nSpikesInWin[i] = len(spkIdx[t[0]:t[1]]) - 1 # i.e. ignore ith spike

                &#39;&#39;&#39;
                [Stage 2] Prepare for main loop
                &#39;&#39;&#39;
                #2a. Work out offset inidices to be used when storing spike data
                off_spike = np.cumsum([nSpikesInWin])
                off_spike = np.pad(off_spike,(1,0),&#39;constant&#39;,constant_values=(0))

                #2b. Work out number of downsampled pos bins in window and offset indicies for storing data
                nPosInWindow = np.minimum(winSizeBins, n_samps - spkIdx)
                nDownsampInWin = np.floor((nPosInWindow-1)/downsample)+1

                off_dwell = np.cumsum(nDownsampInWin.astype(int))
                off_dwell = np.pad(off_dwell,(1,0),&#39;constant&#39;,constant_values=(0))
                

                #2c. Pre-allocate dwell and spike arrays, singles for speed
                dwell = np.zeros((2, off_dwell[-1]),dtype=np.single) * np.nan
                spike = np.zeros((2, off_spike[-1]), dtype=np.single) * np.nan

                filled_pvals = 0
                filled_svals = 0

                for i in range(n_spks):
                        # calculate dwell displacements
                        winInd_dwell = np.arange(spkIdx[i] + 1, np.minimum(spkIdx[i]+winSizeBins, n_samps), downsample, dtype=np.int)
                        WL = len(winInd_dwell)
                        dwell[:, filled_pvals:filled_pvals + WL] = np.rot90(np.array(np.rot90(xy[:, winInd_dwell]) - xy[:,spkIdx[i]]))
                        filled_pvals = filled_pvals + WL
                        # calculate spike displacements
                        winInd_spks = i + (spkIdx[i+1:n_spks] &lt; spkIdx[i]+winSizeBins).nonzero()[0]
                        WL = len(winInd_spks)
                        spike[:, filled_svals:filled_svals+WL] = np.rot90(np.array(np.rot90(xy[:, spkIdx[winInd_spks]]) - xy[:,spkIdx[i]]))
                        filled_svals = filled_svals + WL

                dwell = np.delete(dwell, np.isnan(dwell).nonzero()[1], axis=1)
                spike = np.delete(spike, np.isnan(spike).nonzero()[1], axis=1)

                dwell = np.hstack((dwell, -dwell))
                spike = np.hstack((spike, -spike))

                dwell_min = np.min(dwell, axis=1)
                dwell_max = np.max(dwell, axis=1)

                binsize = (dwell_max[1] - dwell_min[1]) / nbins

                dwell = np.round((dwell - np.ones_like(dwell) * dwell_min[:,np.newaxis]) / binsize)
                spike = np.round((spike - np.ones_like(spike) * dwell_min[:,np.newaxis]) / binsize)

                binsize = np.max(dwell, axis=1)
                binedges = np.array(((-0.5,-0.5),binsize+0.5)).T
                Hp = np.histogram2d(dwell[0,:], dwell[1,:], range=binedges, bins=binsize)[0]
                Hs = np.histogram2d(spike[0,:], spike[1,:], range=binedges, bins=binsize)[0]

#        # reverse y,x order
                Hp = np.swapaxes(Hp, 1, 0)
                Hs = np.swapaxes(Hs, 1, 0)

                fHp = self.__blur_image__(Hp, boxcar)
                fHs = self.__blur_image__(Hs, boxcar)

                H = fHs / fHp
                H[Hp &lt; Pthresh] = np.nan

                if plot:
                        plt.figure()
                        plt.imshow(H.T, interpolation=&#39;nearest&#39;)
                        plt.show()
                return H</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ephysiopy.dacq2py" href="index.html">ephysiopy.dacq2py</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ephysiopy.dacq2py.gridcell.SAC" href="#ephysiopy.dacq2py.gridcell.SAC">SAC</a></code></h4>
<ul class="two-column">
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.autoCorr2D" href="#ephysiopy.dacq2py.gridcell.SAC.autoCorr2D">autoCorr2D</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.crossCorr2D" href="#ephysiopy.dacq2py.gridcell.SAC.crossCorr2D">crossCorr2D</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.deformSAC" href="#ephysiopy.dacq2py.gridcell.SAC.deformSAC">deformSAC</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getMeasures" href="#ephysiopy.dacq2py.gridcell.SAC.getMeasures">getMeasures</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getextrema" href="#ephysiopy.dacq2py.gridcell.SAC.getextrema">getextrema</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getgridness" href="#ephysiopy.dacq2py.gridcell.SAC.getgridness">getgridness</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getorientation" href="#ephysiopy.dacq2py.gridcell.SAC.getorientation">getorientation</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.show" href="#ephysiopy.dacq2py.gridcell.SAC.show">show</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.t_win_SAC" href="#ephysiopy.dacq2py.gridcell.SAC.t_win_SAC">t_win_SAC</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>