<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>ephysiopy.dacq2py.dacq2py_util API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ephysiopy.dacq2py.dacq2py_util</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import division
from scipy import signal, stats, ndimage
from datetime import datetime
import os
import re
from glob import glob
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as colors
from matplotlib.patches import Rectangle
import matplotlib.transforms as transforms
from matplotlib.collections import LineCollection
from mpl_toolkits.axes_grid1 import make_axes_locatable
import warnings
from . import axonaIO
from .tetrode_dict import TetrodeDict
from ephysiopy.ephys_generic import binning
from .fieldcalcs import FieldCalcs
from .spikecalcs import SpikeCalcs
from .eegcalcs import EEGCalcs
from .cluster import Kluster
from . import tintcolours as tcols
from .gridcell import SAC
from itertools import combinations
from mpl_toolkits.axes_grid1 import ImageGrid
import skimage, skimage.morphology, skimage.feature
from collections import OrderedDict

warnings.filterwarnings(&#34;ignore&#34;,
                                                message=&#34;divide by zero encountered in int_scalars&#34;)
warnings.filterwarnings(&#34;ignore&#34;,
                                                message=&#34;divide by zero encountered in divide&#34;)
warnings.filterwarnings(&#34;ignore&#34;,
                                                message=&#34;invalid value encountered in divide&#34;)
warnings.filterwarnings(&#34;ignore&#34;,
                                                message=&#34;Casting complex values to real discards the imaginary part&#34;)
class Trial(axonaIO.IO, SAC, dict):
        &#39;&#39;&#39;
        Providesm ethods to plot electrophysiology data acquired using the Axona DACQ recording system
        and methods to extract some measures from that data

        The actual loading of the data is done lazily i.e. only when you ask for
        position data (say plotting the path the animal took in the trial) is the
        position data actually loaded. The class also uses as attibutes several
        instances of subpackages (binning.Ratemap for example) so that the code
        could be made more modular.

        Attributes:
                filename_root : str
                        Absolute location on the filesystem of the set of files without a suffix
                basename : str
                        Basename of the set of files without a suffix (everything after the last trailing slash)
                EEG : dacq2py.axonaIO.EEG class
                        Containing data from .eeg file
                EGF : dacq2py.axonaIO.EEG class
                        Containing data from .egf file
                STM : dacq2py.axonaIO.Stim class
                        Contains stimulation data (timestamps mostly) and header + some additions work done below
                POS : dacq2py.axonaIO.Pos class
                        Contains raw and post-processed position data (xy, dir, speed etc) &amp; header
                TETRODE : extension of Pythons dict class&#34;
                        Each value is an instance of dacq2py.axonaIO.Tetrode. Contains
                        methods to get cluster spike times, cluster indices etc
                posFilter : dict
                        Keys are things like &#39;speed&#39;, &#39;time&#39;; values are n x 2 arrays of range of values *to keep*
                setheader : dict
                        Corresponds to the .set file for the file set. Keys/ values are all strings
                _available_files : list
                        All files matching the filename_root + any valid suffix
                metadata : OrderedDict
                        Some basic info if the file is an *rh one (see _parseMetaData)
                ratemap : dacq2py.binning.Ratemap class instance

        See Also
        --------
        binning
                Basic binning of data, calculation of bin sizes etc
        eegcalcs
                Contains filters, eeg power spectra methods
        spikecalcs
                Temporal measures of spike trains (firing rates etc) and extracting
                parameters from the waveforms and clusters themselves
        fieldcalcs
                Methods for extracting information from 2D ratemaps mostly but also
                contains some statistical tools (information theoretic measures etc)
        gridcellTrial
                Trial inherits from this at the moment. Includes methods for obtaining
                the spatial autocorrelogram (SAC) (and cross-correlogram) and plotting of the
                SAC

        Examples
        --------
        &gt;&gt;&gt; from dacq2py.dacq2py_util import Trial
        &gt;&gt;&gt; T = Trial(r&#39;/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh&#39;)

        &#39;&#39;&#39;

        def __init__(self, filename_root, **kwargs):
                &#34;&#34;&#34;
                Parameters
                ----------
                filename_root: str
                        The absolute filename without any suffix attached
                        i.e. C:\\\Robin\\\mytrial

                        Note that when RH is using this can be just the trial name as the getFullFile method
                        tries to find the trial given the folder layout and the filename - see that method
                        for details

                Returns
                -------
                T : object
                        a dacq2py_util.Trial object

                Examples
                --------
                &gt;&gt;&gt; T = dacq2py_util.Trial(r&#39;/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh&#39;)
                &#34;&#34;&#34;

                # try and intelligently get full filename from just the root
                filename_root = self.getFullFile(filename_root)
                self.basename = os.path.basename(filename_root)
                self.filename_root = filename_root
                self._EEG = None
                self._EGF = None
                self._STM = None
                self._POS = None
                if &#39;volts&#39; in kwargs:
                        useVolts = kwargs[&#39;volts&#39;]
                        self.TETRODE = TetrodeDict(filename_root, volts=useVolts)  # see TETRODE class above
                else:
                        self.TETRODE = TetrodeDict(filename_root)
                self._posFilter = None  # a dict used to filter pos
                self._setheader = None
                self.ratemap = None #becomes binning.RateMap instance - see POS getter property below
                self.spikecalcs = SpikeCalcs()
                self.fieldcalcs = FieldCalcs()
                self._isinteractive = 1
                self._figNum = 1
                self._min_spks = 1
                self._available_files = None
                self._getAvailableFiles()
                self.metadata = OrderedDict()
                self.tetrodes = None
                self.clusters = None
                self.pos_weights = None
                if &#39;cm&#39; in kwargs:
                        self.useCm = kwargs[&#39;cm&#39;]
                else:
                        self.useCm = False
                try:
                        self._parseMetaData()
                except:
                        self.metadata = {&#39;Contents&#39;: &#39;Not an rhayman file&#39;}
                try:
                        self.getTsAndCs()
                except:
                        pass
                self.eeg_file = 1

        def __repr__(self):
                return &#39;{self.__class__.__name__}({self.filename_root})&#39;.format(self=self)

        def hasFiles(self):
                &#39;&#39;&#39;
                Checks for some automated yaml processing (see Dropbox/Science/Analysis/)
                &#39;&#39;&#39;

                for i in self.axona_files.iterkeys():
                        if os.path.isfile(self.filename_root + i):
                                self[&#39;has_&#39; + i[1:]] = True
                        else:
                                self[&#39;has_&#39; + i[1:]] = False

        def getFullFile(self, filename):
                &#39;&#39;&#39;
                Used to constuct filename_root in __init__

                Parameters
                -------------
                filename : str
                        The absolute path the files being analysed here without any suffix
                &#39;&#39;&#39;
                if os.path.isdir(r&#39;/home/robin/Dropbox/Science/Recordings&#39;):
                        pname, fname = os.path.split(filename)
                        if len(pname) == 0:
                                defaultDir = r&#39;/home/robin/Dropbox/Science/Recordings&#39;
                                animal = filename.split(&#39;_&#39;)[0]
                                filename = os.path.join(defaultDir, animal, filename)
                return filename

        @property
        def setheader(self):
                &#39;&#39;&#39;
                Returns
                ----------
                self.dict: dict
                        Matches contents of .set file with keys and values all mapped as strings
                &#39;&#39;&#39;

                if self._setheader is None:
                        try:
                                self._setheader = self.getHeader(self.filename_root + &#39;.set&#39;)
                        except IOError:
                                self._setheader = None
                return self._setheader

        @setheader.setter
        def setheader(self, value):
                self._setheader = value

        @property
        def ppm(self):
                return self.__ppm

        @ppm.setter
        def ppm(self, value):
                self.__ppm = value
                # Update POS
                self.POS.ppm = value
                # Update Ratemap
                self.ratemap = binning.RateMap(self.POS.xy, self.POS.dir, self.POS.speed, self.pos_weights, self.POS.ppm, self.useCm)

        @property
        def POS(self):
                &#39;&#39;&#39;
                Returns
                -----------
                self.POS:
                        Contains raw and post-processed position data
                &#39;&#39;&#39;

                if self._POS is None:
                        try:
                                self._POS = axonaIO.Pos(self.filename_root, cm=self.useCm)
                                self._POS.postprocesspos()
                                self._xlims = (int(self.POS.xy[0,:].min()),
                                                           int(self.POS.xy[0,:].max()))
                                self._ylims = (int(self.POS.xy[1,:].min()),
                                                           int(self.POS.xy[1,:].max()))
                                self.pos_weights = np.ravel(np.ones((1, self.POS.npos), dtype=np.float) / self.POS.pos_sample_rate)
                                self.ratemap = binning.RateMap(self.POS.xy, self.POS.dir, self.POS.speed, self.pos_weights, self.POS.ppm, self.useCm)
                        except IOError:
                                self._POS = None
                return self._POS

        @POS.setter
        def POS(self, value):
                self._POS = value

        @property
        def EEG(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.EEG:
                        eeg data and header
                &#39;&#39;&#39;
                if self._EEG is None:
                        try:
                                self._EEG = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file)
                                self.pos2eegScale = int(self.EEG.sample_rate /
                                                                                self.POS.pos_sample_rate)
                        except IOError:
                                self._EEG = None
                return self._EEG

        @EEG.setter
        def EEG(self, value):
                self._EEG = value

        @property
        def EGF(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.EGF:
                        eeg data and header from .egf file
                &#39;&#39;&#39;
                if self._EGF is None:
                        try:
                                self._EGF = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file, egf=1)
                                self.pos2egfScale = int(self.EGF.sample_rate /
                                                                                self.POS.pos_sample_rate)
                        except IOError:
                                self._EGF = None
                return self._EGF

        @EGF.setter
        def EGF(self, value):
                self._EGF = value

        @property
        def STM(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.Stim:
                        Stimulation data and header + some extras parsed from pos, eeg and set files
                &#39;&#39;&#39;
                if self._STM is None:
                        try:
                                self._STM = axonaIO.Stim(self.filename_root)
                                &#39;&#39;&#39;
                                update the STM dict with some relevant values from the .set file and the headers
                                of the eeg and pos files
                                &#39;&#39;&#39;
                                posHdr = self.getHeader(self.filename_root + &#39;.pos&#39;)
                                eegHdr = self.getHeader(self.filename_root + &#39;.eeg&#39;)
                                self._STM[&#39;posSampRate&#39;] = self.getHeaderVal(posHdr, &#39;sample_rate&#39;)
                                self._STM[&#39;eegSampRate&#39;] = self.getHeaderVal(eegHdr, &#39;sample_rate&#39;)
                                try:
                                        egfHdr = self.getHeader(self.filename_root + &#39;.egf&#39;)
                                        self._STM[&#39;egfSampRate&#39;] = self.getHeaderVal(egfHdr, &#39;sample_rate&#39;)
                                except:
                                        pass
                                stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;]) / int(1000) # get into ms
                                self._STM[&#39;off&#39;] = self._STM[&#39;on&#39;] + int(stim_pwidth)
                                &#34;&#34;&#34;
                                There are a set of key / value pairs in the set file that
                                correspond to the patterns/ protocols specified in the
                                Stimulator menu in DACQ. Extract those items now...
                                There are five possibe &#34;patterns&#34; that can be used in a trial. Those patterns 
                                consist of either &#34;Pause (no stimulation)&#34; or some user-defined stimulation pattern.
                                Whether or not one of the five was used is specified in &#34;stim_patternmask_n&#34; where n 
                                is 1-5. Confusingly in dacqUSB these 5 things are called &#34;Protocols&#34; accessed from
                                the menu Stimulator/Protocols... within that window they are actually called &#34;Phase 1&#34;,
                                &#34;Phase 2&#34; etc. To keep everything in order it&#39;s best to iterate through using a for loop
                                as a dict is not guaranteed to be ordered and I cba to use an OrderedDict.
                                In dacqUSB nomencalture the pattern is actually the stimulation you 
                                want to apply i.e. 10ms pulse every 150ms or whatever. The &#34;pattern&#34; is what is applied
                                within every Phase.
                                &#34;&#34;&#34;
                                # phase_info : a dict for each phase that is active
                                phase_info = {&#39;startTime&#39;: None, &#39;duration&#39;: None, &#39;name&#39;: None, &#39;pulseWidth&#39;: None, &#39;pulsePause&#39;: None};
                                stim_dict = {};
                                stim_patt_dict = {};
                                for k,v in self.setheader.iteritems():
                                        if k.startswith(&#34;stim_patternmask_&#34;):
                                                if (int(v) == 1):
                                                        # get the number of the phase
                                                        phase_num = k[-1]
                                                        stim_dict[&#39;Phase_&#39; + phase_num] = phase_info.copy();
                                        if k.startswith(&#34;stim_patt_&#34;):
                                                stim_patt_dict[k] = v;
                                self.patt_dict = stim_patt_dict
                                for k,v in stim_dict.iteritems():
                                        phase_num = k[-1]
                                        stim_dict[k][&#39;duration&#39;] = int(self.setheader[&#39;stim_patterntimes_&#39; + phase_num])
                                        phase_name = self.setheader[&#39;stim_patternnames_&#39; + phase_num]
                                        stim_dict[k][&#39;name&#39;] = phase_name
                                        if not (phase_name.startswith(&#34;Pause&#34;)):
                                                # find the matching string in the stim_patt_dict
                                                for kk,vv in stim_patt_dict.iteritems():
                                                        split_str = vv.split(&#39;&#34;&#39;);
                                                        patt_name = split_str[1]
                                                        if (patt_name == phase_name):
                                                                ss = split_str[2].split()
                                                                stim_dict[k][&#39;pulseWidth&#39;] = int(ss[0])
                                                                stim_dict[k][&#39;pulsePause&#39;] = int(ss[2])
                                # make the dict ordered by Phase number
                                self.STM[&#39;stim_params&#39;] = OrderedDict(sorted(stim_dict.items()));
                        except IOError:
                                self._STM = None
                return self._STM

        @STM.setter
        def STM(self, value):
                self._STM = value

        @property
        def posFilter(self):
                &#39;&#39;&#39;
                self.posFilter : dict
                        Keys are strings such as &#39;speed&#39;, &#39;time&#39; etc. Values are n x 2 arrays of values *to keep*
                &#39;&#39;&#39;
                return self._posFilter

        @posFilter.setter
        def posFilter(self, value):
                &#34;&#34;&#34;
                Filters data depending on the filter specified in the dictionary value

                Parameters
                ----------
                value : dict
                        Filter dict. Legal keys include: &#39;time&#39;, &#39;dir&#39;, &#39;speed&#39;, &#39;xrange&#39;,
                        &#39;yrange&#39;. If key is &#39;time&#39;, values must be a n x 2 numpy array that 
                        specifies the times to keep in SECONDS. If key is &#39;dir&#39; values must
                        be a two element list/ array that specifies the directions to keep
                        in DEGREES NB the values can be singular strings of either &#39;w&#39;, 
                        &#39;e&#39;, &#39;n&#39; or &#39;s&#39; which filters for a +/-45 degree range around that
                        cardinal direction. If key is &#39;speed&#39; values are a 2 element list/ 
                        array to keep specified in m/s. If key is &#39;xrange&#39; or &#39;yrange&#39; 
                        values are a two element list/ array that specify the x or y values
                        to keep in PIXELS.

                Returns
                -------
                modified dacq2py_util.Trial object: object
                        The Trial object is modified in place and all the relevant 
                        variables are filtered and changed to numpy masked arrays

                Examples
                --------
                &gt;&gt;&gt; import numpy as np
                &gt;&gt;&gt; T = dacq2py_util.Trial(r&#39;D:\M851\M851_140908t1rh&#39;)
                &gt;&gt;&gt; T.posFilter = {&#39;time&#39;: np.array([600,1200])}
                &#34;&#34;&#34;

                # If masked, remove all masks on all aspects of data
                if np.ma.is_masked(self.POS.speed):
                        self.POS.speed.mask = np.ma.nomask
                if np.ma.is_masked(self.POS.dir):
                        self.POS.dir.mask = np.ma.nomask
                if np.ma.is_masked(self.POS.xy):
                        self.POS.xy.mask = np.ma.nomask
                if np.ma.is_masked(self.EEG.eeg):
                        self.EEG.eeg.mask = np.ma.nomask
                if np.ma.is_masked(self.EGF.eeg):
                        self.EGF.eeg.mask = np.ma.nomask
                if np.any(self.EEG.EEGphase):
                        if np.ma.is_masked(self.EEG.EEGphase):
                                self.EEG.EEGphase.mask = np.ma.nomask
                if self.TETRODE:#true if TETRODE dict has entries
                        for tet in self.TETRODE.iterkeys():
                                if np.ma.is_masked(self.TETRODE[tet].waveforms):
                                        self.TETRODE[tet].waveforms.mask = np.ma.nomask
                                        self.TETRODE[tet].spk_ts.mask = np.ma.nomask

                if value is None:
                        return

                idx = self.POS.filterPos(value)
                if self.TETRODE:
                        for tet in self.TETRODE.iterkeys():
                                posSamps = self.TETRODE[tet].getPosSamples()
                                common = np.in1d(posSamps, np.nonzero(idx)[1])
                                # Mask timestamps first as this is a vector, then expand
                                # out the mask array (common)
                                self.TETRODE[tet].spk_ts = np.ma.masked_where(common, self.TETRODE[tet].spk_ts)
                                common = common[:, None, None]
                                common = np.repeat(np.repeat(common, 4, axis=1), 50, axis=-1)
                                self.TETRODE[tet].waveforms = np.ma.masked_where(common, self.TETRODE[tet].waveforms)

                self.POS.speed = np.squeeze(np.ma.masked_where(idx, np.expand_dims(self.POS.speed,0)))
                self.POS.dir = np.squeeze(np.ma.masked_where(idx, np.expand_dims(self.POS.dir,0)))
                posMask = np.squeeze(idx)
                posMask = np.vstack((posMask, posMask))
                self.POS.xy = np.ma.masked_where(posMask, self.POS.xy)
                self.EEG.eeg = np.ma.masked_where(np.repeat(np.squeeze(idx),    self.pos2eegScale), self.EEG.eeg)
                if self.EGF:
                        self.EGF.eeg = np.ma.masked_where(np.repeat(np.squeeze(idx), self.pos2egfScale), self.EGF.eeg)
                if np.any(self.EEG.EEGphase):
                        self.EEG.EEGphase = np.ma.masked_where(np.repeat(np.squeeze(idx), self.pos2eegScale), self.EEG.EEGphase)
                self._posFilter = value

        def print_stim_dict(self):
                &#39;&#39;&#39;
                Prints out keys/ values of STM dict
                &#39;&#39;&#39;
                for k,v in self.STM.iteritems():
                        print(k, v)

        def _filterForStm(self, laser=None):
                &#39;&#39;&#39;
                Cycles through the STM dict and fiters for laser on / off periods and
                applies the filter to the pos and eeg data NB tetrode data not dealt with
                yet

                Parameters
                -------------
                laser : bool
                        Whether to filter for laser stimulation events
                &#39;&#39;&#39;
                if laser is not None:
                        times = [0]
                        phaseType = []
                        for k, d in self.STM[&#39;stim_params&#39;].iteritems():
                                for kk, v in d.iteritems():
                                        if &#39;duration&#39; in kk:
                                                times.append(v)
                                        if &#39;name&#39; in kk:
                                                phaseType.append(v)
                        periods = np.cumsum(times)
                        period_bounds = dict.fromkeys(set(phaseType), [])
                        for pk in period_bounds.keys():
                                bounds = []
                                for k, d in self.STM[&#39;stim_params&#39;].iteritems():
                                        if pk == d[&#39;name&#39;]:
                                                idx = int(k.split(&#39;_&#39;)[1])
                                                bounds.append(periods[idx-1:idx+1])
                                period_bounds[pk] = bounds

                        for k, v in period_bounds.iteritems():
                                if laser == 0:
                                        if &#39;Pause&#39; in k:
                                                self.posFilter = {&#39;time&#39;: np.array(v)}
                                elif laser == 1:
                                        if &#39;Pause&#39; not in k:
                                                self.posFilter = {&#39;time&#39;: np.array(v)}

        def _getAvailableFiles(self):
                self._available_files = glob(self.filename_root + &#39;*&#39;)

        def _getMap(self, tetrode=None, cluster=None, var2bin=&#39;pos&#39;, binsize=3,
                                smooth_sz=5, smooth=True, **kwargs):
                &#39;&#39;&#39;

                Returns the ratemap (smoothed or unsmoothed) for a given tetrode and
                cluster

                Parameters
                ----------
                tetrode : int
                                 the tetrode you want to look at
                cluster : int, 1xn array/ list
                                 a single number or list (or 1xn array) of the clusters to plot
                binsize : int, optional
                                 size of bins. Defaults to 3
                smooth_sz : int
                        the width of the smoothing kernel (see **kwargs for more)
                var2bin : str
                        (Optional) Defaults to &#39;pos&#39;. Which variable to bin. Can be either
                        &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked arrays
                smooth : bool, optional.
                        Defaults to true. Whether to smooth the data or not
                **kwargs : extra arguments include:
                                        &#39;gaussian&#39; - the smoothing kernel used is gaussian in shape
                                        not the default boxcar
                                        &#39;after&#39; - smoothing of the pos and spike maps is done after
                                        spikes are divided by pos
                                        &#39;shuffle&#39; - the time in ms by how much to shift the spikes
                                        by. Used for generated distributions for null hypothesis
                                        testing

                Returns
                -------------
                rmap : np.array
                        The data binned up as requested
                &#39;&#39;&#39;
                if &#39;pos&#39; in var2bin:
                        varType = &#39;xy&#39;
                else:
                        varType = var2bin
                if tetrode is None:
                        idx = np.arange(0, self.POS.npos)
                        mapType = &#39;pos&#39;
                else:
                        idx = self.TETRODE[tetrode].getClustIdx(cluster)
                        mapType = &#39;rate&#39;
                spk_weights = np.bincount(idx, minlength=self.POS.npos)
                if &#39;shuffle&#39; in kwargs.keys():
                        spk_weights = np.roll(spk_weights, int(kwargs[&#39;shuffle&#39;]) * 50) # * 50 to go from seconds into pos_samples
                if np.ma.is_masked(self.POS.xy):
                        mask = ~np.ma.getmask(self.POS.xy[0])
                        pos_weights = mask.astype(np.int)
                        self.ratemap.pos_weights = pos_weights
                        spk_weights[~mask] = 0
                # Update the ratemap instance with arguments fed into this method
                self.ratemap.binsize = binsize
                self.ratemap.smooth_sz = smooth_sz
                if &#39;cmsPerBin&#39; in kwargs:
                        self.ratemap.cmsPerBin = kwargs[&#39;cmsPerBin&#39;]
                if &#39;ppm&#39; in kwargs:
                        self.ratemap.ppm = kwargs[&#39;ppm&#39;]
                rmap = self.ratemap.getMap(spk_weights, varType, mapType, smooth)
                return rmap

        def _getPath(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.POS.xy : np.array
                        The smoothed xy positions filtered appropriately 
                &#39;&#39;&#39;
                if np.ma.is_masked(self.POS.xy):
                        return self.POS.xy[:, ~self.POS.xy.mask[0, :]]
                return self.POS.xy

        def _getDir(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.POS.dir : np.array
                        The smoothed directional data filtered appropriately
                &#39;&#39;&#39;
                if np.ma.is_masked(self.POS.dir):
                        return self.POS.dir[:, ~self.POS.dir.mask[0, :]]
                return self.POS.dir

        def _getFieldLims(self, tetrode, cluster, binsize=3):
                &#39;&#39;&#39;
                Returns a labelled matrix of the ratemap for a given cluster on a given
                tetrode. Binsize can be fractional for smaller bins. Uses anything &gt;
                than the half peak rate to select as a field. Data is heavily smoothed

                Parameters
                ---------------
                tetrode : int
                        The tetrode to examine
                cluster : int
                        The cluster identity

                Returns
                ----------
                labelled ratemap and the x and y edges of the binned data as a 3-tuple 
                &#39;&#39;&#39;
                rmap, (ye, xe) = self._getMap(tetrode, cluster, binsize=binsize)
                rmap[np.isnan(rmap)] = 0.0
                h = int(np.max(rmap.shape) / 2)
                sm_rmap = self.ratemap.blurImage(rmap, h, ftype=&#39;gaussian&#39;)
                thresh = np.max(sm_rmap.ravel()) * 0.2  # select area &gt; 20% of peak
                # do some image processing magic to get region to keep as field
                distance = ndimage.distance_transform_edt(sm_rmap &gt; thresh)
                mask = skimage.feature.peak_local_max(distance, indices=False,
                                                                                          exclude_border=False,
                                                                                          labels=sm_rmap &gt; thresh)
                label = ndimage.label(mask)[0]
                w = skimage.morphology.watershed(-distance, label,
                                                                                 mask=sm_rmap &gt; thresh)
                label = ndimage.label(w)[0]
                return label, xe, ye

        def _getClusterPhaseVals(self, tetrode, cluster):
                &#39;&#39;&#39;
                Returns the phases of the LFP theta a given cluster fired at

                Parameters
                ---------------
                tetrode : int
                        The tetrode to examine
                cluster : int
                        The cluster identity

                Returns
                ----------
                eegphase : np.array
                        The phase of theta a cluster fired at
                &#39;&#39;&#39;
                ts = self.TETRODE[tetrode].getSpkTS()
                ts = ts / (self.TETRODE[tetrode].timebase / self.EEG.sample_rate)
                ts_idx = np.floor(ts[self.TETRODE[tetrode].cut == cluster]).astype(np.int)
                self.EEG.thetaAmpPhase()
                EEGphase = self.EEG.EEGphase[ts_idx]
                return EEGphase

        def _getThetaCycles(self):
                &#39;&#39;&#39;
                Return a tuple of indices into the EEG record that denotes the peaks
                and troughs of theta cycles
                &#39;&#39;&#39;
                if not self.EEG:
                        self.EEG = EEG(self.filename_root)
                sm_eeg = self.EEG.eegfilter()
                df_eeg = np.diff(sm_eeg)
                pts = np.diff((df_eeg &gt; 0).astype(int), 2)
                pts = ((pts == 1).nonzero()[0]).astype(int)
                peaks = pts[sm_eeg[pts] &gt; 0] + 1
                troughs = pts[sm_eeg[pts] &lt; 0] + 2
                return peaks, troughs

        def _getSpikeInCycle(self, peakIdx, spkIdx=None, whichSpk=&#39;first&#39;):
                &#39;&#39;&#39;
                given an array of spike indices into eeg and indices of peaks in the
                smoothed, theta-filtered eeg signal this returns the first spike in the
                cycle
                whichSpk can be &#39;first&#39; or &#39;last&#39;
                &#39;&#39;&#39;
                if &#39;first&#39; in whichSpk:
                        side = &#39;left&#39;
                elif &#39;last&#39; in whichSpk:
                        side = &#39;right&#39;
                peaks, troughs = self._getThetaCycles()
                if spkIdx is None:
                        spkIdx = self.TETRODE[self.tetrode].getSpkTS()
                spk2eeg_idx = (spkIdx / (self.TETRODE[self.tetrode].timebase /
                                           self.EEG.sample_rate)).astype(np.int)
                idx = np.searchsorted(peaks, spk2eeg_idx, side=side)
                uniques, unique_indices = np.unique(idx, return_index=True)
                return spk2eeg_idx[unique_indices]

        def _parseMetaData(self):
                &#39;&#39;&#39;
                Parses the filename (mine has a standard format) to populate some of
                the objects properties (self.animal_id, self.trial_num etc)
                &#39;&#39;&#39;
                pname, fname = os.path.split(self.filename_root)
                self.metadata[&#39;Filename&#39;] = fname
                self.metadata[&#39;Path&#39;] = pname
                if &#39;R&#39; in fname[0]:
                        self.metadata[&#39;Animal&#39;] = &#39;Rat&#39;
                else:
                        self.metadata[&#39;Animal&#39;] = &#39;Mouse&#39;
                self.metadata[&#39;Experimenter&#39;] = fname[-2:]
                self.metadata[&#39;Animal_id&#39;] = fname.rsplit(&#39;_&#39;)[0]
                trial_date = self.setheader[&#39;trial_date&#39;] + &#39;:&#39; + self.setheader[&#39;trial_time&#39;]
                self.metadata[&#39;Trial_date&#39;] = datetime.strptime(trial_date,
                                                                                                                &#39;%A, %d %b %Y:%H:%M:%S&#39;)
                self.metadata[&#39;Trial_num&#39;] = int(fname.rsplit(&#39;t&#39;)[1][0:-2])

        def _set_figure_title(self, fig, tet, clust):
                fig.canvas.set_window_title(&#39;Tetrode: {0} Cluster: {1}&#39;.format(tet, clust))

        def _set_ax_title(self, ax, tet, clust):
                ax.set_title(&#39;Tetrode: {0}\nCluster: {1}&#39;.format(tet, clust))

        def klustakwik(self, d):
                &#34;&#34;&#34;
                Calls two methods below (kluster and getPC) to run klustakwik on
                a given tetrode with nFet number of features (for the PCA)

                Parameters
                ----------
                d : dict
                        Specifies the vector of features to be used in
                        clustering. Each key is the identity of a tetrode (i.e. 1, 2 etc)
                         and the values are the features used to do the clustering for that tetrode (i.e.
                        &#39;PC1&#39;, &#39;PC2&#39;, &#39;Amp&#39; (amplitude) etc
                &#34;&#34;&#34;

                legal_values = [&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;, &#39;PC4&#39;, &#39;Amp&#39;,
                                                &#39;Vt&#39;, &#39;P&#39;, &#39;T&#39;, &#39;tP&#39;, &#39;tT&#39;, &#39;En&#39;, &#39;Ar&#39;]
                reg = re.compile(&#34;.*(PC).*&#34;)  # check for number of principal comps
                # check for any input errors in whole dictionary first
                for i_tetrode in d.keys():
                        for v in d[i_tetrode]:
                                if v not in legal_values:
                                        raise ValueError(&#39;Could not find %s in %s&#39; % (v, legal_values))
                # iterate through features and see what the max principal component is
                for i_tetrode in d.keys():
                        pcs = [m.group(0) for l in d[i_tetrode] for m in [reg.search(l)] if m]
                        waves = self.TETRODE[i_tetrode].waveforms
                        princomp = None
                        if pcs:
                                max_pc = []
                                for pc in pcs:
                                        max_pc.append(int(pc[2]))
                                num_pcs = np.max(max_pc)  # get max number of prin comps
                                princomp = self.TETRODE[i_tetrode].getParam(waves,
                                                                                  param=&#39;PCA&#39;, fet=num_pcs)
                                # Rearrange the output from PCA calc to match the 
                                # number of requested principal components
                                inds2keep = []
                                for m in max_pc:
                                        inds2keep.append(np.arange((m-1)*4, (m)*4))
                                inds2keep = np.hstack(inds2keep)
                                princomp = np.take(princomp, inds2keep, axis=1)
                        out = []
                        for value in d[i_tetrode]:
                                if &#39;PC&#39; not in value:
                                        out.append(self.TETRODE[i_tetrode].getParam(waves, param=value))
                        if princomp is not None:
                                out.append(princomp)
                        out = np.hstack(out)

                        c = Kluster(self.filename_root, i_tetrode, out)
                        c.make_fet()
                        mask = c.get_mask()
                        c.make_fmask(mask)
                        c.kluster()

        def getcoherence(self, tetrode, cluster, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Wrapper for fieldcalcs.coherence - see docs there
                &#34;&#34;&#34;
                smthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=True, **kwargs)

                unsmthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=False, **kwargs)

                return self.fieldcalcs.coherence(smthd[0], unsmthd[0])

        def getkldiv(self, tetrode, cluster, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Wrapper for fieldcalcs.kldiv - see there for explanation
                &#34;&#34;&#34;
                polarMap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=True, **kwargs)
                return self.fieldcalcs.kldiv_dir(polarMap[0])

        def getmrv(self, tetrode, cluster, **kwargs):
                &#39;&#39;&#39;
                Calculate the mean resultant vector length and direction for a given
                cluster/ cell

                A wrapper for statscalcs.Statscalcs.mean_resultant_vector (see
                statscalcs.py)

                Parameters
                ----------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine

                Returns
                ----------
                r : float
                        the mean resultant vector length (range = 0-1)
                th : float
                        the mean resultant vector direction (in radians)
                &#39;&#39;&#39;

                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                angsInRads = np.deg2rad(self.POS.dir[idx])
                from statscalcs import StatsCalcs
                S = StatsCalcs()
                r, th = S.mean_resultant_vector(angsInRads)
                return r, th

        def getcircR(self, tetrode, cluster, **kwargs):
                &#39;&#39;&#39;
                Calculate the mean resultant vector length of circular data
                Unlike getmrv (above) this only returns the vector length. This is
                calculated differently (using complex numbers) but is a) faster, b)
                works with binned data and, c) plays nicer/ easier with shuffles of
                the spike train

                Parameters
                ---------------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine
                **kwargs:
                        Legal values of interest:
                        shuffle: int
                        the number of seconds to shift the spike train

                Returns
                ----------
                r : float
                        the mean resultant vector length (range = 0-1)
                &#39;&#39;&#39;

                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                spk_weights = np.bincount(idx, minlength=self.POS.npos)

                if &#39;shuffle&#39; in kwargs.keys():
                        spk_weights = np.roll(spk_weights, int(kwargs[&#39;shuffle&#39;] * 50))
                inc = (np.pi*2) / 120.0
                h = self.ratemap._RateMap__binData(np.deg2rad(self.POS.dir), np.arange(0, np.pi*2+inc, inc), spk_weights)
                from statscalcs import StatsCalcs
                S = StatsCalcs()
                R = S.circ_r(h[1][0][0:-1], h[0])
                return R

        def getskaggsInfo(self, tetrode, cluster, binsize=3, **kwargs):
                &#39;&#39;&#39;
                Wrapper for fieldcalcs.skaggsInfo see there for docs

                Parameters
                ---------------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine
                binsize : int
                        Size of bins in cms
                Returns
                --------------
                bits per spike : float

                Notes
                -----
                binning could be over any single spatial variable (e.g. location, direction, speed).
                &#39;&#39;&#39;
                ratemap = self._getMap(tetrode, cluster, binsize=binsize, **kwargs)[0]
                dwelltimes = self._getMap(binsize=binsize, **kwargs)[0]
                ratemap, _, dwelltimes = self.ratemap._RateMap__adaptiveMap(ratemap, dwelltimes)
                return self.fieldcalcs.skaggsInfo(ratemap, dwelltimes)

        def getTsAndCs(self, verbose=False):
                &#34;&#34;&#34;
                Prints out the available tetrodes and clusters
                &#34;&#34;&#34;
                cut_files = [(f) for f in glob(self.filename_root + &#39;*&#39;) if &#39;cut&#39; in f]
                m = re.compile(&#39;(.*)_(.*).cut&#39;, re.M|re.I)
                tAndCdict = {}
                if cut_files:
                        for f in cut_files:
                                tet = int(m.match(f).group(2))
                                try:
                                        data = self.getCut(tet)
                                        clusters = list(np.unique(data))
                                        if clusters[0]==0:
                                                clusters.pop(0)
                                                if clusters:
                                                        tAndCdict[tet] = clusters
                                        if verbose:
                                                print(&#39;\nTetrode {0} contains clusters: {1}&#39;.format(tet, clusters))
                                except:
                                        if verbose:
                                                print(&#39;\nTetrode{0} has no cut&#39;.format(tet))
                else:
                        pass
                if tAndCdict:
                        tets = []
                        clusts = []
                        for t,c in tAndCdict.items():
                                for cc in c:
                                        tets.append(str(t))
                                        clusts.append(str(cc))
                        &#39;&#39;&#39;
                        The two fucking stupid lines below are so yaml can
                        serialize the object correctly
                        &#39;&#39;&#39;
                        self.tetrodes = map(int,tets)
                        self.clusters = map(int,clusts)
                        return tAndCdict

        def plotMap(self, tetrode, clusters, ax=None, var2bin=&#39;pos&#39;, *args, **kwargs):
                &#34;&#34;&#34;
                Plots a ratemap for a given tetrode and cluster
                Wrapper for _plotMap() so multiple clusters can be plotted

                Parameters
                ----------
                tetrode : int
                                 the tetrode you want to look at
                cluster : int, 1xn array/ list
                                 a single number or list (or 1xn array) of the clusters to plot
                ax : optional, defaults to None. Which axis to add the plot to; if None
                                        then a new figure window is produced
                **kwargs :
                        extra arguments include:
                        &#39;bar&#39; - for use with directional data to produce a polar
                        histogram plot
                        &#39;add_peak_rate&#39; - bool
                        adds the peak rate (to 2 decimal places) to the figure
                        binsize : int, optional
                                size of bins. Defaults to 3
                        smooth_sz : the width of the smoothing kernel (see **kwargs for more)
                                var2bin: optional, defaults to &#39;pos&#39;. Which variable to bin.
                                Can be either &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked
                                arrays
                        smooth : bool, optional. Defaults to true. Whether to smooth the data or
                                not

                Returns
                -------
                ratemap : numpy.ndarray
                        depending on whether a directional (1d) or positional (2d) map was
                        asked for an ndarray is returned

                Examples
                --------
                &gt;&gt;&gt; T = dacq2py_util.Trial(&#39;M845_141003t1rh&#39;)
                &gt;&gt;&gt; # Plot the ratemap for cluster 1 on tetrode 1
                &gt;&gt;&gt; T.plotMap(1,1)
                &gt;&gt;&gt; # Add the peak rate to the figure window
                &gt;&gt;&gt; T.plotMap(1,1,add_peak_rate=True)
                &gt;&gt;&gt; # Plot the polar map for same cluster
                &gt;&gt;&gt; T.plotMap(1,1,var2bin=&#39;dir&#39;)
                &gt;&gt;&gt; # Plot the unsmoothed dwell map for the trial
                &gt;&gt;&gt; T.plotMap(None,None,smooth=False)
                &#34;&#34;&#34;

                for key in (&#39;var2bin&#39;, &#39;ax&#39;, &#39;binsize&#39;,&#39;smooth_sz&#39;, &#39;smooth&#39;):
                        if key in kwargs:
                                setattr(self, key, kwargs[key])
                if isinstance(clusters, int):
                        setattr(self, &#39;clusters&#39;, [clusters])
                elif isinstance(clusters, list):
                        setattr(self, &#39;clusters&#39;, clusters)
                elif isinstance(clusters, str):
                        if &#39;all&#39; in clusters:
                                tetDict = self.getTsAndCs()
                                setattr(self, &#39;clusters&#39;, tetDict[tetrode])
                clusters = getattr(self, &#39;clusters&#39;, None)
#               var2bin = getattr(self, &#39;var2bin&#39;, &#39;pos&#39;)
                ax = getattr(self, &#39;ax&#39;, None)
                binsize = getattr(self, &#39;binsize&#39;, 3)
                smooth_sz = getattr(self.ratemap, &#39;smooth_sz&#39;, 5)
                smooth = getattr(self, &#39;smooth&#39;, True)

                if len(clusters) == 1:
                        ncols = 1
                        nrows = 1
                elif np.logical_and(len(clusters) &gt; 1, len(clusters) &lt; 6):
                        ncols = len(clusters)
                        nrows = 1
                else:
                        ncols = 5
                        nrows = int(np.floor(len(clusters) / 5) + 1)
                if ax is None:
                        fig = plt.figure()
                        if &#39;dir&#39; in var2bin:
                                ax = fig.add_subplot(nrows, ncols, 1, projection=&#39;polar&#39;)
                        else:
                                ax = fig.add_subplot(nrows, ncols, 1)
                axes_out = []
                if clusters is None:
                        axes = fig.add_subplot(1, 1, 1)
                        ax, ratemap = self._plotMap(None, None, var2bin=var2bin, ax=ax,
                                                  binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        self._set_ax_title(axes, tetrode, clusters)
                        axes_out.append(ax)
                if len(clusters) == 1:
                        cluster = clusters[0]

                        ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin, ax=ax,
                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        axes = ax
#                       # check kwargs to see if we want to add peak rate to axes
                        if &#34;add_peak_rate&#34; in kwargs:
                                if kwargs[&#39;add_peak_rate&#39;]:
                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(ratemap)), (0.9,0.15), \
                                                        xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)


                        self._set_ax_title(axes, tetrode, cluster)
                        axes_out.append(ax)
                else:
                        fig.set_facecolor(&#39;w&#39;)
                        fig.set_frameon(False)
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)
                        for iax, cluster in enumerate(clusters):
                                inax = fig.add_subplot(nrows, ncols, iax+1)
                                ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin,
                                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth,
                                                          ax=inax)
                                self._set_ax_title(inax, tetrode, cluster)
                                axes_out.append(ax)
                return axes_out

        def _plotMap(self, tetrode=None, cluster=None, ax=None, var2bin=&#39;pos&#39;, 
                                binsize=3, smooth_sz=5, smooth=True, **kwargs):
                &#34;&#34;&#34;
                Plots a ratemap for a given tetrode and cluster

                Parameters
                ----------
                tetrode : int
                        the tetrode you want to look at
                cluster : int, 1xn array/ list
                        a single number or list (or 1xn array) of the clusters to plot
                binsize : int, optional
                        size of bins. Defaults to 3
                smooth_sz : int
                        the width of the smoothing kernel (see **kwargs for more)
                var2bin : optional, defaults to &#39;pos&#39;. Which variable to bin.
                        Can be either &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked arrays
                smooth : bool
                        Defaults to true. Whether to smooth the data or not
                ax : matplotlib.axes
                        Defaults to None. Which axis to add the plot to; if None
                        then a new figure window is produced
                **kwargs : various
                        &#39;bar&#39; - for use with directional data to produce a polar
                        histogram plot

                Returns
                -------
                ratemap: ndarray (1d or 2d)
                        depending on whether a directional (1d) or positional (2d) map was
                        asked for an ndarray is returned
                &#34;&#34;&#34;

                rmap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin,
                                                        binsize=binsize, smooth_sz=smooth_sz,
                                                        smooth=smooth, **kwargs)
                if rmap[0].ndim == 1:
                        # polar plot
                        if ax is None:
                                fig = plt.figure()
                                self._set_figure_title(fig, tetrode, cluster)
                                ax = fig.add_subplot(111, projection=&#39;polar&#39;)
                        theta = np.deg2rad(rmap[1][0][1:])
                        ax.clear()
                        ax.plot(theta, rmap[0])
                        ax.set_aspect(&#39;equal&#39;)
                        ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, left=&#39;off&#39;, right=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, labelleft=&#39;off&#39;, labeltop=&#39;off&#39;, labelright=&#39;off&#39;)
                        ax.set_rticks([])
                        # deal with vmin/ vmax in kwargs
                        if &#39;vmax&#39; in kwargs.keys():
                                ax.set_rmax(kwargs[&#39;vmax&#39;])
                        # See if we should add the mean resultant vector (mrv)
                        if &#39;add_mrv&#39; in kwargs.keys():
                                from statscalcs import StatsCalcs
                                S = StatsCalcs()
                                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                                angles = self.POS.dir[idx]
                                print(&#39;len angles: {}&#39;.format(len(angles)))
                                r, th = S.mean_resultant_vector(np.deg2rad(angles))
                                ax.hold(True)
                                print(&#39;r: {}\nth: {}&#39;.format(r,th))
                                ax.plot([th, th],[0, r*np.max(rmap[0])],&#39;r&#39;)
                        ax.set_thetagrids([0, 90, 180, 270])
                        ratemap = rmap[0]

                elif rmap[0].ndim == 2:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                                self._set_figure_title(fig, tetrode, cluster)
                        # mask the ratemap where NaNs occur for plotting purposes
                        ratemap = np.ma.MaskedArray(rmap[0], np.isnan(rmap[0]), copy=True)
                        x, y = np.meshgrid(rmap[1][1][0:-1], rmap[1][0][0:-1][::-1])
                        # deal with vmin/ vmax in kwargs
                        if &#39;vmax&#39; in kwargs.keys():
                                vmax = kwargs[&#39;vmax&#39;]
                        else:
                                vmax = np.max(np.ravel(ratemap))
                        ax.pcolormesh(x, y, ratemap, cmap=cm.jet, edgecolors=&#39;face&#39;, vmax=vmax)
                        ax.axis([x.min(), x.max(), y.min(), y.max()])
                        ax.set_aspect(&#39;equal&#39;)
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)
                        ax.axes.get_xaxis().set_visible(False)
                        ax.axes.get_yaxis().set_visible(False)
                        ax.spines[&#39;right&#39;].set_visible(False)
                        ax.spines[&#39;top&#39;].set_visible(False)
                        ax.spines[&#39;bottom&#39;].set_visible(False)
                        ax.spines[&#39;left&#39;].set_visible(False)
                return ax, ratemap

        def plotPath(self, ax=None, clamp=False, label=False, applyStm=False, **kwargs):
                &#39;&#39;&#39;
                Plots the animals path during a trial. Default is to limit plot range
                to the min/ max of x/y extent of path

                Parameters
                ----------
                ax : matplotlib.Axes
                        The axes to plot into. If none a new figure window is created
                clamp : bool
                        whether the axes are clamped to self._xlims and self._ylims or not
                applyStm : bool
                        Whether to overlay r crosses on the path where the laser events occurred
                &#39;&#39;&#39;
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        fig = plt.gcf()
                fig.set_facecolor(&#39;w&#39;)
                xy = self._getPath()
                ax.plot(xy[0], xy[1], color=[0.8627, 0.8627, 0.8627],**kwargs)
                ax.invert_yaxis()
                if applyStm:
                        stmTS = self.STM.getPosTS()
                        stmXY = xy[:, stmTS.astype(int)]
                        ax.plot(stmXY[0], stmXY[1], &#39;rx&#39;, ms=2)
                if clamp:
                        ax.set_xlim(self._xlims)
                        ax.set_ylim(self._ylims)
                ax.set_aspect(&#39;equal&#39;)
                if not label:
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)

        def plotSpikesOnPath(self, tetrode, clusters, ax=None, clamp=False, **kwargs):
                &#39;&#39;&#39;
                Plots the spikes on the path during a trial for a particular tetrode/
                cluster(s)

                Parameters
                ----------
                tetrode: int
                                the tetrode you want to look at
                cluster : int, 1xn array/ list
                                a single number or list (or 1xn array) of the clusters to plot
                clamp : bool, optional
                                whether to restrict the plot to the self._xlims and self_ylims
                                property
                ax : matplotlib.Axes
                        defaults to None. Which axis to add the plot to.
                        If None a new figure window is produced

                &#39;&#39;&#39;
                if not isinstance(clusters, (np.ndarray, list)):
                        if isinstance(clusters, str):
                                clusters = self.availableClusters
                        else:
                                clusters = [clusters]
                xy = self.POS.xy
                for i, clust in enumerate(clusters):
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        ax.plot(xy[0], xy[1], c=tcols.colours[0], zorder=1)
                        idx = self.TETRODE[tetrode].getClustIdx(clust)
                        # useful to override default colour scheme for publication figures
                        if &#39;mec&#39; in kwargs.keys():
                                mec = kwargs.pop(&#39;mec&#39;)
                        else:
                                mec = tcols.colours[clust]
                        ax.plot(xy[0, idx], xy[1, idx], &#39;s&#39;, c=mec, mec=mec, **kwargs)
                        if clamp:
                                ax.set_xlim(self._xlims)
                                ax.set_ylim(self._ylims)
                        ax.set_aspect(&#39;equal&#39;)
                        ax.invert_yaxis()
                        plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                        plt.setp(ax.get_xticklabels() + ax.get_yticklabels(),
                                         visible=False)
                return ax

        def plotRaster(self, tetrode, clusters, ax=None, dt=(-50, 100), prc_max = 0.5, ms_per_bin=1, histtype=&#39;count&#39;, hist=True, **kwargs):
                &#34;&#34;&#34;
                Wrapper for _plotRaster allowing multiple clusters to be plotted in
                separate figure windows

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : 2-tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                prc_max : float
                        the proportion of firing the cell has to &#39;lose&#39; to count as
                        silent; a float between 0 and 1
                ax - matplotlib.Axes
                        the axes to plot into. If not provided a new figure is created
                ms_per_bin : int
                        The number of milliseconds in each bin of the raster plot
                histtype : str
                        either &#39;count&#39; or &#39;rate&#39; - the resulting histogram plotted above the raster plot will
                        consist of either the counts of spikes in ms_per_bin or the mean rate
                        in ms_per_bin
                &#34;&#34;&#34;
                if isinstance(clusters, int):
                        clusters = [clusters]
                elif isinstance(clusters, str):
                        if &#39;all&#39; in clusters:
                                tetDict = self.getTsAndCs()
                                clusters = tetDict[tetrode]
                for cluster in clusters:
                        # Calculate the stimulation ratio
                        stim_histo = self.getRasterHist(tetrode, cluster, dt=dt, hist=hist)
                        mean_stim_spikes = np.sum(stim_histo, 1)
                        pre_stim_spks = np.mean(mean_stim_spikes[0:50])
                        post_stim_spks = np.mean(mean_stim_spikes[50:60])
                        ratio = (post_stim_spks-pre_stim_spks) / (post_stim_spks+pre_stim_spks)
                        print(&#34;Stimulation ratio = {}&#34;.format(ratio))
                        self._plotRaster(tetrode=tetrode, cluster=cluster, dt=dt,prc_max=prc_max, ax=ax, ms_per_bin=ms_per_bin,histtype=histtype, **kwargs)
                return ratio

        def _plotRaster(self, tetrode, cluster, dt=(-50, 100), prc_max=0.5, ax=None, ms_per_bin=1, histtype=&#39;count&#39;, **kwargs):
                &#34;&#34;&#34;
                Plots a raster plot for a specified tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : 2-tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                prc_max : float
                        the proportion of firing the cell has to &#39;lose&#39; to count as
                        silent; a float between 0 and 1
                ax - matplotlib.Axes
                        the axes to plot into. If not provided a new figure is created
                ms_per_bin : int
                        The number of milliseconds in each bin of the raster plot
                histtype : str
                        either &#39;count&#39; or &#39;rate&#39; - the resulting histogram plotted above the raster plot will
                        consist of either the counts of spikes in ms_per_bin or the mean rate
                        in ms_per_bin
                &#34;&#34;&#34;

                if &#39;x1&#39; in kwargs.keys():
                        x1 = kwargs.pop(&#39;x1&#39;)
                else:
                        x1 = self.TETRODE[tetrode].getClustTS(cluster)
                        x1 = x1 / int(self.TETRODE[tetrode].timebase / 1000.) #in ms
                x1.sort()
                on_good = self.STM.getTS()
                dt = np.array(dt)
                irange = on_good[:, np.newaxis] + dt[np.newaxis, :]
                dts = np.searchsorted(x1, irange)
                y = []
                x = []
                for i, t in enumerate(dts):
                        tmp = x1[t[0]:t[1]] - on_good[i]
                        x.extend(tmp)
                        y.extend(np.repeat(i, len(tmp)))
                if ax is None:
                        fig = plt.figure(figsize=(4.0, 7.0))
                        self._set_figure_title(fig, tetrode, cluster)
                        axScatter = fig.add_subplot(111)
                else:
                        axScatter = ax
                axScatter.scatter(x, y, marker=&#39;.&#39;, s=2, rasterized=False, **kwargs)
                divider = make_axes_locatable(axScatter)
                axScatter.set_xticks((dt[0], 0, dt[1]))
                axScatter.set_xticklabels((str(dt[0]), &#39;0&#39;, str(dt[1])))
                axHistx = divider.append_axes(&#34;top&#34;, 0.95, pad=0.2, sharex=axScatter,
                                                                          transform=axScatter.transAxes)
                scattTrans = transforms.blended_transform_factory(axScatter.transData,
                                                                                                                  axScatter.transAxes)
                stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;])
                axScatter.add_patch(Rectangle((0, 0), width=stim_pwidth/1000., height=1,
                                                        transform=scattTrans,
                                                        color=[0, 0, 1], alpha=0.5))
                histTrans = transforms.blended_transform_factory(axHistx.transData,
                                                                                                                 axHistx.transAxes)
                axHistx.add_patch(Rectangle((0, 0), width=stim_pwidth/1000., height=1,
                                                  transform=histTrans,
                                                  color=[0, 0, 1], alpha=0.5))
                axScatter.set_ylabel(&#39;Laser stimulation events&#39;, labelpad=-18.5)
                axScatter.set_xlabel(&#39;Time to stimulus onset(ms)&#39;)
                nStms = int(self.STM[&#39;num_stm_samples&#39;])
                axScatter.set_ylim(0, nStms)
                # Label only the min and max of the y-axis
                ylabels = axScatter.get_yticklabels()
                for i in range(1, len(ylabels)-1):
                        ylabels[i].set_visible(False)
                yticks = axScatter.get_yticklines()
                for i in range(1, len(yticks)-1):
                        yticks[i].set_visible(False)

                histColor = [192/255.0,192/255.0,192/255.0]
                histX = axHistx.hist(x, bins=np.arange(dt[0], dt[1] + ms_per_bin, ms_per_bin),
                                                         color=histColor, alpha=0.6, range=dt, rasterized=True, histtype=&#39;stepfilled&#39;)
                vals = histX[0]
                bins = histX[1]
                if &#39;rate&#39; in histtype:
                        axHistx.set_ylabel(&#39;Rate&#39;)
                        mn_rate_pre_stim = np.mean(vals[bins[1:] &lt; 0])
                        idx = np.logical_and(bins[1:] &gt; 0, bins[1:] &lt; 10).nonzero()[0]
                        mn_rate_post_stim = np.mean(vals[idx])
                        above_half_idx = idx[(vals[idx] &lt; mn_rate_pre_stim * prc_max).nonzero()[0]]
                        half_pre_rate_ms = bins[above_half_idx[0]]
                        print(&#39;\ntime to {0}% of pre-stimulus rate = {1}ms&#39;.format(*(prc_max * 100, half_pre_rate_ms)))
                        print(&#39;mean pre-laser rate = {0}Hz&#39;.format(mn_rate_pre_stim))
                        print(&#39;mean 10ms post-laser rate = {0}&#39;.format(mn_rate_post_stim))
                else:
                        axHistx.set_ylabel(&#39;Spike count&#39;, labelpad=-2.5)
                plt.setp(axHistx.get_xticklabels(),
                                 visible=False)
                # Label only the min and max of the y-axis
                ylabels = axHistx.get_yticklabels()
                for i in range(1, len(ylabels)-1):
                        ylabels[i].set_visible(False)
                yticks = axHistx.get_yticklines()
                for i in range(1, len(yticks)-1):
                        yticks[i].set_visible(False)
                axHistx.set_xlim(dt)
                axScatter.set_xlim(dt)

                return x,y

        def getRasterHist(self, tetrode, cluster, dt=(-50, 100), hist=True):
                &#39;&#39;&#39;
                Calculates the histogram of the raster of spikes during a series of events

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                hist : bool
                        not sure
                &#39;&#39;&#39;
                x1 = self.TETRODE[tetrode].getClustTS(cluster)
                x1 = x1 / int(self.TETRODE[tetrode].timebase / 1000.) #in ms
                x1.sort()
                on_good = self.STM.getTS()
                dt = np.array(dt)
                irange = on_good[:, np.newaxis] + dt[np.newaxis, :]
                dts = np.searchsorted(x1, irange)
                y = []
                x = []
                for i, t in enumerate(dts):
                        tmp = x1[t[0]:t[1]] - on_good[i]
                        x.extend(tmp)
                        y.extend(np.repeat(i, len(tmp)))

                if hist:
                        nEvents = int(self.STM[&#34;num_stm_samples&#34;])
                        return np.histogram2d(x, y, bins=[np.arange(dt[0],dt[1]+1,1), np.arange(0,nEvents+1, 1)])[0]
                else:
                        return np.histogram(x, bins=np.arange(dt[0],dt[1]+1,1), range=dt)[0]

        def plot_event_EEG(self, eeg_type=&#39;egf&#39;, dt=(-50, 100), plot=True, ax=None, 
                                           evenOnsets=True, **kwargs):
                &#34;&#34;&#34;
                Plots out the eeg record following an &#39;on&#39; event in the log file

                Parameters
                ----------
                eeg_type : str
                        either &#39;eeg&#39; or &#39;egf&#39;
                dt : tuple
                        time to look before and after an onset event
                plot : bool
                        whether to plot the stimulus-triggered-eeg
                ax : matplotlib.axis
                        will plot into this axis if supplied
                        (new figure produced if plot is None and ax is None)
                evenOnsets: bool
                        if True assume there is supposed to be an even 
                        difference between the events in the .stm file. If events are 
                        found that have an uneven difference they are thrown out.
                        NB The difference is calculated from information gleaned from 
                        the trial.STM field. If False this is ignored.
                &#34;&#34;&#34;
                on_good = self.STM.getTS()#timestamps in ms
                &#34;&#34;&#34;
                Check for inter-stimulus time differences to make sure that the large
                majority (99%) of on pulses are regularly spaced - otherwise issue a warning
                &#34;&#34;&#34;
                df = np.diff(np.diff(on_good))
                if np.count_nonzero(df) / float(len(on_good)) * 100 &gt; 1:
                        warnings.warn(&#39;More than 1% of on events differ in size&#39;, UserWarning)
                #check for abnormally large number of stim events and abort
                if len(on_good) &gt; 100000:
                        raise Exception(&#39;Very large number of stimulation events. Aborting plot_event_EEG&#39;)
                #get the eeg data and indices to use
                if &#39;egf&#39; in eeg_type:
                        eeg = self.EGF.eeg
                        on_idx = self.STM.getEGFIdx()
                        eeg_samps_per_ms = self.EGF.sample_rate / 1000.0
                elif &#39;eeg&#39; in eeg_type:
                        eeg = self.EEG.eeg
                        on_idx = self.STM.getEEGIdx()
                        eeg_samps_per_ms = self.EEG.sample_rate / 1000.0

                &#34;&#34;&#34;
                NB the following conditional assumes there is only one phase of the 
                stimulation that actually contains stim events. If there is more than 
                one then the last one will be the one used
                &#34;&#34;&#34;
                df = np.diff(on_good)
                &#34;&#34;&#34;
                keep pulsePause here as used lower down to plot multiple Rectangle
                patches in case the dt tuple specifies a range of values higher than
                the pause between stimulation events
                &#34;&#34;&#34;
                pulsePause = 0
                if evenOnsets:
                        for k, v in self.STM.iteritems():
                                if isinstance(v, OrderedDict):
                                        for kk, vv in v.iteritems():
                                                for kkk, vvv in vv.iteritems():
                                                        if &#39;Pause&#39; in kkk:
                                                                if vvv is not None:
                                                                        pulsePause = vvv
                        pulsePause_ms = pulsePause / 1000#this is the desired
                        unequalPausesIdx = np.nonzero(df!=pulsePause_ms)[0]
                        on_good = np.delete(on_good, unequalPausesIdx)
                        on_idx = np.delete(on_idx, unequalPausesIdx)
                eeg = eeg - np.ma.mean(eeg)
                dt_eeg = eeg_samps_per_ms * np.array(dt)
                rng = np.arange(dt_eeg[0], dt_eeg[1], 1)
                idx = (on_idx[np.newaxis, :] + rng[:, np.newaxis]).astype(int)
                result = np.zeros((len(rng), len(on_good)))
                result = eeg[idx]
                if not plot:
                        return result, idx
                else:
                        mn = np.mean(result, 1)
                        se = np.std(result, 1) / np.sqrt(len(on_good))
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        else:
                                ax = ax
                        ax.errorbar(np.linspace(dt[0], dt[1], len(mn)), mn * 1e6,
                                                yerr=se*1e6, rasterized=False)
                        ax.set_xlim(dt)
                        axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                                   ax.transAxes)
                        stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;])
                        if pulsePause &gt; 0:
                                a = np.arange(0, dt[1], pulsePause_ms)
                                b = np.arange(0, dt[0], -pulsePause_ms)
                                patchStarts = np.unique(np.concatenate((a, b)))
                        for p in patchStarts:
                                ax.add_patch(Rectangle((p, 0), width=stim_pwidth/1000., height=1,
                                                         transform=axTrans,
                                                         color=[1, 1, 0], alpha=0.5))
                        ax.set_ylabel(&#39;LFP ($\mu$V)&#39;)
                        ax.set_xlabel(&#39;Time(ms)&#39;)
                        return result

        def plotEventEEGRange(self, eeg_type=&#39;egf&#39;, stimTrials=[0,1], ax=None, **kwargs):
                &#34;&#34;&#34;
                Calls plot_event_eeg with defaults and no plotting and then plots out
                a time period in seconds from x1 to x2 and overlays the correct time in
                seconds on the x-axis - meant for manual inspection of the effect of
                stimulation events on the eeg

                Parameters
                ------------
                eeg_type : str
                        either &#39;egf&#39; or &#39;eeg&#39; although probably no point
                        using &#39;eeg&#39; as sample rate too low
                stimTrials : list
                        the stimulation &#39;trial&#39; to plot, starting at 0
                        NB stimulating every 150ms for 10ms for 20 minutes gets
                        you 8000 trials
                ax : matplotlib.axis
                        the axis to plot into. A new figure is
                        produced if this is None
                &#34;&#34;&#34;

                result, idx = self.plot_event_EEG(eeg_type=eeg_type, plot=False)
                eeg_samp_rate = self.STM[eeg_type + &#39;SampRate&#39;]
                time_ms = idx / float(eeg_samp_rate / 1000.)
                eeg_blocks = []
                time_blocks = []
                for t in stimTrials:
                        eeg_blocks.append(result[:, t])
                        time_blocks.append(time_ms[:, t])

                speed_idx = (idx / (eeg_samp_rate / self.POS.pos_sample_rate)).astype(int)
                speed = self.POS.speed[0, np.ravel(speed_idx, &#39;F&#39;)]
                max_speed = np.max(speed)
                speed = np.reshape(speed, idx.shape, &#39;F&#39;)
                # filter the eeg data in the theta and gamma bands
                E = EEGCalcs(self.filename_root)
                eeg = self.EGF.eeg
                eeg = eeg - np.ma.mean(eeg)
                sampRate = self.EGF.sample_rate
                theta_eeg = E.filterWithButter(eeg, 4, 8, sampRate, 2)
                gamma_eeg = E.filterWithButter(eeg, 30, 80, sampRate, 2)

                theta = theta_eeg[np.ravel(idx, &#39;F&#39;)]
                theta = np.reshape(theta, idx.shape, &#39;F&#39;)
                gamma = gamma_eeg[np.ravel(idx, &#39;F&#39;)]
                gamma = np.reshape(gamma, idx.shape, &#39;F&#39;)
                #dt is (-50, 150)
                rectStart = int((eeg_samp_rate / 1000.) * 50)
                rectEnd = int((eeg_samp_rate / 1000.) * 60)
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax1 = ax.twinx()
                for block in zip(time_blocks, eeg_blocks, stimTrials):
                        ax.plot(block[0], block[1], color=[0.8627, 0.8627, 0.8627])
                        ax.hold(True)
                        ax.plot(block[0], theta[:, block[2]], &#39;r&#39;)
                        ax.plot(block[0], gamma[:, block[2]], &#39;g&#39;)
                        ax1.plot(block[0], speed[:, block[2]], &#39;y&#39;)
                        ax1.set_ylim(0, np.max(max_speed) * 4)
                        axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                                   ax.transAxes)
                        i = block[0][rectStart]
                        j = block[0][rectEnd] - block[0][rectStart]
                        ax.add_patch(Rectangle((i,0), width=j, height=1,
                                                         transform=axTrans,
                                                         color=[41./256, 161./256, 230./256], alpha=0.5))
                ax.set_xlim(time_blocks[0][0], time_blocks[-1][-1])
                ylabels = ax1.yaxis.get_majorticklabels()
                for i,xxx in enumerate(ylabels):
                        if i &gt; 1:
                                xxx.set_visible(False)
                        else:
                                xxx.set_color(&#39;k&#39;)
                yticks = ax1.yaxis.get_major_ticks()
                for i,xxx in enumerate(yticks):
                        if i &gt; 1:
                                xxx.set_visible(False)

        def adjust_median_speed(self, min_speed=5, plot=True):
                &#39;&#39;&#39;
                Parameters
                ----------
                min_speed : float
                plot : bool
                &#39;&#39;&#39;
                grandMedian = stats.nanmedian(self.POS.speed, 1)
                sortedSpIdx = np.argsort(self.POS.speed)
                sortedSp = np.sort(self.POS.speed)
                indMedian = np.nonzero(sortedSp &gt;= grandMedian)[1][0]
                indFirstOverThresh = np.nonzero(sortedSp &gt;= min_speed)[1][0]
                indLastNotNan = np.nonzero(~np.isnan(sortedSp))[1][-1]
                halfWidth = np.min([indMedian-indFirstOverThresh, indLastNotNan-indMedian])
                if plot:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                        maxSp = sortedSp[0, indLastNotNan]
                        L = sortedSp.shape[1]
                        rect = Rectangle(xy=(0, indMedian-halfWidth), width=maxSp, height=indMedian+halfWidth/2, color=&#39;b&#39;, alpha=0.5)
                        ax.add_patch(rect)
                        ax.plot(sortedSp[0, 0:indLastNotNan], np.arange(indLastNotNan), &#39;k&#39;, lw=2)
                        ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                        ax.set_ylabel(&#39;Cumulative number of samples&#39;)
                        if indLastNotNan != L:
                                ax.plot((0, maxSp), (indLastNotNan+1, indLastNotNan+1), &#39;r-&#39;)
                                ax.plot((0, maxSp), (L, L), &#39;r-&#39;)
                        ax.set_xlim(0, maxSp)
                        ax.set_ylim(0, L)
                        ax.plot((0, maxSp), (indMedian, indMedian), &#39;b&#39;, lw=1)
                        ax.plot((grandMedian, grandMedian), (0, indMedian), &#39;b-&#39;)
                        ax.plot(grandMedian, indMedian, &#39;bo&#39;, ms=12)
                        ax.plot((0, maxSp), (indFirstOverThresh, indFirstOverThresh), &#39;b&#39;, lw=1)
                        ax.plot((min_speed, min_speed), (0, indFirstOverThresh), &#39;b--&#39;)
                        ax.plot(min_speed, indFirstOverThresh, &#39;bo&#39;, ms=12)
                return sortedSpIdx[indMedian-halfWidth:indMedian+halfWidth]

        def plotRateVSpeed(self, tetrode, cluster, minSpeed=0.0, maxSpeed = 40.0, 
                                           sigma=3.0, shuffle=False, nShuffles=100, plot=False, ax=None,
                                           verbose=False, getShuffledData=False, getData=False, **kwargs):
                &#39;&#39;&#39;
                Plots the instantaneous firing rate of a cell against running speed
                Also outputs a couple of measures as with Kropff et al., 2015; the
                Pearsons correlation and the depth of modulation (dom) - see below for
                details

                Parameters
                -------------------
                tetrode : int
                        the tetrode to use
                cluster : int
                        the cluster to use
                minSpeed : float
                        speeds below this value are masked and not used
                maxSpeed : float
                        speeds above this value are masked and not used
                sigma : float
                        the standard deviation of the gaussian used to smooth the spike
                        train
                shuffle : bool, default False
                        Whether to calculate the significance of the speed score or not
                        This is done by calculating the correlation between speed and
                        the shuffled spike train for nShuffles where the shuffles are only allowed with the
                        window (trial_start + minTime) : (trial_end - minTime). Default is
                        30 seconds as with Kropff et al., 2015. Default False
                nShuffles : int
                        How many times to perform the shuffle. Defaults to 100 as with
                        Kropff et al., 2015
                plot : bool
                        Whether to plot output or not. Defaults to False
                &#39;&#39;&#39;

                speed = self.POS.speed.ravel()
                # Calculate histogram to see how much is accounted for in each bin
                if np.nanmax(speed) &lt; maxSpeed:
                        maxSpeed = np.nanmax(speed)
                        if verbose:
                                print(&#39;Capping speed to max in data: {:.2f}&#39;.format(maxSpeed))
                spd_bins = np.arange(minSpeed, maxSpeed, 1.0)
                # Construct the mask
                speed_filt = np.ma.MaskedArray(speed)
                speed_filt = np.ma.masked_where(speed_filt &lt; minSpeed, speed_filt)
                speed_filt = np.ma.masked_where(speed_filt &gt; maxSpeed, speed_filt)
                spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
                spk_sm = np.ma.MaskedArray(spk_sm, mask=np.ma.getmask(speed_filt))

                # res is the basic correlation between running speed and instantaneous
                # firing rate
                res = stats.mstats.pearsonr(spk_sm, speed_filt)
                if shuffle:
                        duration = self.POS.npos / self.POS.pos_sample_rate
                        shuffles = np.linspace(30, duration-30, nShuffles)
                        shuffled_rs = []
                        for time in shuffles:
                                shuffled_spks = self._getTimeSmoothedSpikes(tetrode, cluster, sigma, time)
                                shuffled_rs.append(stats.mstats.pearsonr(shuffled_spks, speed_filt)[0])
                        prob = np.array([.90, .95, .99])
                        qtiles = stats.mstats.mquantiles(shuffled_rs, prob)
                        if verbose:
                                print(&#34;Running speed vs firing rate correlation (PPMC): {0}&#34;.format(res[0]))
                                print(&#34;The {0} percentiles are {1}&#34;.format(prob*100, qtiles))
                spd_dig  = np.digitize(speed_filt, spd_bins, right=True)
                mn_rate = np.array([np.ma.mean(spk_sm[spd_dig==i]) for i in range(0,len(spd_bins))])
                if plot:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        ax.plot(spd_bins, mn_rate * self.POS.pos_sample_rate, &#39;k&#39;)
                        ax.set_xlim(spd_bins[0], spd_bins[-1])
                        ax.set_ylabel(&#34;Firing rate(Hz)&#34;)
                        ax.set_xlabel(&#34;Speed(cm/s)&#34;)
                        ylabels = ax.get_yticklabels()
                        for i in range(1, len(ylabels)-1):
                                ylabels[i].set_visible(False)
                        yticks = ax.get_yticklines()
                        for i in range(1, len(yticks)-1):
                                yticks[i].set_visible(False)
                        xlabels = ax.get_xticklabels()
                        for i in range(1, len(xlabels)-1):
                                xlabels[i].set_visible(False)
                        xticks = ax.get_xticklines()
                        for i in range(1, len(xticks)-1):
                                xticks[i].set_visible(False)
                        ax.spines[&#39;right&#39;].set_visible(False)
                        ax.spines[&#39;top&#39;].set_visible(False)
                        ax.yaxis.set_ticks_position(&#39;left&#39;)
                        ax.xaxis.set_ticks_position(&#39;bottom&#39;)
                        if &#34;add_peak_rate&#34; in kwargs:
                                if kwargs[&#39;add_peak_rate&#39;]:
                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(res[0])), (0.15,0.9), \
                                                        xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

                if getData:
                        return res[0], spd_bins, mn_rate * self.POS.pos_sample_rate
                if getShuffledData:
                        return res[0], shuffled_rs
                else:
                        return res[0]

        def plotRollingCorrRateVSpeed(self, tetrode, cluster, minSpeed=2.0,
                                                                  sigma=3.0, **kwargs):
                &#39;&#39;&#39;
                Plots the rolling correlation of instantaneous firing rate of a given
                cell against running speed

                Parameters
                ----------
                tetrode : int
                cluster : int
                minSpeed : float
                sigma : float
                        The width of the smoothing kernel applied to the spike train to smooth it
                &#39;&#39;&#39;
                speed_filt = self.POS.speed.ravel()
                #filter for low speeds
                lowSpeedIdx = speed_filt &lt; minSpeed
                spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
                windowSize = 50
                runningCorr = np.ones_like(spk_sm)
                for i in range(len(spk_sm)):
                        runningCorr[i] = stats.pearsonr(spk_sm[i:i+windowSize],
                                                                                          speed_filt[i:i+windowSize])[0]
                speed_filt = np.ma.MaskedArray(speed_filt, lowSpeedIdx)
                spk_sm = np.ma.MaskedArray(spk_sm, lowSpeedIdx)
                # mask the running correlation where there is no rate (ie the cell fails
                # to fire)
                new_mask = np.ma.mask_or(lowSpeedIdx, spk_sm==0)
                runningCorr = np.ma.MaskedArray(runningCorr, new_mask)
                fig, ax = plt.subplots()
                fig.subplots_adjust(right=0.75)
                ax2 = ax.twinx()
                ax3 = ax.twinx()
                ax2.spines[&#34;right&#34;].set_position((&#34;axes&#34;, 1.2))
                ax3.set_frame_on(True)
                ax3.patch.set_visible(False)
                for sp in ax.spines.values():
                        sp.set_visible(False)
                ax3.spines[&#34;right&#34;].set_visible(True)

                p1, = ax.plot(speed_filt, &#39;b&#39;)
                p2, = ax2.plot(spk_sm, &#39;r&#39;)
                p3, = ax3.plot(runningCorr, &#39;k&#39;)

                ax.set_xlim(0, len(speed_filt))
                ax.set_ylim(0, np.max(speed_filt))
                ax2.set_ylim(0, np.max(spk_sm))
                ax3.set_ylim(-1, 1)

                ax.set_ylabel(&#39;Speed(cm/s)&#39;)
                ax2.set_ylabel(&#39;Instantaneous firing rate(Hz)&#39;)
                ax3.set_ylabel(&#39;Running correlation&#39;)

                ax.yaxis.label.set_color(p1.get_color())
                ax2.yaxis.label.set_color(p2.get_color())
                ax3.yaxis.label.set_color(p3.get_color())

                tkw = dict(size=4, width=1.5)
                ax.tick_params(axis=&#39;y&#39;, colors=p1.get_color(), **tkw)
                ax2.tick_params(axis=&#39;y&#39;, colors=p2.get_color(), **tkw)
                ax3.tick_params(axis=&#39;y&#39;, colors=p3.get_color(), **tkw)
                ax.tick_params(axis=&#39;x&#39;, **tkw)


        def _getTimeSmoothedSpikes(self, tetrode, cluster, sigma=3.0, shuffle=None):
                &#39;&#39;&#39;
                Returns a spike train the same length as num pos samples that has been
                smoothed in time with a gaussian kernel M in width and standard deviation
                equal to sigma

                Parameters
                --------------
                tetrode : int
                        the tetrode to use
                cluster : int
                        the cluster to use
                sigma : float
                        the standard deviation of the gaussian used to smooth the spike
                        train
                &#39;&#39;&#39;

                x1 = self.TETRODE[tetrode].getClustIdx(cluster)
                spk_sm = self.spikecalcs.smoothSpikePosCount(x1, self.POS.npos, sigma, shuffle)
                return spk_sm

        def plotFreqVSpeed(self, minSp=5, maxSp=50, spStep=5, ax=None, laserFilter=None, **kwargs):
                &#39;&#39;&#39;
                Plots running speed vs eeg frequencies and does linear regression. Also adds position sample histogram
                TODO: filter out negative frequencies - do this as default in EEG class
                Parameters
                ----------
                minSp : int
                        speeds below this are ignored
                maxSp : int
                        speeds above this are ignored
                spStep : int
                        the bin width for speed
                ax : matplotlib.axes
                        the axes in which to plot
                laser : int or None
                        whether to filter for laser on/ off events
                        None means no filtering at all
                        1 means laser is on and data is filtered for on periods
                        0 means filter for laser off periods

                &#39;&#39;&#39;

                sp = np.ma.compressed(self.POS.speed)
                if laserFilter:
                        eeg = self.EEG.eeg
                        EE = EEGCalcs(self.filename_root, thetaRange=[6,12])
                        if &#39;dip&#39; in kwargs:
                                d = kwargs[&#39;dip&#39;]
                        else:
                                d = 15.0
                        if &#39;width&#39; in kwargs:
                                w = kwargs[&#39;width&#39;]
                        else:
                                w = 0.125
                        if &#39;stimFreq&#39; in kwargs:
                                sf = kwargs[&#39;stimFreq&#39;]
                        else:
                                sf = 6.66
                        fx = EE.filterForLaser(E=eeg, width=w, dip=d, stimFreq=sf)#filters out laser stimulation artifact
                        fxx = self.EEG.eegfilter(fx)
                        self.EEG.thetaAmpPhase(fxx)#filters for theta
                        freq = self.EEG.EEGinstfreq
                else:
                        try:
                                freq = self.EEG.EEGinstfreq
                        except:
                                self.EEG.thetaAmpPhase()
                                freq = self.EEG.EEGinstfreq
                freq[freq&lt;0] = np.nan
                sp_bins = np.arange(minSp, maxSp, spStep)
                sp_dig = np.digitize(sp, sp_bins)
                freq = np.reshape(freq, (self.POS.npos, self.EEG.sample_rate/self.POS.pos_sample_rate))
                if np.ma.is_masked(self.POS.speed):
                        mask = np.ma.getmask(self.POS.speed)
                        mask = np.tile(mask.T, self.EEG.sample_rate/self.POS.pos_sample_rate)
                        freq = np.ma.MaskedArray(freq, mask=mask)
                mn_freq = np.nanmean(freq, 1)
                mn_freq = np.ma.compressed(mn_freq)
                X = [mn_freq[sp_dig==i] for i in range(len(sp_bins))]
                # remove any nans which will screw plt.boxplots ability to calculate means
                # and do the boxplot correctly
                for i,x in enumerate(X):
                        idx = ~np.isfinite(x)
                        X[i] = np.delete(x,np.nonzero(idx))
                if ax is None:
                        fig = plt.figure()
                        fig.set_facecolor(&#39;w&#39;)
                        ax = plt.gca()
                else:
                        fig = plt.gcf()
                        fig.set_facecolor(&#39;w&#39;)
                # set up some properties for the elements in the box plot
                bprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                wprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                ax.boxplot(X, positions=sp_bins, boxprops=bprops, whiskerprops=wprops)
                medians = np.array([stats.nanmedian(x) for x in X])
                nan_idx = np.isnan(medians)
                slope, intercept, r_value, p_value, std_err = stats.linregress(sp_bins[~nan_idx], medians[~nan_idx])
                minFreq = np.min(medians[~nan_idx]) - 1.0
                maxFreq = np.max(medians[~nan_idx]) + 1.0
                ax.set_ylim(minFreq, maxFreq)
#        ax.set_xlim(0, sp_bins[-1])
#               ylims = np.array(ax.get_ylim())
                xlims = np.array(ax.get_xlim())
                res = stats.theilslopes(medians[~nan_idx], sp_bins[~nan_idx], 0.90)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[0] * sp_bins[-1])), &#39;r-&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[2] * sp_bins[-1])), &#39;r--&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[3] * sp_bins[-1])), &#39;r--&#39;)
#        ax.plot([0,xlims[1]], (intercept, intercept + (sp_bins[-1] * slope)), &#39;k--&#39;, lw=2)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                ax.set_title(&#39;Intercept: {0:.3f}    Slope: {1:.5f}&#39;.format(intercept, slope))
                # add the right-hand y-axis and format
                ax1 = ax.twinx()
                # get a histogram of speed to be plotted against the right-hand y-axis
                h,e = np.histogram(np.ma.compressed(sp), bins=len(sp_bins)*10, range=(0, sp_bins[-1]))
                ax1.bar(e[0:-1], h, color=[0.6667, 0.6667, 0], linewidth=0, align=&#39;edge&#39;)
                ax1.set_ylim(0, np.max(h) * 4) # reduce the &#39;height&#39; of the secondary plot
#        ax1.set_xlim(0, sp_bins[-1]+spStep)
                ax1.set_ylabel(&#39;Position samples&#39;, color=[0.6667, 0.6667, 0])
                ax1.yaxis.set_label_coords(1.1,.15)
                ylabels = ax1.yaxis.get_majorticklabels()
                for i,xxx in enumerate(ylabels):
                        if i &gt; 1:
                                xxx.set_visible(False)
                        else:
                                xxx.set_color([0.6667, 0.6667, 0])
                yticks = ax1.yaxis.get_major_ticks()
                for i,xxx in enumerate(yticks):
                        if i &gt; 1:
                                xxx.set_visible(False)
                return ax, intercept, slope

        def plotPhaseOfFiring(self, tetrode, cluster, ax=None, **kwargs):
                &#34;&#34;&#34;
                Plots the phase of firing of a given cluster as a histogram

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.Axes
                &#34;&#34;&#34;

                phase = self._getClusterPhaseVals(tetrode, cluster)
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(211)
                        ax2 = fig.add_subplot(212)
                # make the plot like the Somogyi figures!
                fig.set_facecolor(&#39;#203C8A&#39;)
                phase = np.hstack((phase, phase + (2*np.pi)))
                ax2.hist(phase, bins=120, range=(-np.pi, 3*np.pi), color=&#39;w&#39;, histtype=&#39;stepfilled&#39;)
                t = np.arange(-np.pi, 3 * np.pi, 0.1)
                ax.plot(t, np.sin(t), &#39;w&#39;)
                ax.annotate(&#39;180&#39;, xy=(-np.pi-0.2, 0), xycoords=&#39;data&#39;, ha=&#39;right&#39;, va=&#39;center&#39;,
                                        color=&#39;w&#39;, fontsize=20)
                ax.set_axis_bgcolor(&#39;#203C8A&#39;)
                ax.set_ylim(-1.1, 1.1)
                ax.axis(&#39;off&#39;)
                ax2.set_axis_bgcolor(&#39;#203C8A&#39;)
                plt.axis(&#39;off&#39;)

        def plotPhaseInField(self, tetrode, cluster, ax=None, **kwargs):
                &#39;&#39;&#39;
                Plots theta phase of spikes in a place field (found using _getFieldLims)
                as individual colours for each run through the field
                TODO: broken
                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.Axes
                &#39;&#39;&#39;
                if not self.EEG:
                        self.EEG = EEG(self.filename_root)
                self.EEG.thetaAmpPhase()
                self.EEG.EEGphase = np.rad2deg(self.EEG.EEGphase)
                runs_to_keep, spk_in_run, run_duration = self.getFieldRuns(tetrode, cluster)
                if ax is None:
                        ax = plt.gca()
                else:
                        ax = ax
                for spks in spk_in_run:
                        ax.plot(self.POS.xy[0,spks], self.EEG.EEGphase[spks * self.pos2eegScale]+180,&#39;.&#39;)
                ax.set_title(self.filename_root.split(&#39;\\&#39;)[-1] + &#39; cluster &#39; + str(cluster) + &#39; on tetrode &#39; + str(tetrode))
                plt.show()

        def plotSpectrogram(self, eegType=&#39;eeg&#39;, ymin=0, ymax=50, ax=None, secsPerBin=2,
                                                laser=False, width=0.125, dip=15.0):
                &#39;&#39;&#39;
                Plots a spectrogram of the LFP of the whole trial

                Parameters
                --------------
                eegType : str
                        Whether to do use .eeg file or .egf file. Defaults to eeg
                ymin / ymax : int
                        Minimum/ maximum frequency (y-axis) to plot
                ax : matplotlib.pyplot.axis]
                        Which axis to add the plot to. If None a new figure window is produced
                secsPerBin : int
                        Size of the x-axis bins
                laser : bool
                        Whether to filter the eeg for laser stimulation events
                width/ dip : float
                        Parameters for Kaisser filter in eegcalcs.EEGCalcs - see there
                        for definition

                Returns
                ------------
                Plots the spectrogram
                &#39;&#39;&#39;

                if &#39;eeg&#39; in eegType:
                        E = self.EEG.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EEG.sample_rate
                elif &#39;egf&#39; in eegType:
                        E = self.EGF.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EGF.sample_rate

                EE = EEGCalcs(self.filename_root,thetaRange=[6,12])
                if laser:
                        &#39;&#39;&#39;
                        Split the eeg into the parts where the laser is on and off
                        and then reassemble for the spectrogram
                        NB this assumes the laser comes on at 600s for 20 minutes
                        and then goes off
                        &#39;&#39;&#39;
                        mask = np.ones_like(E).astype(bool)

                        mask[600*int(Fs):1800*int(Fs)] = False
                        # filter
#                       import pdb
#                       pdb.set_trace()
                        fx = EE.filterForLaser(E=E[~mask], width=width, dip=dip)
                        # reassemble
                        Etmp = np.zeros_like(E)
                        Etmp[~mask] = fx
                        Etmp[mask] = E[mask]
                        fx = Etmp

                else:
                        fx = E
                nperseg = int(Fs * secsPerBin)
                freqs, times, Sxx = signal.spectrogram(fx, Fs, nperseg=nperseg)
#               Sxx_sm = self.ratemap.blurImage(Sxx, (secsPerBin*2)+1)
                Sxx_sm = Sxx
                x, y = np.meshgrid(times, freqs)
                if ax is None:
                        plt.figure()
                        ax = plt.gca()
                        im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, cmap=&#39;RdBu&#39;,norm=colors.LogNorm())
                im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, norm=colors.LogNorm())
                ax.set_xlim(times[0], times[-1])
                ax.set_ylim(ymin, ymax)
                ax.set_xlabel(&#39;Time(s)&#39;)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                if laser:
                        ax.vlines(600,ymin,ymax)
                        ax.vlines(1800,ymin,ymax)

                        ax.set_xticks((0, 600, 1800, 2400))
                        ax.set_xticklabels((str(0), str(600), str(1800), str(2400)))
                return freqs, times, Sxx, im

        def plotEEGPower(self, E=None, eegType=&#39;eeg&#39;, smthKernelSigma=0.1875,
                                        freqBand=(6,12), outsideBand=(3,125), s2nWdth=2, xmax=125, 
                                        ymax=None, plot=True, ax=None, **kwargs):
                &#39;&#39;&#39;
                Plots the eeg power spectrum. Annotates graph around theta frequency band.

                Parameters
                -------------
                E : numpy.array
                        (Optional) numEEGSamples sized numpy array of raw eeg signal amplitude.
                eegType : str
                        (Optional) Either &#39;eeg&#39; or &#39;egf&#39;. The .eeg file type to use. Defaults to &#39;eeg&#39;
                smthKernelSigma : float
                        (Optional) number of points in the output window for gaussian filtering of eeg. This
                        value is multipled by the binsPerHz which comes from the length of the fft (derived from nextpow2 for speed).
                freqBand : two-tuple
                        (Optional) the theta-band to examine.
                outsideBand : two-tuple
                        (Optional): frequencies outside these values are ignored. NOT IMPLEMENTED.
                s2nWdth : int
                        (Optional) Determines the width of the window to calculate the signal-to-noise ratio.
                xmax : int
                        (Optional) Maximum x-value (frequency) to plot to. Defaults to 125
                ymax : int
                        (Optional) Maximum y-value to plot to. Defaults to None so plots full range
                plot : bool
                        (Optional) Whether to produce a plot
                ax : matplotlib.pyplot.axis instance
                        (Optional) The axis to plot in to.

                Returns
                -------------
                ax : matplotlib.pyplot.axis instance
                        The axis containing the plot.
                &#39;&#39;&#39;

                if E is None:
                        if &#39;eeg&#39; in eegType:
                                E = self.EEG.eeg
                                freqBand = (self.EEG.x1, self.EEG.x2)
                                if np.ma.is_masked(E):
                                        E = E.compressed()
                                sample_rate = self.EEG.sample_rate
                        elif &#39;egf&#39; in eegType:
                                E = self.EGF.eeg
                                freqBand = (self.EEG.x1, self.EEG.x2)
                                if np.ma.is_masked(E):
                                        E = E.compressed()
                                sample_rate = self.EGF.sample_rate
                else:
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        sample_rate = kwargs[&#39;sample_rate&#39;]
                nqLim = 0
                nqLim = sample_rate / 2
                origLength = len(E)
                fftLength = 2 ** self.EEG.nextpow2(origLength).astype(int)
                freqs, power = signal.periodogram(E, fs=sample_rate, return_onesided=True, nfft=fftLength)
                fftHalfLength = fftLength / 2+1
                # calculate the number of points in the gaussian window - gleaned from gaussian_filter1d
                # which lives in scipy/ndimage/filters.py
                binsPerHz = (fftHalfLength-1) / nqLim
                kernelSigma = smthKernelSigma * binsPerHz
                smthKernelWidth = 2 * int(4.0 * kernelSigma + 0.5) + 1
                gaussWin = signal.gaussian(smthKernelWidth, kernelSigma)
                # smooth the power
                sm_power = signal.fftconvolve(power, gaussWin, &#39;same&#39;)
                # normalize the smoothed power by the length of the fft
                sm_power = sm_power / np.sqrt(len(sm_power))
                # calculate some metrics
                spectrumMaskBand = np.logical_and(freqs&gt;freqBand[0], freqs&lt;freqBand[1])
                bandMaxPower = np.max(sm_power[spectrumMaskBand])
                maxBinInBand = np.argmax(sm_power[spectrumMaskBand])
                bandFreqs = freqs[spectrumMaskBand]
                freqAtBandMaxPower = bandFreqs[maxBinInBand]
                # find power in windows around peak, divide by power in rest of spectrum
                # to get SNR
                spectrumMaskPeak = np.logical_and(freqs&gt;freqAtBandMaxPower-s2nWdth/2, freqs &lt; freqAtBandMaxPower + s2nWdth/2)
                snr = np.nanmean(sm_power[spectrumMaskPeak]) / np.nanmean(sm_power[~spectrumMaskPeak])
                # collect all the following keywords into a dict for output
                dictKeys = (&#39;sm_power&#39;,&#39;freqs&#39;, &#39;spectrumMaskPeak&#39;, &#39;power&#39;,&#39;freqBand&#39;,
                &#39;freqAtBandMaxPower&#39;, &#39;bandMaxPower&#39;, &#39;xmax&#39;, &#39;ymax&#39;, &#39;snr&#39;, &#39;kernelSigma&#39;, &#39;binsPerHz&#39;)
                outDict = dict.fromkeys(dictKeys,np.nan)
                for thiskey in outDict.keys():
                        outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
                if plot:
                        if ax is None:
                                plt.figure()
                                ax = plt.gca()
                        ax.plot(freqs, power, alpha=0.5, color=[0.8627, 0.8627, 0.8627])
                        # ax.hold(1)
                        ax.plot(freqs, sm_power)
                        r = Rectangle((freqBand[0],0), width=np.diff(freqBand)[0], height=np.diff(ax.get_ylim())[0], alpha=0.25, color=&#39;r&#39;, ec=&#39;none&#39;)
                        ax.add_patch(r)
                        ax.set_xlim(0,xmax)
                        ax.set_ylim(0, bandMaxPower / 0.8)
                        ax.set_xlabel(&#39;Frequency&#39;)
                        ax.set_ylabel(&#39;Power&#39;)
                        ax.text(x = freqBand[1] / 0.9, y = bandMaxPower, s = str(freqAtBandMaxPower)[0:4], fontsize=20)
                return ax

        def plotClusterSpace(self, tetrode, clusters=None, ax=None, bins=256,**kwargs):
                &#39;&#39;&#39;
                Plots the cluster space for the given tetrode

                Parameters
                ----------
                tetrode : int
                        the tetrode cluster space to plot
                clusters : int or list or np.array
                        the clusters to colour in
                ax : matplotlib.pyplot.axis
                        the axis to plot into
                bins : int
                        the number of bins to use in the histogram
                **kwargs :
                        can include a param keyword for the parameter to construct the
                        histogram from - this defaults to amplitude (&#39;Amp&#39;) but can be any
                        valid key in the getParam method of the Tetrode class

                Returns
                -------
                fig: handle to figure window
                &#39;&#39;&#39;

                if clusters is not None and not isinstance(clusters, (np.ndarray, list)):
                        clusters = [clusters]  # ie needs to be iterable
                waves = self.TETRODE[tetrode].waveforms
                if self.TETRODE[tetrode].volts:
                        waves = (waves * 128) / self.TETRODE[tetrode].scaling[:, np.newaxis]
                        waves = waves.astype(int)
                cutfile = self.TETRODE[tetrode].cut

                if cutfile is not None:
                        cutfile = np.array(cutfile)
                if &#39;param&#39; in kwargs.keys():
                        param = kwargs[&#39;param&#39;]
                else:
                        param = &#39;Amp&#39;
                amps = self.TETRODE[tetrode].getParam(waves, param=param)
                bad_electrodes = np.setdiff1d(np.array(range(4)),np.array(np.sum(amps,0).nonzero())[0])
                cmap = np.tile(tcols.colours[0],(bins,1))
                cmap[0] = (1,1,1)
                cmap = colors.ListedColormap(cmap)
                cmap._init()
                alpha_vals = np.ones(cmap.N+3)
                alpha_vals[0] = 0
                cmap._lut[:,-1] = alpha_vals
                cmb = combinations(range(4),2)
                if &#39;figure&#39; in kwargs.keys():
                        fig = kwargs.pop(&#39;figure&#39;)
                else:
                        fig = plt.figure()
                if ax is None:
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax.axis(&#39;off&#39;)
#        fig = plt.gcf()
                rect = ax.get_position().bounds
                grid = ImageGrid(fig, rect, nrows_ncols= (2,3), axes_pad=0.1)
                if &#39;Amp&#39; in param:
                        myRange = [[0,256],[0,256]]
                else:
                        myRange = None
                for i, c in enumerate(cmb):
                        if c not in bad_electrodes:
                                H = np.histogram2d(amps[:,c[0]], amps[:,c[1]], range = myRange, bins=bins)
                                grid[i].imshow(H[0], cmap=cmap, interpolation=&#39;nearest&#39;)
                                if clusters is not None:
                                        for thisclust in clusters:
                                                if &#39;clustColour&#39; in kwargs.keys():
                                                        clustColour = kwargs[&#39;clustColour&#39;]
                                                else:
                                                        clustColour = tcols.colours[thisclust]
                                                clustidx = (cutfile==thisclust).nonzero()[0]
                                                H = np.histogram2d(amps[clustidx,c[0]],amps[clustidx,c[1]], range=myRange, bins=bins)
                                                H = H[0]
                                                H = signal.convolve2d(H, np.ones((3, 3)), mode=&#39;same&#39;)
                                                clustCMap = np.tile(clustColour,(bins,1))
                                                clustCMap[0] = (1,1,1)
                                                clustCMap = colors.ListedColormap(clustCMap)
                                                clustCMap._init()
                                                clustCMap._lut[:,-1] = alpha_vals
                                                grid[i].imshow(H, cmap=clustCMap, interpolation=&#39;nearest&#39;)
                        s = str(c[0]+1) + &#39; v &#39; + str(c[1]+1)
                        grid[i].text(0.05,0.95, s, va=&#39;top&#39;, ha=&#39;left&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)
                        grid[i].set_xlim([0,bins])
                        grid[i].set_ylim([0,bins])
                        grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                plt.setp([a.get_xticklabels() for a in grid], visible=False)
                plt.setp([a.get_yticklabels() for a in grid], visible=False)
                return fig

        def plotXCorr(self, tetrode, clusters, ax=None, Trange=(-500,500), bins=None, annotate=True, **kwargs):
                &#39;&#39;&#39;
                Plots the temporal autocorrelogram (defaults to +/- 500ms)
                TODO: needs to be able to take in two tetrodes &amp; make sure Trange in ms

                Parameters
                ----------
                tetrode : int
                clusters : int or list
                ax : matplotlib.Axes
                        The axes to plot into. If None a new figure window is created
                TRange : two-tuple
                        The range over which to examine the events. Zero time is the occurance of the event
                bins : int
                        The number of bins to assign the data to
                annotate : bool
                        Whether to add the cluster identities to the figure axis
                **kwargs
                        if &#39;add_peak_rate&#39; is in the kwargs then that is also added to the axes
                &#39;&#39;&#39;
                if isinstance(clusters, (np.ndarray, list, int)):
                        clusters = [clusters]
                if isinstance(tetrode, (np.ndarray, list, int)):
                        tetrode = [tetrode]
                duration = np.diff(Trange)
                if bins is None:
                        bins = 201
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                if len(clusters) == 1:
                        cluster_a = cluster_b = clusters[0]
                elif len(clusters) == 2:
                        cluster_a = clusters[0]
                        cluster_b = clusters[1]
                if len(tetrode) == 1:
                        tetrode_a = tetrode[0]
                        tetrode_b = None
                elif len(tetrode) == 2:
                        tetrode_a = tetrode[0]
                        tetrode_b = tetrode[1]
                Trange = np.array(Trange)
                timebase = self.TETRODE[tetrode_a].timebase
                x1 = self.TETRODE[tetrode_a].getClustTS(cluster_a) / (timebase/1000)
                if tetrode_b is None:
                        if cluster_b is None:
                                x2 = x1
                                cluster_b = cluster_a
                        else:
                                x2 = self.TETRODE[tetrode_a].getClustTS(cluster_b) / (timebase/1000)
                else:
                        x2 = self.TETRODE[tetrode_b].getClustTS(cluster_b) / (timebase/1000)
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                        if cluster_b is not None:
                                x2PosSamp = (x2 / (1000 / self.POS.pos_sample_rate)).astype(int)
                                x2 = x2[np.in1d(x2PosSamp, idx)]
                y = self.spikecalcs.xcorr(x1, x2, Trange=Trange)
                h = ax.hist(y[y != 0], bins=bins, range=Trange, color=&#39;k&#39;, histtype=&#39;stepfilled&#39;)
                ax.set_xlim(Trange)
                if annotate:
                        if cluster_b is None:
                                cond_rate = np.count_nonzero(y == 0) / np.float(duration)
                                ax.text(0.55, .9, &#34;{0:.4}&#34;.format(str(cond_rate)), ha=&#39;center&#39;, va=&#39;center&#39;,
                                                transform=ax.transAxes)
                        else:
                                if np.logical_or((tetrode_a == tetrode_b), tetrode_b is None):
                                        if (cluster_a == cluster_b):
                                                #autocorr being done so get theta modulation
                                                modIdx = self.spikecalcs.thetaModIdx(x1)
                                                ax.set_title(&#39;Cluster {0} vs Cluster {1}\ntheta modulation: {2:.4f}&#39;.format(cluster_a, cluster_b, modIdx))
                                                if &#34;add_peak_rate&#34; in kwargs:
                                                        if kwargs[&#39;add_peak_rate&#39;]:
                                                                ax.annotate(&#39;{:.2f}&#39;.format(np.max(modIdx)), (0.15,0.9), \
                                                                                xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

        #                    ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b) +&#39;\ntheta modulation=&#39; + str(modIdx))
                                else:
                                        ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b))
                ax.set_xlabel(&#39;Time(ms)&#39;)
                ax.set_xticks((Trange[0], 0, Trange[1]))
                ax.set_xticklabels((str(Trange[0]), &#39;0&#39;, str(Trange[1])))
                ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                ax.set_yticklabels(&#39;&#39;)
                ax.spines[&#39;right&#39;].set_visible(False)
                ax.spines[&#39;top&#39;].set_visible(False)
                ax.spines[&#39;left&#39;].set_visible(False)
                ax.xaxis.set_ticks_position(&#39;bottom&#39;)
                return ax, h

        def getThetaModIdx(self, tetrode, cluster):
                &#39;&#39;&#39;
                Calculates the theta modulation index of a clusters autocorrelogram
                as the difference between the first trough and second peak of the
                autocorrelogram (actually the difference over their sum)

                Parameters
                --------------
                tetrode : int
                        The tetrode the cluster is on
                cluster : int
                        The cluster identity
                Returns
                -------------
                thetaModulation : int
                        The depth of theta modulation
                &#39;&#39;&#39;
                x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                thetaMod = self.spikecalcs.thetaModIdx(x1)
                return thetaMod

        def getThetaModIdx2(self, tetrode, cluster):
                &#39;&#39;&#39;
                Wrapper for thetaModIdxV2 in spikecalcs.py

                Parameters
                --------------
                tetrode : int
                        The tetrode the cluster is on
                cluster : int
                        The cluster identity
                Returns
                -------------
                thetaModulation : int
                        The depth of theta modulation
                &#39;&#39;&#39;

                x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                thetaMod = self.spikecalcs.thetaModIdxV2(x1)
                return thetaMod

        def plotWaveforms(self, tetrode, clusters, ax=None, **kwargs):
                &#34;&#34;&#34;
                Plots spike waveforms on all four wires for a given tetrode/ cluster
                The units for the plots are *real* in the sense that the x-axis is in
                ms and the y-axis is in micro-volts. The axes limits are set up so the 
                ratio between the x and y axes is 100

                Parameters
                ----------
                tetrode : int
                clusters : int or list
                ax : matplotlib.Axes
                        the axes to plot into. If None a new figure window is created.
                &#34;&#34;&#34;
                waves = self.TETRODE[tetrode].waveforms
                clust_idx = self.TETRODE[tetrode].cut == clusters
                clust_waves = waves[clust_idx, :, :]
                gains = self.TETRODE[tetrode].gains
                samps_per_spike = int(self.TETRODE[tetrode].header[&#39;samples_per_spike&#39;])
                clust_waves = clust_waves * 1e6 # now in uv
                ADC_scale = int(self.setheader[&#39;ADC_fullscale_mv&#39;])
                axes_scales = (ADC_scale / gains.astype(float)) * 1000 # axes limits in uv
                if ~np.any(clust_idx):
                        return
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        fig = kwargs[&#39;figure&#39;]
                        ax = ax
                ax.axis(&#39;off&#39;)
                rect = ax.get_position().bounds
                x = np.linspace(0, 0.001, samps_per_spike)
                if &#39;clustColour&#39; in kwargs.keys():
                        clustColour = kwargs[&#39;clustColour&#39;]
                else:
                        if clusters is None:
                                clustColour = tcols.colours[0]
                        else:
                                clustColour = tcols.colours[clusters]
                grid = ImageGrid(fig, rect, nrows_ncols= (1, 4), axes_pad=0.1, add_all=True, share_all=True)
                for i in range(4):
                        lc = LineCollection(list(zip(x,y) for y in np.squeeze(clust_waves[:, i, :])))
                        lc.set_rasterized(True)
                        lc.set_color(clustColour)
                        grid[i].add_collection(lc)
                        grid[i].plot(x, np.squeeze(np.mean(clust_waves[:, i, :], 0)), &#39;w-&#39;)
                        grid[i].set_aspect(2.5e-6*(ADC_scale/1000.))
                        grid[i].set_xlim(0, 0.001)
                        grid[i].set_ylim(-axes_scales[i], axes_scales[i])
                        grid[i].set_rasterized(True)
                        grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                        grid[i].text(0.9,0.95, str(i+1), va=&#39;top&#39;, ha=&#39;right&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)

                plt.setp([a.get_xticklabels() for a in grid], visible=False)
                plt.setp([a.get_yticklabels() for a in grid], visible=False)


        def plotSAC(self, tetrode, clusters, ax=None, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Plots the spatial autocorrelogram of the given tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.pyplot.axis
                        plots into this axis
                binsize : int
                        size of bins (cms)

                See Also
                --------
                        plotFullSAC

                &#34;&#34;&#34;
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, **kwargs)[0]
                nodwell = ~np.isfinite(rmap)
                ret = self.autoCorr2D(rmap, nodwell)
                ax.imshow(ret, interpolation=&#39;nearest&#39;, origin=&#39;lower&#39;)
                ax.set_aspect(&#39;equal&#39;)
                plt.setp(ax.get_xticklabels(), visible=False)
                plt.setp(ax.get_yticklabels(), visible=False)
                return ax

        def plotFullSAC(self, tetrode, clusters, ax=None, binsize=3, limit2mask=False, plot=True, **kwargs):
                &#34;&#34;&#34;
                Plots the full SAC ie including the edges and colours the central area in colour
                and the outlying bits (outside the mask area used to calculate gridness) in black and white

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.pyplot.axis
                        plots into this axis
                binsize : int
                        size of bins (cms)

                &#34;&#34;&#34;
                if plot:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                if &#39;step&#39; in kwargs.keys():
                        step = kwargs.pop(&#39;step&#39;)
                else:
                        step = 30
                rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, limit2mask=limit2mask, **kwargs)[0]
                nodwell = np.isnan(rmap)
                ret = self.autoCorr2D(rmap, nodwell)
                dct = self.getMeasures(ret, step=step)
                if &#39;gaussian&#39; in kwargs.keys():
                        kwargs.pop(&#39;gaussian&#39;)
                if plot:
                        print(&#39;\nGridness: {0}\nOrientation: {1}\nScale: {2}&#39;.format(dct[&#39;gridness&#39;], dct[&#39;orientation&#39;], dct[&#39;scale&#39;]))
                        self.show(ret, dct, ax=ax, **kwargs)
                return dct

        def getFieldRuns(self, tetrode, cluster, binsize=3):
                &#39;&#39;&#39;
                Extracts the runs through a place field of a given cluster on a given
                tetrode and returns the indices of the runs that are kept (defaults to
                at least 5 spikes needing to be fired) and the indices of the spikes in
                the run and the duration of each run

                Parameters
                ----------
                tetrode : int
                cluster : int
                binsize : int
                        size of bins (cms)

                Returns
                -------
                data : tuple
                        The runs retained, the spikes in the run and the run duration
                &#39;&#39;&#39;

                # label is a mask of the place field - this could be hijacked to cover the whole track
                label, xe, ye = self._getFieldLims(tetrode, cluster, binsize)
                S = skimage.measure.regionprops(label)
                areas = [s[&#39;area&#39;] for s in S]# get the biggest field
                bigFieldIdx = np.argmax(areas)
                bigFieldProps = S[bigFieldIdx]
                binCoords = bigFieldProps.coords
                min_field_edge = np.min(binCoords[:,1])
                max_field_edge = np.max(binCoords[:,1])
                x_coord_field_min = xe[min_field_edge]
                x_coord_field_max = xe[max_field_edge]
                xy = self._getPath()
                x_field_bool = np.logical_and(xy[0] &gt; x_coord_field_min,
                                                                  xy[0] &lt; x_coord_field_max)
                # find the runs with spikes
                run_indices = x_field_bool.nonzero()
                # get a list of runs
                runs = np.array_split(run_indices[0], np.where(np.diff(run_indices[0])&gt;10)[0]+1)
                # there might be short runs through the field so calculate the min distance
                # across the largest part of the field - done so this method can hopefully
                # account for runs in open fields as well as linear tracks
                ppb = int(self.POS.header[&#39;pixels_per_metre&#39;]) / 100. # pixels per bin
                dist2CrossField = bigFieldProps[&#39;major_axis_length&#39;] * ppb
                # get the spike indices into position data
                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                runs_to_keep = []
                spks_in_run = []
                run_duration = []
                for run in runs:
                        if np.nansum(np.hypot(np.diff(xy[0,run]),np.diff(xy[1,run]))) &gt; (dist2CrossField / 2): # be conservative and take 1/2 dist
                                if np.intersect1d(run, idx).any():
                                        if len(np.intersect1d(run, idx)) &gt; self._min_spks:# if there are &gt;5 spikes keep run
                                                runs_to_keep.append(run)
                                                spks_in_run.append(np.intersect1d(run, idx))
                                                run_duration.append((run[-1] - run[0])/float(self.POS.pos_sample_rate))
                return runs_to_keep, spks_in_run, run_duration

        def tortuosity(self, xy=None):
                &#39;&#39;&#39;
                Parameters
                -----------
                xy - numpy.array
                        2xm matrix of xy positions. Default is None so will use this
                        instances xy array in POS

                Returns
                --------
                tortuosity : float
                        tortuosity index calculated as follows:
                        T = sum(path_segment / segment_straight_line) / n_segments
                        n_segments is the number of one second segments per trial
                &#39;&#39;&#39;

                if xy is None:
                        xy = self._getPath()
                T = np.zeros(int(np.shape(xy)[1]/50))
                idx = 0
                for i in xrange(0, xy.shape[1]-50, 50):
                        straight_line = np.hypot(xy[0,i] - xy[0,i+50], xy[1,i] - xy[1,i+50])
                        path_segment = np.nansum(np.hypot(np.diff(xy[0,i:i+50]),np.diff(xy[1,i:i+50])))
                        T[idx] = path_segment / straight_line
                        idx += 1
                toobigbool = T &gt; 100
                T = np.delete(T, toobigbool.nonzero())
                zerobool = T==0
                T = np.delete(T, zerobool.nonzero())
                T = np.delete(T, np.isinf(T).nonzero())
                T = np.delete(T, np.isnan(T).nonzero())
                return np.sum(T) / len(T)

        def getThigmotaxisIndex(self):
                &#39;&#39;&#39;
                Currently fucked
                Calculates the ratio of time spent in the middle of the environment
                to the amount of time spent in the central part
                &#39;&#39;&#39;
                dwellmap = self._getMap(smooth=False)[0] # unsmoothed dwell map
                # simply calculate the sums in the corners and see if this 
                # goes above some threshold
                corner_sz = 3
                tl = dwellmap[0:corner_sz, 0:corner_sz]
                tr = dwellmap[0:corner_sz, -corner_sz:]
                bl = dwellmap[-corner_sz:, 0:corner_sz]
                br = dwellmap[-corner_sz:, -corner_sz:]
                corner_dwell = np.sum([tl, tr, bl, br])

                if corner_dwell &gt; 20:
                        shape = &#39;square&#39;

                else:
                        shape = &#39;circle&#39;

        def getBorderScore(self, tetrode, cluster, debug=False, **kwargs):
                &#39;&#39;&#39;
                Calculates the border score in a similar way to how the Moser group did
                but can also deal with circular environments as well as square ones

                Wrapper for fieldcalcs getBorderScore - see there for docs

                Parameters
                ----------
                tetrode : int
                cluster : int
                debug : bool

                See Also
                --------
                fieldcalcs.FieldCalcs.getBorderScore
                &#39;&#39;&#39;

                A = self._getMap(tetrode, cluster, **kwargs)[0]
                dwellmap = self._getMap(smooth=None)[0]
                # simply calculate the sums in the corners and see if this
                # goes above some threshold
                corner_sz = 3
                tl = dwellmap[0:corner_sz, 0:corner_sz]
                tr = dwellmap[0:corner_sz, -corner_sz:]
                bl = dwellmap[-corner_sz:, 0:corner_sz]
                br = dwellmap[-corner_sz:, -corner_sz:]
                corner_dwell = np.sum([tl, tr, bl, br])

                A_rows, A_cols = np.shape(A)

                if corner_dwell &gt; 20:
                        shape = &#39;square&#39;
                else:
                        shape = &#39;circle&#39;
                return self.fieldcalcs.getBorderScore(A, shape=shape, debug=debug)

        def plotDirFilteredRmaps(self, tetrode, cluster, maptype=&#39;rmap&#39;, **kwargs):
                &#39;&#39;&#39;
                Plots out directionally filtered ratemaps for the tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                maptype : str
                        Valid values include &#39;rmap&#39;, &#39;polar&#39;, &#39;xcorr&#39;
                &#39;&#39;&#39;
                inc = 8.0
                step = 360/inc
                dirs_st = np.arange(-step/2, 360-(step/2), step)
                dirs_en = np.arange(step/2, 360, step)
                dirs_st[0] = dirs_en[-1]

                if &#39;polar&#39; in maptype:
                        fig, axes = plt.subplots(nrows=3, ncols=3, subplot_kw={&#39;projection&#39;: &#39;polar&#39;})
                else:
                        fig, axes = plt.subplots(nrows=3, ncols=3)
                ax0 = axes[0][0] # top-left
                ax1 = axes[0][1] # top-middle
                ax2 = axes[0][2] # top-right
                ax3 = axes[1][0] # middle-left
                ax4 = axes[1][1] # middle
                ax5 = axes[1][2] # middle-right
                ax6 = axes[2][0] # bottom-left
                ax7 = axes[2][1] # bottom-middle
                ax8 = axes[2][2] # bottom-right

                max_rate = 0
                for d in zip(dirs_st, dirs_en):
                        self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                        if &#39;polar&#39; in maptype:
                                rmap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;)[0]
                        elif &#39;xcorr&#39; in maptype:
                                x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                                rmap = self.spikecalcs.xcorr(x1, x1, Trange=np.array([-500, 500]))
                        else:
                                rmap = self._getMap(tetrode=tetrode, cluster=cluster)[0]
                        if np.nanmax(rmap) &gt; max_rate:
                                max_rate = np.nanmax(rmap)

                from collections import OrderedDict
                dir_rates = OrderedDict.fromkeys(dirs_st, None)

                for d in zip(dirs_st, dirs_en, [ax5,ax2,ax1,ax0,ax3,ax6,ax7,ax8]):
                        self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                        npos = np.count_nonzero(np.ma.compressed(~self.POS.dir.mask))
                        print(&#34;npos = {}&#34;.format(npos))
                        nspikes = np.count_nonzero(np.ma.compressed(~self.TETRODE[tetrode].getClustSpks(cluster).mask[:,0,0]))
                        print(&#34;nspikes = {}&#34;.format(nspikes))
                        dir_rates[d[0]] = nspikes# / (npos/50.0)
                        if &#39;spikes&#39; in maptype:
                                self.plotSpikesOnPath(tetrode, cluster, ax=d[2], markersize=4)
                        elif &#39;rmap&#39; in maptype:
                                self._plotMap(tetrode, cluster, ax=d[2], vmax=max_rate)
                        elif &#39;polar&#39; in maptype:
                                self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=d[2], vmax=max_rate)
                        elif &#39;xcorr&#39; in maptype:
                                self.plotXCorr(tetrode, cluster, ax=d[2])
                                x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                                print(&#34;x1 len = {}&#34;.format(len(x1)))
                                dir_rates[d[0]] = self.spikecalcs.thetaBandMaxFreq(x1)
                                d[2].set_xlabel(&#39;&#39;)
                                d[2].set_title(&#39;&#39;)
                                d[2].set_xticklabels(&#39;&#39;)
                        d[2].set_title(&#34;nspikes = {}&#34;.format(nspikes))
                self.posFilter = None
                if &#39;spikes&#39; in maptype:
                        self.plotSpikesOnPath(tetrode, cluster, ax=ax4)
                elif &#39;rmap&#39; in maptype:
                        self._plotMap(tetrode, cluster, ax=ax4)
                elif &#39;polar&#39; in maptype:
                        self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=ax4)
                elif &#39;xcorr&#39; in maptype:
                        self.plotXCorr(tetrode, cluster, ax=ax4)
                        ax4.set_xlabel(&#39;&#39;)
                        ax4.set_title(&#39;&#39;)
                        ax4.set_xticklabels(&#39;&#39;)
                return dir_rates</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial"><code class="flex name class">
<span>class <span class="ident">Trial</span></span>
<span>(</span><span>filename_root, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Providesm ethods to plot electrophysiology data acquired using the Axona DACQ recording system
and methods to extract some measures from that data</p>
<p>The actual loading of the data is done lazily i.e. only when you ask for
position data (say plotting the path the animal took in the trial) is the
position data actually loaded. The class also uses as attibutes several
instances of subpackages (binning.Ratemap for example) so that the code
could be made more modular.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>filename_root</code></strong> :&ensp;<code>str</code></dt>
<dd>Absolute location on the filesystem of the set of files without a suffix</dd>
<dt><strong><code>basename</code></strong> :&ensp;<code>str</code></dt>
<dd>Basename of the set of files without a suffix (everything after the last trailing slash)</dd>
<dt><strong><code>EEG</code></strong> :&ensp;<code>dacq2py.axonaIO.EEG</code> <code>class</code></dt>
<dd>Containing data from .eeg file</dd>
<dt><strong><code>EGF</code></strong> :&ensp;<code>dacq2py.axonaIO.EEG</code> <code>class</code></dt>
<dd>Containing data from .egf file</dd>
<dt><strong><code>STM</code></strong> :&ensp;<code>dacq2py.axonaIO.Stim</code> <code>class</code></dt>
<dd>Contains stimulation data (timestamps mostly) and header + some additions work done below</dd>
<dt><strong><code>POS</code></strong> :&ensp;<code>dacq2py.axonaIO.Pos</code> <code>class</code></dt>
<dd>Contains raw and post-processed position data (xy, dir, speed etc) &amp; header</dd>
<dt><strong><code>TETRODE</code></strong> :&ensp;<code>extension</code> of <code>Pythons</code> <code>dict</code> <code>class"</code></dt>
<dd>Each value is an instance of dacq2py.axonaIO.Tetrode. Contains
methods to get cluster spike times, cluster indices etc</dd>
<dt><strong><code>posFilter</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keys are things like 'speed', 'time'; values are n x 2 arrays of range of values <em>to keep</em></dd>
<dt><strong><code>setheader</code></strong> :&ensp;<code>dict</code></dt>
<dd>Corresponds to the .set file for the file set. Keys/ values are all strings</dd>
<dt><strong><code>_available_files</code></strong> :&ensp;<code>list</code></dt>
<dd>All files matching the filename_root + any valid suffix</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>OrderedDict</code></dt>
<dd>Some basic info if the file is an *rh one (see _parseMetaData)</dd>
<dt><strong><code>ratemap</code></strong> :&ensp;<code>dacq2py.binning.Ratemap</code> <code>class</code> <code>instance</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>binning Basic binning of data</code>, <code>calculation of bin sizes etc</code>
<code>eegcalcs Contains filters</code>, <code>eeg power spectra methods</code>
<code>spikecalcs Temporal measures of spike trains (firing rates etc) and extracting parameters from the waveforms and clusters themselves</code>
<code>fieldcalcs Methods for extracting information from 2D ratemaps mostly but also contains some statistical tools (information theoretic measures etc)</code>
<code>gridcellTrial Trial inherits from this at the moment. Includes methods for obtaining the spatial autocorrelogram (SAC) (and cross-correlogram) and plotting of the SAC</code></p>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; from dacq2py.dacq2py_util import Trial
&gt;&gt;&gt; T = Trial(r'/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh')
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename_root</code></strong> :&ensp;<code>str</code></dt>
<dd>The absolute filename without any suffix attached
i.e. C:\Robin\mytrial<pre><code>Note that when RH is using this can be just the trial name as the getFullFile method
tries to find the trial given the folder layout and the filename - see that method
for details
</code></pre>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>object</code></dt>
<dd>a dacq2py_util.Trial object</dd>
</dl>
<h2 id="examples_1">Examples</h2>
<pre><code>&gt;&gt;&gt; T = dacq2py_util.Trial(r'/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh')
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Trial(axonaIO.IO, SAC, dict):
        &#39;&#39;&#39;
        Providesm ethods to plot electrophysiology data acquired using the Axona DACQ recording system
        and methods to extract some measures from that data

        The actual loading of the data is done lazily i.e. only when you ask for
        position data (say plotting the path the animal took in the trial) is the
        position data actually loaded. The class also uses as attibutes several
        instances of subpackages (binning.Ratemap for example) so that the code
        could be made more modular.

        Attributes:
                filename_root : str
                        Absolute location on the filesystem of the set of files without a suffix
                basename : str
                        Basename of the set of files without a suffix (everything after the last trailing slash)
                EEG : dacq2py.axonaIO.EEG class
                        Containing data from .eeg file
                EGF : dacq2py.axonaIO.EEG class
                        Containing data from .egf file
                STM : dacq2py.axonaIO.Stim class
                        Contains stimulation data (timestamps mostly) and header + some additions work done below
                POS : dacq2py.axonaIO.Pos class
                        Contains raw and post-processed position data (xy, dir, speed etc) &amp; header
                TETRODE : extension of Pythons dict class&#34;
                        Each value is an instance of dacq2py.axonaIO.Tetrode. Contains
                        methods to get cluster spike times, cluster indices etc
                posFilter : dict
                        Keys are things like &#39;speed&#39;, &#39;time&#39;; values are n x 2 arrays of range of values *to keep*
                setheader : dict
                        Corresponds to the .set file for the file set. Keys/ values are all strings
                _available_files : list
                        All files matching the filename_root + any valid suffix
                metadata : OrderedDict
                        Some basic info if the file is an *rh one (see _parseMetaData)
                ratemap : dacq2py.binning.Ratemap class instance

        See Also
        --------
        binning
                Basic binning of data, calculation of bin sizes etc
        eegcalcs
                Contains filters, eeg power spectra methods
        spikecalcs
                Temporal measures of spike trains (firing rates etc) and extracting
                parameters from the waveforms and clusters themselves
        fieldcalcs
                Methods for extracting information from 2D ratemaps mostly but also
                contains some statistical tools (information theoretic measures etc)
        gridcellTrial
                Trial inherits from this at the moment. Includes methods for obtaining
                the spatial autocorrelogram (SAC) (and cross-correlogram) and plotting of the
                SAC

        Examples
        --------
        &gt;&gt;&gt; from dacq2py.dacq2py_util import Trial
        &gt;&gt;&gt; T = Trial(r&#39;/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh&#39;)

        &#39;&#39;&#39;

        def __init__(self, filename_root, **kwargs):
                &#34;&#34;&#34;
                Parameters
                ----------
                filename_root: str
                        The absolute filename without any suffix attached
                        i.e. C:\\\Robin\\\mytrial

                        Note that when RH is using this can be just the trial name as the getFullFile method
                        tries to find the trial given the folder layout and the filename - see that method
                        for details

                Returns
                -------
                T : object
                        a dacq2py_util.Trial object

                Examples
                --------
                &gt;&gt;&gt; T = dacq2py_util.Trial(r&#39;/media/robin/data/Dropbox/Science/Recordings/M851/M851_140908t1rh&#39;)
                &#34;&#34;&#34;

                # try and intelligently get full filename from just the root
                filename_root = self.getFullFile(filename_root)
                self.basename = os.path.basename(filename_root)
                self.filename_root = filename_root
                self._EEG = None
                self._EGF = None
                self._STM = None
                self._POS = None
                if &#39;volts&#39; in kwargs:
                        useVolts = kwargs[&#39;volts&#39;]
                        self.TETRODE = TetrodeDict(filename_root, volts=useVolts)  # see TETRODE class above
                else:
                        self.TETRODE = TetrodeDict(filename_root)
                self._posFilter = None  # a dict used to filter pos
                self._setheader = None
                self.ratemap = None #becomes binning.RateMap instance - see POS getter property below
                self.spikecalcs = SpikeCalcs()
                self.fieldcalcs = FieldCalcs()
                self._isinteractive = 1
                self._figNum = 1
                self._min_spks = 1
                self._available_files = None
                self._getAvailableFiles()
                self.metadata = OrderedDict()
                self.tetrodes = None
                self.clusters = None
                self.pos_weights = None
                if &#39;cm&#39; in kwargs:
                        self.useCm = kwargs[&#39;cm&#39;]
                else:
                        self.useCm = False
                try:
                        self._parseMetaData()
                except:
                        self.metadata = {&#39;Contents&#39;: &#39;Not an rhayman file&#39;}
                try:
                        self.getTsAndCs()
                except:
                        pass
                self.eeg_file = 1

        def __repr__(self):
                return &#39;{self.__class__.__name__}({self.filename_root})&#39;.format(self=self)

        def hasFiles(self):
                &#39;&#39;&#39;
                Checks for some automated yaml processing (see Dropbox/Science/Analysis/)
                &#39;&#39;&#39;

                for i in self.axona_files.iterkeys():
                        if os.path.isfile(self.filename_root + i):
                                self[&#39;has_&#39; + i[1:]] = True
                        else:
                                self[&#39;has_&#39; + i[1:]] = False

        def getFullFile(self, filename):
                &#39;&#39;&#39;
                Used to constuct filename_root in __init__

                Parameters
                -------------
                filename : str
                        The absolute path the files being analysed here without any suffix
                &#39;&#39;&#39;
                if os.path.isdir(r&#39;/home/robin/Dropbox/Science/Recordings&#39;):
                        pname, fname = os.path.split(filename)
                        if len(pname) == 0:
                                defaultDir = r&#39;/home/robin/Dropbox/Science/Recordings&#39;
                                animal = filename.split(&#39;_&#39;)[0]
                                filename = os.path.join(defaultDir, animal, filename)
                return filename

        @property
        def setheader(self):
                &#39;&#39;&#39;
                Returns
                ----------
                self.dict: dict
                        Matches contents of .set file with keys and values all mapped as strings
                &#39;&#39;&#39;

                if self._setheader is None:
                        try:
                                self._setheader = self.getHeader(self.filename_root + &#39;.set&#39;)
                        except IOError:
                                self._setheader = None
                return self._setheader

        @setheader.setter
        def setheader(self, value):
                self._setheader = value

        @property
        def ppm(self):
                return self.__ppm

        @ppm.setter
        def ppm(self, value):
                self.__ppm = value
                # Update POS
                self.POS.ppm = value
                # Update Ratemap
                self.ratemap = binning.RateMap(self.POS.xy, self.POS.dir, self.POS.speed, self.pos_weights, self.POS.ppm, self.useCm)

        @property
        def POS(self):
                &#39;&#39;&#39;
                Returns
                -----------
                self.POS:
                        Contains raw and post-processed position data
                &#39;&#39;&#39;

                if self._POS is None:
                        try:
                                self._POS = axonaIO.Pos(self.filename_root, cm=self.useCm)
                                self._POS.postprocesspos()
                                self._xlims = (int(self.POS.xy[0,:].min()),
                                                           int(self.POS.xy[0,:].max()))
                                self._ylims = (int(self.POS.xy[1,:].min()),
                                                           int(self.POS.xy[1,:].max()))
                                self.pos_weights = np.ravel(np.ones((1, self.POS.npos), dtype=np.float) / self.POS.pos_sample_rate)
                                self.ratemap = binning.RateMap(self.POS.xy, self.POS.dir, self.POS.speed, self.pos_weights, self.POS.ppm, self.useCm)
                        except IOError:
                                self._POS = None
                return self._POS

        @POS.setter
        def POS(self, value):
                self._POS = value

        @property
        def EEG(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.EEG:
                        eeg data and header
                &#39;&#39;&#39;
                if self._EEG is None:
                        try:
                                self._EEG = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file)
                                self.pos2eegScale = int(self.EEG.sample_rate /
                                                                                self.POS.pos_sample_rate)
                        except IOError:
                                self._EEG = None
                return self._EEG

        @EEG.setter
        def EEG(self, value):
                self._EEG = value

        @property
        def EGF(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.EGF:
                        eeg data and header from .egf file
                &#39;&#39;&#39;
                if self._EGF is None:
                        try:
                                self._EGF = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file, egf=1)
                                self.pos2egfScale = int(self.EGF.sample_rate /
                                                                                self.POS.pos_sample_rate)
                        except IOError:
                                self._EGF = None
                return self._EGF

        @EGF.setter
        def EGF(self, value):
                self._EGF = value

        @property
        def STM(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.Stim:
                        Stimulation data and header + some extras parsed from pos, eeg and set files
                &#39;&#39;&#39;
                if self._STM is None:
                        try:
                                self._STM = axonaIO.Stim(self.filename_root)
                                &#39;&#39;&#39;
                                update the STM dict with some relevant values from the .set file and the headers
                                of the eeg and pos files
                                &#39;&#39;&#39;
                                posHdr = self.getHeader(self.filename_root + &#39;.pos&#39;)
                                eegHdr = self.getHeader(self.filename_root + &#39;.eeg&#39;)
                                self._STM[&#39;posSampRate&#39;] = self.getHeaderVal(posHdr, &#39;sample_rate&#39;)
                                self._STM[&#39;eegSampRate&#39;] = self.getHeaderVal(eegHdr, &#39;sample_rate&#39;)
                                try:
                                        egfHdr = self.getHeader(self.filename_root + &#39;.egf&#39;)
                                        self._STM[&#39;egfSampRate&#39;] = self.getHeaderVal(egfHdr, &#39;sample_rate&#39;)
                                except:
                                        pass
                                stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;]) / int(1000) # get into ms
                                self._STM[&#39;off&#39;] = self._STM[&#39;on&#39;] + int(stim_pwidth)
                                &#34;&#34;&#34;
                                There are a set of key / value pairs in the set file that
                                correspond to the patterns/ protocols specified in the
                                Stimulator menu in DACQ. Extract those items now...
                                There are five possibe &#34;patterns&#34; that can be used in a trial. Those patterns 
                                consist of either &#34;Pause (no stimulation)&#34; or some user-defined stimulation pattern.
                                Whether or not one of the five was used is specified in &#34;stim_patternmask_n&#34; where n 
                                is 1-5. Confusingly in dacqUSB these 5 things are called &#34;Protocols&#34; accessed from
                                the menu Stimulator/Protocols... within that window they are actually called &#34;Phase 1&#34;,
                                &#34;Phase 2&#34; etc. To keep everything in order it&#39;s best to iterate through using a for loop
                                as a dict is not guaranteed to be ordered and I cba to use an OrderedDict.
                                In dacqUSB nomencalture the pattern is actually the stimulation you 
                                want to apply i.e. 10ms pulse every 150ms or whatever. The &#34;pattern&#34; is what is applied
                                within every Phase.
                                &#34;&#34;&#34;
                                # phase_info : a dict for each phase that is active
                                phase_info = {&#39;startTime&#39;: None, &#39;duration&#39;: None, &#39;name&#39;: None, &#39;pulseWidth&#39;: None, &#39;pulsePause&#39;: None};
                                stim_dict = {};
                                stim_patt_dict = {};
                                for k,v in self.setheader.iteritems():
                                        if k.startswith(&#34;stim_patternmask_&#34;):
                                                if (int(v) == 1):
                                                        # get the number of the phase
                                                        phase_num = k[-1]
                                                        stim_dict[&#39;Phase_&#39; + phase_num] = phase_info.copy();
                                        if k.startswith(&#34;stim_patt_&#34;):
                                                stim_patt_dict[k] = v;
                                self.patt_dict = stim_patt_dict
                                for k,v in stim_dict.iteritems():
                                        phase_num = k[-1]
                                        stim_dict[k][&#39;duration&#39;] = int(self.setheader[&#39;stim_patterntimes_&#39; + phase_num])
                                        phase_name = self.setheader[&#39;stim_patternnames_&#39; + phase_num]
                                        stim_dict[k][&#39;name&#39;] = phase_name
                                        if not (phase_name.startswith(&#34;Pause&#34;)):
                                                # find the matching string in the stim_patt_dict
                                                for kk,vv in stim_patt_dict.iteritems():
                                                        split_str = vv.split(&#39;&#34;&#39;);
                                                        patt_name = split_str[1]
                                                        if (patt_name == phase_name):
                                                                ss = split_str[2].split()
                                                                stim_dict[k][&#39;pulseWidth&#39;] = int(ss[0])
                                                                stim_dict[k][&#39;pulsePause&#39;] = int(ss[2])
                                # make the dict ordered by Phase number
                                self.STM[&#39;stim_params&#39;] = OrderedDict(sorted(stim_dict.items()));
                        except IOError:
                                self._STM = None
                return self._STM

        @STM.setter
        def STM(self, value):
                self._STM = value

        @property
        def posFilter(self):
                &#39;&#39;&#39;
                self.posFilter : dict
                        Keys are strings such as &#39;speed&#39;, &#39;time&#39; etc. Values are n x 2 arrays of values *to keep*
                &#39;&#39;&#39;
                return self._posFilter

        @posFilter.setter
        def posFilter(self, value):
                &#34;&#34;&#34;
                Filters data depending on the filter specified in the dictionary value

                Parameters
                ----------
                value : dict
                        Filter dict. Legal keys include: &#39;time&#39;, &#39;dir&#39;, &#39;speed&#39;, &#39;xrange&#39;,
                        &#39;yrange&#39;. If key is &#39;time&#39;, values must be a n x 2 numpy array that 
                        specifies the times to keep in SECONDS. If key is &#39;dir&#39; values must
                        be a two element list/ array that specifies the directions to keep
                        in DEGREES NB the values can be singular strings of either &#39;w&#39;, 
                        &#39;e&#39;, &#39;n&#39; or &#39;s&#39; which filters for a +/-45 degree range around that
                        cardinal direction. If key is &#39;speed&#39; values are a 2 element list/ 
                        array to keep specified in m/s. If key is &#39;xrange&#39; or &#39;yrange&#39; 
                        values are a two element list/ array that specify the x or y values
                        to keep in PIXELS.

                Returns
                -------
                modified dacq2py_util.Trial object: object
                        The Trial object is modified in place and all the relevant 
                        variables are filtered and changed to numpy masked arrays

                Examples
                --------
                &gt;&gt;&gt; import numpy as np
                &gt;&gt;&gt; T = dacq2py_util.Trial(r&#39;D:\M851\M851_140908t1rh&#39;)
                &gt;&gt;&gt; T.posFilter = {&#39;time&#39;: np.array([600,1200])}
                &#34;&#34;&#34;

                # If masked, remove all masks on all aspects of data
                if np.ma.is_masked(self.POS.speed):
                        self.POS.speed.mask = np.ma.nomask
                if np.ma.is_masked(self.POS.dir):
                        self.POS.dir.mask = np.ma.nomask
                if np.ma.is_masked(self.POS.xy):
                        self.POS.xy.mask = np.ma.nomask
                if np.ma.is_masked(self.EEG.eeg):
                        self.EEG.eeg.mask = np.ma.nomask
                if np.ma.is_masked(self.EGF.eeg):
                        self.EGF.eeg.mask = np.ma.nomask
                if np.any(self.EEG.EEGphase):
                        if np.ma.is_masked(self.EEG.EEGphase):
                                self.EEG.EEGphase.mask = np.ma.nomask
                if self.TETRODE:#true if TETRODE dict has entries
                        for tet in self.TETRODE.iterkeys():
                                if np.ma.is_masked(self.TETRODE[tet].waveforms):
                                        self.TETRODE[tet].waveforms.mask = np.ma.nomask
                                        self.TETRODE[tet].spk_ts.mask = np.ma.nomask

                if value is None:
                        return

                idx = self.POS.filterPos(value)
                if self.TETRODE:
                        for tet in self.TETRODE.iterkeys():
                                posSamps = self.TETRODE[tet].getPosSamples()
                                common = np.in1d(posSamps, np.nonzero(idx)[1])
                                # Mask timestamps first as this is a vector, then expand
                                # out the mask array (common)
                                self.TETRODE[tet].spk_ts = np.ma.masked_where(common, self.TETRODE[tet].spk_ts)
                                common = common[:, None, None]
                                common = np.repeat(np.repeat(common, 4, axis=1), 50, axis=-1)
                                self.TETRODE[tet].waveforms = np.ma.masked_where(common, self.TETRODE[tet].waveforms)

                self.POS.speed = np.squeeze(np.ma.masked_where(idx, np.expand_dims(self.POS.speed,0)))
                self.POS.dir = np.squeeze(np.ma.masked_where(idx, np.expand_dims(self.POS.dir,0)))
                posMask = np.squeeze(idx)
                posMask = np.vstack((posMask, posMask))
                self.POS.xy = np.ma.masked_where(posMask, self.POS.xy)
                self.EEG.eeg = np.ma.masked_where(np.repeat(np.squeeze(idx),    self.pos2eegScale), self.EEG.eeg)
                if self.EGF:
                        self.EGF.eeg = np.ma.masked_where(np.repeat(np.squeeze(idx), self.pos2egfScale), self.EGF.eeg)
                if np.any(self.EEG.EEGphase):
                        self.EEG.EEGphase = np.ma.masked_where(np.repeat(np.squeeze(idx), self.pos2eegScale), self.EEG.EEGphase)
                self._posFilter = value

        def print_stim_dict(self):
                &#39;&#39;&#39;
                Prints out keys/ values of STM dict
                &#39;&#39;&#39;
                for k,v in self.STM.iteritems():
                        print(k, v)

        def _filterForStm(self, laser=None):
                &#39;&#39;&#39;
                Cycles through the STM dict and fiters for laser on / off periods and
                applies the filter to the pos and eeg data NB tetrode data not dealt with
                yet

                Parameters
                -------------
                laser : bool
                        Whether to filter for laser stimulation events
                &#39;&#39;&#39;
                if laser is not None:
                        times = [0]
                        phaseType = []
                        for k, d in self.STM[&#39;stim_params&#39;].iteritems():
                                for kk, v in d.iteritems():
                                        if &#39;duration&#39; in kk:
                                                times.append(v)
                                        if &#39;name&#39; in kk:
                                                phaseType.append(v)
                        periods = np.cumsum(times)
                        period_bounds = dict.fromkeys(set(phaseType), [])
                        for pk in period_bounds.keys():
                                bounds = []
                                for k, d in self.STM[&#39;stim_params&#39;].iteritems():
                                        if pk == d[&#39;name&#39;]:
                                                idx = int(k.split(&#39;_&#39;)[1])
                                                bounds.append(periods[idx-1:idx+1])
                                period_bounds[pk] = bounds

                        for k, v in period_bounds.iteritems():
                                if laser == 0:
                                        if &#39;Pause&#39; in k:
                                                self.posFilter = {&#39;time&#39;: np.array(v)}
                                elif laser == 1:
                                        if &#39;Pause&#39; not in k:
                                                self.posFilter = {&#39;time&#39;: np.array(v)}

        def _getAvailableFiles(self):
                self._available_files = glob(self.filename_root + &#39;*&#39;)

        def _getMap(self, tetrode=None, cluster=None, var2bin=&#39;pos&#39;, binsize=3,
                                smooth_sz=5, smooth=True, **kwargs):
                &#39;&#39;&#39;

                Returns the ratemap (smoothed or unsmoothed) for a given tetrode and
                cluster

                Parameters
                ----------
                tetrode : int
                                 the tetrode you want to look at
                cluster : int, 1xn array/ list
                                 a single number or list (or 1xn array) of the clusters to plot
                binsize : int, optional
                                 size of bins. Defaults to 3
                smooth_sz : int
                        the width of the smoothing kernel (see **kwargs for more)
                var2bin : str
                        (Optional) Defaults to &#39;pos&#39;. Which variable to bin. Can be either
                        &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked arrays
                smooth : bool, optional.
                        Defaults to true. Whether to smooth the data or not
                **kwargs : extra arguments include:
                                        &#39;gaussian&#39; - the smoothing kernel used is gaussian in shape
                                        not the default boxcar
                                        &#39;after&#39; - smoothing of the pos and spike maps is done after
                                        spikes are divided by pos
                                        &#39;shuffle&#39; - the time in ms by how much to shift the spikes
                                        by. Used for generated distributions for null hypothesis
                                        testing

                Returns
                -------------
                rmap : np.array
                        The data binned up as requested
                &#39;&#39;&#39;
                if &#39;pos&#39; in var2bin:
                        varType = &#39;xy&#39;
                else:
                        varType = var2bin
                if tetrode is None:
                        idx = np.arange(0, self.POS.npos)
                        mapType = &#39;pos&#39;
                else:
                        idx = self.TETRODE[tetrode].getClustIdx(cluster)
                        mapType = &#39;rate&#39;
                spk_weights = np.bincount(idx, minlength=self.POS.npos)
                if &#39;shuffle&#39; in kwargs.keys():
                        spk_weights = np.roll(spk_weights, int(kwargs[&#39;shuffle&#39;]) * 50) # * 50 to go from seconds into pos_samples
                if np.ma.is_masked(self.POS.xy):
                        mask = ~np.ma.getmask(self.POS.xy[0])
                        pos_weights = mask.astype(np.int)
                        self.ratemap.pos_weights = pos_weights
                        spk_weights[~mask] = 0
                # Update the ratemap instance with arguments fed into this method
                self.ratemap.binsize = binsize
                self.ratemap.smooth_sz = smooth_sz
                if &#39;cmsPerBin&#39; in kwargs:
                        self.ratemap.cmsPerBin = kwargs[&#39;cmsPerBin&#39;]
                if &#39;ppm&#39; in kwargs:
                        self.ratemap.ppm = kwargs[&#39;ppm&#39;]
                rmap = self.ratemap.getMap(spk_weights, varType, mapType, smooth)
                return rmap

        def _getPath(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.POS.xy : np.array
                        The smoothed xy positions filtered appropriately 
                &#39;&#39;&#39;
                if np.ma.is_masked(self.POS.xy):
                        return self.POS.xy[:, ~self.POS.xy.mask[0, :]]
                return self.POS.xy

        def _getDir(self):
                &#39;&#39;&#39;
                Returns
                ------------
                self.POS.dir : np.array
                        The smoothed directional data filtered appropriately
                &#39;&#39;&#39;
                if np.ma.is_masked(self.POS.dir):
                        return self.POS.dir[:, ~self.POS.dir.mask[0, :]]
                return self.POS.dir

        def _getFieldLims(self, tetrode, cluster, binsize=3):
                &#39;&#39;&#39;
                Returns a labelled matrix of the ratemap for a given cluster on a given
                tetrode. Binsize can be fractional for smaller bins. Uses anything &gt;
                than the half peak rate to select as a field. Data is heavily smoothed

                Parameters
                ---------------
                tetrode : int
                        The tetrode to examine
                cluster : int
                        The cluster identity

                Returns
                ----------
                labelled ratemap and the x and y edges of the binned data as a 3-tuple 
                &#39;&#39;&#39;
                rmap, (ye, xe) = self._getMap(tetrode, cluster, binsize=binsize)
                rmap[np.isnan(rmap)] = 0.0
                h = int(np.max(rmap.shape) / 2)
                sm_rmap = self.ratemap.blurImage(rmap, h, ftype=&#39;gaussian&#39;)
                thresh = np.max(sm_rmap.ravel()) * 0.2  # select area &gt; 20% of peak
                # do some image processing magic to get region to keep as field
                distance = ndimage.distance_transform_edt(sm_rmap &gt; thresh)
                mask = skimage.feature.peak_local_max(distance, indices=False,
                                                                                          exclude_border=False,
                                                                                          labels=sm_rmap &gt; thresh)
                label = ndimage.label(mask)[0]
                w = skimage.morphology.watershed(-distance, label,
                                                                                 mask=sm_rmap &gt; thresh)
                label = ndimage.label(w)[0]
                return label, xe, ye

        def _getClusterPhaseVals(self, tetrode, cluster):
                &#39;&#39;&#39;
                Returns the phases of the LFP theta a given cluster fired at

                Parameters
                ---------------
                tetrode : int
                        The tetrode to examine
                cluster : int
                        The cluster identity

                Returns
                ----------
                eegphase : np.array
                        The phase of theta a cluster fired at
                &#39;&#39;&#39;
                ts = self.TETRODE[tetrode].getSpkTS()
                ts = ts / (self.TETRODE[tetrode].timebase / self.EEG.sample_rate)
                ts_idx = np.floor(ts[self.TETRODE[tetrode].cut == cluster]).astype(np.int)
                self.EEG.thetaAmpPhase()
                EEGphase = self.EEG.EEGphase[ts_idx]
                return EEGphase

        def _getThetaCycles(self):
                &#39;&#39;&#39;
                Return a tuple of indices into the EEG record that denotes the peaks
                and troughs of theta cycles
                &#39;&#39;&#39;
                if not self.EEG:
                        self.EEG = EEG(self.filename_root)
                sm_eeg = self.EEG.eegfilter()
                df_eeg = np.diff(sm_eeg)
                pts = np.diff((df_eeg &gt; 0).astype(int), 2)
                pts = ((pts == 1).nonzero()[0]).astype(int)
                peaks = pts[sm_eeg[pts] &gt; 0] + 1
                troughs = pts[sm_eeg[pts] &lt; 0] + 2
                return peaks, troughs

        def _getSpikeInCycle(self, peakIdx, spkIdx=None, whichSpk=&#39;first&#39;):
                &#39;&#39;&#39;
                given an array of spike indices into eeg and indices of peaks in the
                smoothed, theta-filtered eeg signal this returns the first spike in the
                cycle
                whichSpk can be &#39;first&#39; or &#39;last&#39;
                &#39;&#39;&#39;
                if &#39;first&#39; in whichSpk:
                        side = &#39;left&#39;
                elif &#39;last&#39; in whichSpk:
                        side = &#39;right&#39;
                peaks, troughs = self._getThetaCycles()
                if spkIdx is None:
                        spkIdx = self.TETRODE[self.tetrode].getSpkTS()
                spk2eeg_idx = (spkIdx / (self.TETRODE[self.tetrode].timebase /
                                           self.EEG.sample_rate)).astype(np.int)
                idx = np.searchsorted(peaks, spk2eeg_idx, side=side)
                uniques, unique_indices = np.unique(idx, return_index=True)
                return spk2eeg_idx[unique_indices]

        def _parseMetaData(self):
                &#39;&#39;&#39;
                Parses the filename (mine has a standard format) to populate some of
                the objects properties (self.animal_id, self.trial_num etc)
                &#39;&#39;&#39;
                pname, fname = os.path.split(self.filename_root)
                self.metadata[&#39;Filename&#39;] = fname
                self.metadata[&#39;Path&#39;] = pname
                if &#39;R&#39; in fname[0]:
                        self.metadata[&#39;Animal&#39;] = &#39;Rat&#39;
                else:
                        self.metadata[&#39;Animal&#39;] = &#39;Mouse&#39;
                self.metadata[&#39;Experimenter&#39;] = fname[-2:]
                self.metadata[&#39;Animal_id&#39;] = fname.rsplit(&#39;_&#39;)[0]
                trial_date = self.setheader[&#39;trial_date&#39;] + &#39;:&#39; + self.setheader[&#39;trial_time&#39;]
                self.metadata[&#39;Trial_date&#39;] = datetime.strptime(trial_date,
                                                                                                                &#39;%A, %d %b %Y:%H:%M:%S&#39;)
                self.metadata[&#39;Trial_num&#39;] = int(fname.rsplit(&#39;t&#39;)[1][0:-2])

        def _set_figure_title(self, fig, tet, clust):
                fig.canvas.set_window_title(&#39;Tetrode: {0} Cluster: {1}&#39;.format(tet, clust))

        def _set_ax_title(self, ax, tet, clust):
                ax.set_title(&#39;Tetrode: {0}\nCluster: {1}&#39;.format(tet, clust))

        def klustakwik(self, d):
                &#34;&#34;&#34;
                Calls two methods below (kluster and getPC) to run klustakwik on
                a given tetrode with nFet number of features (for the PCA)

                Parameters
                ----------
                d : dict
                        Specifies the vector of features to be used in
                        clustering. Each key is the identity of a tetrode (i.e. 1, 2 etc)
                         and the values are the features used to do the clustering for that tetrode (i.e.
                        &#39;PC1&#39;, &#39;PC2&#39;, &#39;Amp&#39; (amplitude) etc
                &#34;&#34;&#34;

                legal_values = [&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;, &#39;PC4&#39;, &#39;Amp&#39;,
                                                &#39;Vt&#39;, &#39;P&#39;, &#39;T&#39;, &#39;tP&#39;, &#39;tT&#39;, &#39;En&#39;, &#39;Ar&#39;]
                reg = re.compile(&#34;.*(PC).*&#34;)  # check for number of principal comps
                # check for any input errors in whole dictionary first
                for i_tetrode in d.keys():
                        for v in d[i_tetrode]:
                                if v not in legal_values:
                                        raise ValueError(&#39;Could not find %s in %s&#39; % (v, legal_values))
                # iterate through features and see what the max principal component is
                for i_tetrode in d.keys():
                        pcs = [m.group(0) for l in d[i_tetrode] for m in [reg.search(l)] if m]
                        waves = self.TETRODE[i_tetrode].waveforms
                        princomp = None
                        if pcs:
                                max_pc = []
                                for pc in pcs:
                                        max_pc.append(int(pc[2]))
                                num_pcs = np.max(max_pc)  # get max number of prin comps
                                princomp = self.TETRODE[i_tetrode].getParam(waves,
                                                                                  param=&#39;PCA&#39;, fet=num_pcs)
                                # Rearrange the output from PCA calc to match the 
                                # number of requested principal components
                                inds2keep = []
                                for m in max_pc:
                                        inds2keep.append(np.arange((m-1)*4, (m)*4))
                                inds2keep = np.hstack(inds2keep)
                                princomp = np.take(princomp, inds2keep, axis=1)
                        out = []
                        for value in d[i_tetrode]:
                                if &#39;PC&#39; not in value:
                                        out.append(self.TETRODE[i_tetrode].getParam(waves, param=value))
                        if princomp is not None:
                                out.append(princomp)
                        out = np.hstack(out)

                        c = Kluster(self.filename_root, i_tetrode, out)
                        c.make_fet()
                        mask = c.get_mask()
                        c.make_fmask(mask)
                        c.kluster()

        def getcoherence(self, tetrode, cluster, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Wrapper for fieldcalcs.coherence - see docs there
                &#34;&#34;&#34;
                smthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=True, **kwargs)

                unsmthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=False, **kwargs)

                return self.fieldcalcs.coherence(smthd[0], unsmthd[0])

        def getkldiv(self, tetrode, cluster, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Wrapper for fieldcalcs.kldiv - see there for explanation
                &#34;&#34;&#34;
                polarMap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;,
                                                        binsize=binsize, smooth_sz=5,
                                                        smooth=True, **kwargs)
                return self.fieldcalcs.kldiv_dir(polarMap[0])

        def getmrv(self, tetrode, cluster, **kwargs):
                &#39;&#39;&#39;
                Calculate the mean resultant vector length and direction for a given
                cluster/ cell

                A wrapper for statscalcs.Statscalcs.mean_resultant_vector (see
                statscalcs.py)

                Parameters
                ----------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine

                Returns
                ----------
                r : float
                        the mean resultant vector length (range = 0-1)
                th : float
                        the mean resultant vector direction (in radians)
                &#39;&#39;&#39;

                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                angsInRads = np.deg2rad(self.POS.dir[idx])
                from statscalcs import StatsCalcs
                S = StatsCalcs()
                r, th = S.mean_resultant_vector(angsInRads)
                return r, th

        def getcircR(self, tetrode, cluster, **kwargs):
                &#39;&#39;&#39;
                Calculate the mean resultant vector length of circular data
                Unlike getmrv (above) this only returns the vector length. This is
                calculated differently (using complex numbers) but is a) faster, b)
                works with binned data and, c) plays nicer/ easier with shuffles of
                the spike train

                Parameters
                ---------------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine
                **kwargs:
                        Legal values of interest:
                        shuffle: int
                        the number of seconds to shift the spike train

                Returns
                ----------
                r : float
                        the mean resultant vector length (range = 0-1)
                &#39;&#39;&#39;

                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                spk_weights = np.bincount(idx, minlength=self.POS.npos)

                if &#39;shuffle&#39; in kwargs.keys():
                        spk_weights = np.roll(spk_weights, int(kwargs[&#39;shuffle&#39;] * 50))
                inc = (np.pi*2) / 120.0
                h = self.ratemap._RateMap__binData(np.deg2rad(self.POS.dir), np.arange(0, np.pi*2+inc, inc), spk_weights)
                from statscalcs import StatsCalcs
                S = StatsCalcs()
                R = S.circ_r(h[1][0][0:-1], h[0])
                return R

        def getskaggsInfo(self, tetrode, cluster, binsize=3, **kwargs):
                &#39;&#39;&#39;
                Wrapper for fieldcalcs.skaggsInfo see there for docs

                Parameters
                ---------------
                tetrode : int
                        The tetrode to exmaine
                cluster : int
                        The cluster to examine
                binsize : int
                        Size of bins in cms
                Returns
                --------------
                bits per spike : float

                Notes
                -----
                binning could be over any single spatial variable (e.g. location, direction, speed).
                &#39;&#39;&#39;
                ratemap = self._getMap(tetrode, cluster, binsize=binsize, **kwargs)[0]
                dwelltimes = self._getMap(binsize=binsize, **kwargs)[0]
                ratemap, _, dwelltimes = self.ratemap._RateMap__adaptiveMap(ratemap, dwelltimes)
                return self.fieldcalcs.skaggsInfo(ratemap, dwelltimes)

        def getTsAndCs(self, verbose=False):
                &#34;&#34;&#34;
                Prints out the available tetrodes and clusters
                &#34;&#34;&#34;
                cut_files = [(f) for f in glob(self.filename_root + &#39;*&#39;) if &#39;cut&#39; in f]
                m = re.compile(&#39;(.*)_(.*).cut&#39;, re.M|re.I)
                tAndCdict = {}
                if cut_files:
                        for f in cut_files:
                                tet = int(m.match(f).group(2))
                                try:
                                        data = self.getCut(tet)
                                        clusters = list(np.unique(data))
                                        if clusters[0]==0:
                                                clusters.pop(0)
                                                if clusters:
                                                        tAndCdict[tet] = clusters
                                        if verbose:
                                                print(&#39;\nTetrode {0} contains clusters: {1}&#39;.format(tet, clusters))
                                except:
                                        if verbose:
                                                print(&#39;\nTetrode{0} has no cut&#39;.format(tet))
                else:
                        pass
                if tAndCdict:
                        tets = []
                        clusts = []
                        for t,c in tAndCdict.items():
                                for cc in c:
                                        tets.append(str(t))
                                        clusts.append(str(cc))
                        &#39;&#39;&#39;
                        The two fucking stupid lines below are so yaml can
                        serialize the object correctly
                        &#39;&#39;&#39;
                        self.tetrodes = map(int,tets)
                        self.clusters = map(int,clusts)
                        return tAndCdict

        def plotMap(self, tetrode, clusters, ax=None, var2bin=&#39;pos&#39;, *args, **kwargs):
                &#34;&#34;&#34;
                Plots a ratemap for a given tetrode and cluster
                Wrapper for _plotMap() so multiple clusters can be plotted

                Parameters
                ----------
                tetrode : int
                                 the tetrode you want to look at
                cluster : int, 1xn array/ list
                                 a single number or list (or 1xn array) of the clusters to plot
                ax : optional, defaults to None. Which axis to add the plot to; if None
                                        then a new figure window is produced
                **kwargs :
                        extra arguments include:
                        &#39;bar&#39; - for use with directional data to produce a polar
                        histogram plot
                        &#39;add_peak_rate&#39; - bool
                        adds the peak rate (to 2 decimal places) to the figure
                        binsize : int, optional
                                size of bins. Defaults to 3
                        smooth_sz : the width of the smoothing kernel (see **kwargs for more)
                                var2bin: optional, defaults to &#39;pos&#39;. Which variable to bin.
                                Can be either &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked
                                arrays
                        smooth : bool, optional. Defaults to true. Whether to smooth the data or
                                not

                Returns
                -------
                ratemap : numpy.ndarray
                        depending on whether a directional (1d) or positional (2d) map was
                        asked for an ndarray is returned

                Examples
                --------
                &gt;&gt;&gt; T = dacq2py_util.Trial(&#39;M845_141003t1rh&#39;)
                &gt;&gt;&gt; # Plot the ratemap for cluster 1 on tetrode 1
                &gt;&gt;&gt; T.plotMap(1,1)
                &gt;&gt;&gt; # Add the peak rate to the figure window
                &gt;&gt;&gt; T.plotMap(1,1,add_peak_rate=True)
                &gt;&gt;&gt; # Plot the polar map for same cluster
                &gt;&gt;&gt; T.plotMap(1,1,var2bin=&#39;dir&#39;)
                &gt;&gt;&gt; # Plot the unsmoothed dwell map for the trial
                &gt;&gt;&gt; T.plotMap(None,None,smooth=False)
                &#34;&#34;&#34;

                for key in (&#39;var2bin&#39;, &#39;ax&#39;, &#39;binsize&#39;,&#39;smooth_sz&#39;, &#39;smooth&#39;):
                        if key in kwargs:
                                setattr(self, key, kwargs[key])
                if isinstance(clusters, int):
                        setattr(self, &#39;clusters&#39;, [clusters])
                elif isinstance(clusters, list):
                        setattr(self, &#39;clusters&#39;, clusters)
                elif isinstance(clusters, str):
                        if &#39;all&#39; in clusters:
                                tetDict = self.getTsAndCs()
                                setattr(self, &#39;clusters&#39;, tetDict[tetrode])
                clusters = getattr(self, &#39;clusters&#39;, None)
#               var2bin = getattr(self, &#39;var2bin&#39;, &#39;pos&#39;)
                ax = getattr(self, &#39;ax&#39;, None)
                binsize = getattr(self, &#39;binsize&#39;, 3)
                smooth_sz = getattr(self.ratemap, &#39;smooth_sz&#39;, 5)
                smooth = getattr(self, &#39;smooth&#39;, True)

                if len(clusters) == 1:
                        ncols = 1
                        nrows = 1
                elif np.logical_and(len(clusters) &gt; 1, len(clusters) &lt; 6):
                        ncols = len(clusters)
                        nrows = 1
                else:
                        ncols = 5
                        nrows = int(np.floor(len(clusters) / 5) + 1)
                if ax is None:
                        fig = plt.figure()
                        if &#39;dir&#39; in var2bin:
                                ax = fig.add_subplot(nrows, ncols, 1, projection=&#39;polar&#39;)
                        else:
                                ax = fig.add_subplot(nrows, ncols, 1)
                axes_out = []
                if clusters is None:
                        axes = fig.add_subplot(1, 1, 1)
                        ax, ratemap = self._plotMap(None, None, var2bin=var2bin, ax=ax,
                                                  binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        self._set_ax_title(axes, tetrode, clusters)
                        axes_out.append(ax)
                if len(clusters) == 1:
                        cluster = clusters[0]

                        ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin, ax=ax,
                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        axes = ax
#                       # check kwargs to see if we want to add peak rate to axes
                        if &#34;add_peak_rate&#34; in kwargs:
                                if kwargs[&#39;add_peak_rate&#39;]:
                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(ratemap)), (0.9,0.15), \
                                                        xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)


                        self._set_ax_title(axes, tetrode, cluster)
                        axes_out.append(ax)
                else:
                        fig.set_facecolor(&#39;w&#39;)
                        fig.set_frameon(False)
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)
                        for iax, cluster in enumerate(clusters):
                                inax = fig.add_subplot(nrows, ncols, iax+1)
                                ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin,
                                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth,
                                                          ax=inax)
                                self._set_ax_title(inax, tetrode, cluster)
                                axes_out.append(ax)
                return axes_out

        def _plotMap(self, tetrode=None, cluster=None, ax=None, var2bin=&#39;pos&#39;, 
                                binsize=3, smooth_sz=5, smooth=True, **kwargs):
                &#34;&#34;&#34;
                Plots a ratemap for a given tetrode and cluster

                Parameters
                ----------
                tetrode : int
                        the tetrode you want to look at
                cluster : int, 1xn array/ list
                        a single number or list (or 1xn array) of the clusters to plot
                binsize : int, optional
                        size of bins. Defaults to 3
                smooth_sz : int
                        the width of the smoothing kernel (see **kwargs for more)
                var2bin : optional, defaults to &#39;pos&#39;. Which variable to bin.
                        Can be either &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked arrays
                smooth : bool
                        Defaults to true. Whether to smooth the data or not
                ax : matplotlib.axes
                        Defaults to None. Which axis to add the plot to; if None
                        then a new figure window is produced
                **kwargs : various
                        &#39;bar&#39; - for use with directional data to produce a polar
                        histogram plot

                Returns
                -------
                ratemap: ndarray (1d or 2d)
                        depending on whether a directional (1d) or positional (2d) map was
                        asked for an ndarray is returned
                &#34;&#34;&#34;

                rmap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin,
                                                        binsize=binsize, smooth_sz=smooth_sz,
                                                        smooth=smooth, **kwargs)
                if rmap[0].ndim == 1:
                        # polar plot
                        if ax is None:
                                fig = plt.figure()
                                self._set_figure_title(fig, tetrode, cluster)
                                ax = fig.add_subplot(111, projection=&#39;polar&#39;)
                        theta = np.deg2rad(rmap[1][0][1:])
                        ax.clear()
                        ax.plot(theta, rmap[0])
                        ax.set_aspect(&#39;equal&#39;)
                        ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, left=&#39;off&#39;, right=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, labelleft=&#39;off&#39;, labeltop=&#39;off&#39;, labelright=&#39;off&#39;)
                        ax.set_rticks([])
                        # deal with vmin/ vmax in kwargs
                        if &#39;vmax&#39; in kwargs.keys():
                                ax.set_rmax(kwargs[&#39;vmax&#39;])
                        # See if we should add the mean resultant vector (mrv)
                        if &#39;add_mrv&#39; in kwargs.keys():
                                from statscalcs import StatsCalcs
                                S = StatsCalcs()
                                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                                angles = self.POS.dir[idx]
                                print(&#39;len angles: {}&#39;.format(len(angles)))
                                r, th = S.mean_resultant_vector(np.deg2rad(angles))
                                ax.hold(True)
                                print(&#39;r: {}\nth: {}&#39;.format(r,th))
                                ax.plot([th, th],[0, r*np.max(rmap[0])],&#39;r&#39;)
                        ax.set_thetagrids([0, 90, 180, 270])
                        ratemap = rmap[0]

                elif rmap[0].ndim == 2:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                                self._set_figure_title(fig, tetrode, cluster)
                        # mask the ratemap where NaNs occur for plotting purposes
                        ratemap = np.ma.MaskedArray(rmap[0], np.isnan(rmap[0]), copy=True)
                        x, y = np.meshgrid(rmap[1][1][0:-1], rmap[1][0][0:-1][::-1])
                        # deal with vmin/ vmax in kwargs
                        if &#39;vmax&#39; in kwargs.keys():
                                vmax = kwargs[&#39;vmax&#39;]
                        else:
                                vmax = np.max(np.ravel(ratemap))
                        ax.pcolormesh(x, y, ratemap, cmap=cm.jet, edgecolors=&#39;face&#39;, vmax=vmax)
                        ax.axis([x.min(), x.max(), y.min(), y.max()])
                        ax.set_aspect(&#39;equal&#39;)
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)
                        ax.axes.get_xaxis().set_visible(False)
                        ax.axes.get_yaxis().set_visible(False)
                        ax.spines[&#39;right&#39;].set_visible(False)
                        ax.spines[&#39;top&#39;].set_visible(False)
                        ax.spines[&#39;bottom&#39;].set_visible(False)
                        ax.spines[&#39;left&#39;].set_visible(False)
                return ax, ratemap

        def plotPath(self, ax=None, clamp=False, label=False, applyStm=False, **kwargs):
                &#39;&#39;&#39;
                Plots the animals path during a trial. Default is to limit plot range
                to the min/ max of x/y extent of path

                Parameters
                ----------
                ax : matplotlib.Axes
                        The axes to plot into. If none a new figure window is created
                clamp : bool
                        whether the axes are clamped to self._xlims and self._ylims or not
                applyStm : bool
                        Whether to overlay r crosses on the path where the laser events occurred
                &#39;&#39;&#39;
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        fig = plt.gcf()
                fig.set_facecolor(&#39;w&#39;)
                xy = self._getPath()
                ax.plot(xy[0], xy[1], color=[0.8627, 0.8627, 0.8627],**kwargs)
                ax.invert_yaxis()
                if applyStm:
                        stmTS = self.STM.getPosTS()
                        stmXY = xy[:, stmTS.astype(int)]
                        ax.plot(stmXY[0], stmXY[1], &#39;rx&#39;, ms=2)
                if clamp:
                        ax.set_xlim(self._xlims)
                        ax.set_ylim(self._ylims)
                ax.set_aspect(&#39;equal&#39;)
                if not label:
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)

        def plotSpikesOnPath(self, tetrode, clusters, ax=None, clamp=False, **kwargs):
                &#39;&#39;&#39;
                Plots the spikes on the path during a trial for a particular tetrode/
                cluster(s)

                Parameters
                ----------
                tetrode: int
                                the tetrode you want to look at
                cluster : int, 1xn array/ list
                                a single number or list (or 1xn array) of the clusters to plot
                clamp : bool, optional
                                whether to restrict the plot to the self._xlims and self_ylims
                                property
                ax : matplotlib.Axes
                        defaults to None. Which axis to add the plot to.
                        If None a new figure window is produced

                &#39;&#39;&#39;
                if not isinstance(clusters, (np.ndarray, list)):
                        if isinstance(clusters, str):
                                clusters = self.availableClusters
                        else:
                                clusters = [clusters]
                xy = self.POS.xy
                for i, clust in enumerate(clusters):
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        ax.plot(xy[0], xy[1], c=tcols.colours[0], zorder=1)
                        idx = self.TETRODE[tetrode].getClustIdx(clust)
                        # useful to override default colour scheme for publication figures
                        if &#39;mec&#39; in kwargs.keys():
                                mec = kwargs.pop(&#39;mec&#39;)
                        else:
                                mec = tcols.colours[clust]
                        ax.plot(xy[0, idx], xy[1, idx], &#39;s&#39;, c=mec, mec=mec, **kwargs)
                        if clamp:
                                ax.set_xlim(self._xlims)
                                ax.set_ylim(self._ylims)
                        ax.set_aspect(&#39;equal&#39;)
                        ax.invert_yaxis()
                        plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                        plt.setp(ax.get_xticklabels() + ax.get_yticklabels(),
                                         visible=False)
                return ax

        def plotRaster(self, tetrode, clusters, ax=None, dt=(-50, 100), prc_max = 0.5, ms_per_bin=1, histtype=&#39;count&#39;, hist=True, **kwargs):
                &#34;&#34;&#34;
                Wrapper for _plotRaster allowing multiple clusters to be plotted in
                separate figure windows

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : 2-tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                prc_max : float
                        the proportion of firing the cell has to &#39;lose&#39; to count as
                        silent; a float between 0 and 1
                ax - matplotlib.Axes
                        the axes to plot into. If not provided a new figure is created
                ms_per_bin : int
                        The number of milliseconds in each bin of the raster plot
                histtype : str
                        either &#39;count&#39; or &#39;rate&#39; - the resulting histogram plotted above the raster plot will
                        consist of either the counts of spikes in ms_per_bin or the mean rate
                        in ms_per_bin
                &#34;&#34;&#34;
                if isinstance(clusters, int):
                        clusters = [clusters]
                elif isinstance(clusters, str):
                        if &#39;all&#39; in clusters:
                                tetDict = self.getTsAndCs()
                                clusters = tetDict[tetrode]
                for cluster in clusters:
                        # Calculate the stimulation ratio
                        stim_histo = self.getRasterHist(tetrode, cluster, dt=dt, hist=hist)
                        mean_stim_spikes = np.sum(stim_histo, 1)
                        pre_stim_spks = np.mean(mean_stim_spikes[0:50])
                        post_stim_spks = np.mean(mean_stim_spikes[50:60])
                        ratio = (post_stim_spks-pre_stim_spks) / (post_stim_spks+pre_stim_spks)
                        print(&#34;Stimulation ratio = {}&#34;.format(ratio))
                        self._plotRaster(tetrode=tetrode, cluster=cluster, dt=dt,prc_max=prc_max, ax=ax, ms_per_bin=ms_per_bin,histtype=histtype, **kwargs)
                return ratio

        def _plotRaster(self, tetrode, cluster, dt=(-50, 100), prc_max=0.5, ax=None, ms_per_bin=1, histtype=&#39;count&#39;, **kwargs):
                &#34;&#34;&#34;
                Plots a raster plot for a specified tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : 2-tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                prc_max : float
                        the proportion of firing the cell has to &#39;lose&#39; to count as
                        silent; a float between 0 and 1
                ax - matplotlib.Axes
                        the axes to plot into. If not provided a new figure is created
                ms_per_bin : int
                        The number of milliseconds in each bin of the raster plot
                histtype : str
                        either &#39;count&#39; or &#39;rate&#39; - the resulting histogram plotted above the raster plot will
                        consist of either the counts of spikes in ms_per_bin or the mean rate
                        in ms_per_bin
                &#34;&#34;&#34;

                if &#39;x1&#39; in kwargs.keys():
                        x1 = kwargs.pop(&#39;x1&#39;)
                else:
                        x1 = self.TETRODE[tetrode].getClustTS(cluster)
                        x1 = x1 / int(self.TETRODE[tetrode].timebase / 1000.) #in ms
                x1.sort()
                on_good = self.STM.getTS()
                dt = np.array(dt)
                irange = on_good[:, np.newaxis] + dt[np.newaxis, :]
                dts = np.searchsorted(x1, irange)
                y = []
                x = []
                for i, t in enumerate(dts):
                        tmp = x1[t[0]:t[1]] - on_good[i]
                        x.extend(tmp)
                        y.extend(np.repeat(i, len(tmp)))
                if ax is None:
                        fig = plt.figure(figsize=(4.0, 7.0))
                        self._set_figure_title(fig, tetrode, cluster)
                        axScatter = fig.add_subplot(111)
                else:
                        axScatter = ax
                axScatter.scatter(x, y, marker=&#39;.&#39;, s=2, rasterized=False, **kwargs)
                divider = make_axes_locatable(axScatter)
                axScatter.set_xticks((dt[0], 0, dt[1]))
                axScatter.set_xticklabels((str(dt[0]), &#39;0&#39;, str(dt[1])))
                axHistx = divider.append_axes(&#34;top&#34;, 0.95, pad=0.2, sharex=axScatter,
                                                                          transform=axScatter.transAxes)
                scattTrans = transforms.blended_transform_factory(axScatter.transData,
                                                                                                                  axScatter.transAxes)
                stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;])
                axScatter.add_patch(Rectangle((0, 0), width=stim_pwidth/1000., height=1,
                                                        transform=scattTrans,
                                                        color=[0, 0, 1], alpha=0.5))
                histTrans = transforms.blended_transform_factory(axHistx.transData,
                                                                                                                 axHistx.transAxes)
                axHistx.add_patch(Rectangle((0, 0), width=stim_pwidth/1000., height=1,
                                                  transform=histTrans,
                                                  color=[0, 0, 1], alpha=0.5))
                axScatter.set_ylabel(&#39;Laser stimulation events&#39;, labelpad=-18.5)
                axScatter.set_xlabel(&#39;Time to stimulus onset(ms)&#39;)
                nStms = int(self.STM[&#39;num_stm_samples&#39;])
                axScatter.set_ylim(0, nStms)
                # Label only the min and max of the y-axis
                ylabels = axScatter.get_yticklabels()
                for i in range(1, len(ylabels)-1):
                        ylabels[i].set_visible(False)
                yticks = axScatter.get_yticklines()
                for i in range(1, len(yticks)-1):
                        yticks[i].set_visible(False)

                histColor = [192/255.0,192/255.0,192/255.0]
                histX = axHistx.hist(x, bins=np.arange(dt[0], dt[1] + ms_per_bin, ms_per_bin),
                                                         color=histColor, alpha=0.6, range=dt, rasterized=True, histtype=&#39;stepfilled&#39;)
                vals = histX[0]
                bins = histX[1]
                if &#39;rate&#39; in histtype:
                        axHistx.set_ylabel(&#39;Rate&#39;)
                        mn_rate_pre_stim = np.mean(vals[bins[1:] &lt; 0])
                        idx = np.logical_and(bins[1:] &gt; 0, bins[1:] &lt; 10).nonzero()[0]
                        mn_rate_post_stim = np.mean(vals[idx])
                        above_half_idx = idx[(vals[idx] &lt; mn_rate_pre_stim * prc_max).nonzero()[0]]
                        half_pre_rate_ms = bins[above_half_idx[0]]
                        print(&#39;\ntime to {0}% of pre-stimulus rate = {1}ms&#39;.format(*(prc_max * 100, half_pre_rate_ms)))
                        print(&#39;mean pre-laser rate = {0}Hz&#39;.format(mn_rate_pre_stim))
                        print(&#39;mean 10ms post-laser rate = {0}&#39;.format(mn_rate_post_stim))
                else:
                        axHistx.set_ylabel(&#39;Spike count&#39;, labelpad=-2.5)
                plt.setp(axHistx.get_xticklabels(),
                                 visible=False)
                # Label only the min and max of the y-axis
                ylabels = axHistx.get_yticklabels()
                for i in range(1, len(ylabels)-1):
                        ylabels[i].set_visible(False)
                yticks = axHistx.get_yticklines()
                for i in range(1, len(yticks)-1):
                        yticks[i].set_visible(False)
                axHistx.set_xlim(dt)
                axScatter.set_xlim(dt)

                return x,y

        def getRasterHist(self, tetrode, cluster, dt=(-50, 100), hist=True):
                &#39;&#39;&#39;
                Calculates the histogram of the raster of spikes during a series of events

                Parameters
                ----------
                tetrode : int
                cluster : int
                dt : tuple
                        the window of time in ms to examine zeroed on the event of interest
                        i.e. the first value will probably be negative as in the default example
                hist : bool
                        not sure
                &#39;&#39;&#39;
                x1 = self.TETRODE[tetrode].getClustTS(cluster)
                x1 = x1 / int(self.TETRODE[tetrode].timebase / 1000.) #in ms
                x1.sort()
                on_good = self.STM.getTS()
                dt = np.array(dt)
                irange = on_good[:, np.newaxis] + dt[np.newaxis, :]
                dts = np.searchsorted(x1, irange)
                y = []
                x = []
                for i, t in enumerate(dts):
                        tmp = x1[t[0]:t[1]] - on_good[i]
                        x.extend(tmp)
                        y.extend(np.repeat(i, len(tmp)))

                if hist:
                        nEvents = int(self.STM[&#34;num_stm_samples&#34;])
                        return np.histogram2d(x, y, bins=[np.arange(dt[0],dt[1]+1,1), np.arange(0,nEvents+1, 1)])[0]
                else:
                        return np.histogram(x, bins=np.arange(dt[0],dt[1]+1,1), range=dt)[0]

        def plot_event_EEG(self, eeg_type=&#39;egf&#39;, dt=(-50, 100), plot=True, ax=None, 
                                           evenOnsets=True, **kwargs):
                &#34;&#34;&#34;
                Plots out the eeg record following an &#39;on&#39; event in the log file

                Parameters
                ----------
                eeg_type : str
                        either &#39;eeg&#39; or &#39;egf&#39;
                dt : tuple
                        time to look before and after an onset event
                plot : bool
                        whether to plot the stimulus-triggered-eeg
                ax : matplotlib.axis
                        will plot into this axis if supplied
                        (new figure produced if plot is None and ax is None)
                evenOnsets: bool
                        if True assume there is supposed to be an even 
                        difference between the events in the .stm file. If events are 
                        found that have an uneven difference they are thrown out.
                        NB The difference is calculated from information gleaned from 
                        the trial.STM field. If False this is ignored.
                &#34;&#34;&#34;
                on_good = self.STM.getTS()#timestamps in ms
                &#34;&#34;&#34;
                Check for inter-stimulus time differences to make sure that the large
                majority (99%) of on pulses are regularly spaced - otherwise issue a warning
                &#34;&#34;&#34;
                df = np.diff(np.diff(on_good))
                if np.count_nonzero(df) / float(len(on_good)) * 100 &gt; 1:
                        warnings.warn(&#39;More than 1% of on events differ in size&#39;, UserWarning)
                #check for abnormally large number of stim events and abort
                if len(on_good) &gt; 100000:
                        raise Exception(&#39;Very large number of stimulation events. Aborting plot_event_EEG&#39;)
                #get the eeg data and indices to use
                if &#39;egf&#39; in eeg_type:
                        eeg = self.EGF.eeg
                        on_idx = self.STM.getEGFIdx()
                        eeg_samps_per_ms = self.EGF.sample_rate / 1000.0
                elif &#39;eeg&#39; in eeg_type:
                        eeg = self.EEG.eeg
                        on_idx = self.STM.getEEGIdx()
                        eeg_samps_per_ms = self.EEG.sample_rate / 1000.0

                &#34;&#34;&#34;
                NB the following conditional assumes there is only one phase of the 
                stimulation that actually contains stim events. If there is more than 
                one then the last one will be the one used
                &#34;&#34;&#34;
                df = np.diff(on_good)
                &#34;&#34;&#34;
                keep pulsePause here as used lower down to plot multiple Rectangle
                patches in case the dt tuple specifies a range of values higher than
                the pause between stimulation events
                &#34;&#34;&#34;
                pulsePause = 0
                if evenOnsets:
                        for k, v in self.STM.iteritems():
                                if isinstance(v, OrderedDict):
                                        for kk, vv in v.iteritems():
                                                for kkk, vvv in vv.iteritems():
                                                        if &#39;Pause&#39; in kkk:
                                                                if vvv is not None:
                                                                        pulsePause = vvv
                        pulsePause_ms = pulsePause / 1000#this is the desired
                        unequalPausesIdx = np.nonzero(df!=pulsePause_ms)[0]
                        on_good = np.delete(on_good, unequalPausesIdx)
                        on_idx = np.delete(on_idx, unequalPausesIdx)
                eeg = eeg - np.ma.mean(eeg)
                dt_eeg = eeg_samps_per_ms * np.array(dt)
                rng = np.arange(dt_eeg[0], dt_eeg[1], 1)
                idx = (on_idx[np.newaxis, :] + rng[:, np.newaxis]).astype(int)
                result = np.zeros((len(rng), len(on_good)))
                result = eeg[idx]
                if not plot:
                        return result, idx
                else:
                        mn = np.mean(result, 1)
                        se = np.std(result, 1) / np.sqrt(len(on_good))
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        else:
                                ax = ax
                        ax.errorbar(np.linspace(dt[0], dt[1], len(mn)), mn * 1e6,
                                                yerr=se*1e6, rasterized=False)
                        ax.set_xlim(dt)
                        axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                                   ax.transAxes)
                        stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;])
                        if pulsePause &gt; 0:
                                a = np.arange(0, dt[1], pulsePause_ms)
                                b = np.arange(0, dt[0], -pulsePause_ms)
                                patchStarts = np.unique(np.concatenate((a, b)))
                        for p in patchStarts:
                                ax.add_patch(Rectangle((p, 0), width=stim_pwidth/1000., height=1,
                                                         transform=axTrans,
                                                         color=[1, 1, 0], alpha=0.5))
                        ax.set_ylabel(&#39;LFP ($\mu$V)&#39;)
                        ax.set_xlabel(&#39;Time(ms)&#39;)
                        return result

        def plotEventEEGRange(self, eeg_type=&#39;egf&#39;, stimTrials=[0,1], ax=None, **kwargs):
                &#34;&#34;&#34;
                Calls plot_event_eeg with defaults and no plotting and then plots out
                a time period in seconds from x1 to x2 and overlays the correct time in
                seconds on the x-axis - meant for manual inspection of the effect of
                stimulation events on the eeg

                Parameters
                ------------
                eeg_type : str
                        either &#39;egf&#39; or &#39;eeg&#39; although probably no point
                        using &#39;eeg&#39; as sample rate too low
                stimTrials : list
                        the stimulation &#39;trial&#39; to plot, starting at 0
                        NB stimulating every 150ms for 10ms for 20 minutes gets
                        you 8000 trials
                ax : matplotlib.axis
                        the axis to plot into. A new figure is
                        produced if this is None
                &#34;&#34;&#34;

                result, idx = self.plot_event_EEG(eeg_type=eeg_type, plot=False)
                eeg_samp_rate = self.STM[eeg_type + &#39;SampRate&#39;]
                time_ms = idx / float(eeg_samp_rate / 1000.)
                eeg_blocks = []
                time_blocks = []
                for t in stimTrials:
                        eeg_blocks.append(result[:, t])
                        time_blocks.append(time_ms[:, t])

                speed_idx = (idx / (eeg_samp_rate / self.POS.pos_sample_rate)).astype(int)
                speed = self.POS.speed[0, np.ravel(speed_idx, &#39;F&#39;)]
                max_speed = np.max(speed)
                speed = np.reshape(speed, idx.shape, &#39;F&#39;)
                # filter the eeg data in the theta and gamma bands
                E = EEGCalcs(self.filename_root)
                eeg = self.EGF.eeg
                eeg = eeg - np.ma.mean(eeg)
                sampRate = self.EGF.sample_rate
                theta_eeg = E.filterWithButter(eeg, 4, 8, sampRate, 2)
                gamma_eeg = E.filterWithButter(eeg, 30, 80, sampRate, 2)

                theta = theta_eeg[np.ravel(idx, &#39;F&#39;)]
                theta = np.reshape(theta, idx.shape, &#39;F&#39;)
                gamma = gamma_eeg[np.ravel(idx, &#39;F&#39;)]
                gamma = np.reshape(gamma, idx.shape, &#39;F&#39;)
                #dt is (-50, 150)
                rectStart = int((eeg_samp_rate / 1000.) * 50)
                rectEnd = int((eeg_samp_rate / 1000.) * 60)
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax1 = ax.twinx()
                for block in zip(time_blocks, eeg_blocks, stimTrials):
                        ax.plot(block[0], block[1], color=[0.8627, 0.8627, 0.8627])
                        ax.hold(True)
                        ax.plot(block[0], theta[:, block[2]], &#39;r&#39;)
                        ax.plot(block[0], gamma[:, block[2]], &#39;g&#39;)
                        ax1.plot(block[0], speed[:, block[2]], &#39;y&#39;)
                        ax1.set_ylim(0, np.max(max_speed) * 4)
                        axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                                   ax.transAxes)
                        i = block[0][rectStart]
                        j = block[0][rectEnd] - block[0][rectStart]
                        ax.add_patch(Rectangle((i,0), width=j, height=1,
                                                         transform=axTrans,
                                                         color=[41./256, 161./256, 230./256], alpha=0.5))
                ax.set_xlim(time_blocks[0][0], time_blocks[-1][-1])
                ylabels = ax1.yaxis.get_majorticklabels()
                for i,xxx in enumerate(ylabels):
                        if i &gt; 1:
                                xxx.set_visible(False)
                        else:
                                xxx.set_color(&#39;k&#39;)
                yticks = ax1.yaxis.get_major_ticks()
                for i,xxx in enumerate(yticks):
                        if i &gt; 1:
                                xxx.set_visible(False)

        def adjust_median_speed(self, min_speed=5, plot=True):
                &#39;&#39;&#39;
                Parameters
                ----------
                min_speed : float
                plot : bool
                &#39;&#39;&#39;
                grandMedian = stats.nanmedian(self.POS.speed, 1)
                sortedSpIdx = np.argsort(self.POS.speed)
                sortedSp = np.sort(self.POS.speed)
                indMedian = np.nonzero(sortedSp &gt;= grandMedian)[1][0]
                indFirstOverThresh = np.nonzero(sortedSp &gt;= min_speed)[1][0]
                indLastNotNan = np.nonzero(~np.isnan(sortedSp))[1][-1]
                halfWidth = np.min([indMedian-indFirstOverThresh, indLastNotNan-indMedian])
                if plot:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                        maxSp = sortedSp[0, indLastNotNan]
                        L = sortedSp.shape[1]
                        rect = Rectangle(xy=(0, indMedian-halfWidth), width=maxSp, height=indMedian+halfWidth/2, color=&#39;b&#39;, alpha=0.5)
                        ax.add_patch(rect)
                        ax.plot(sortedSp[0, 0:indLastNotNan], np.arange(indLastNotNan), &#39;k&#39;, lw=2)
                        ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                        ax.set_ylabel(&#39;Cumulative number of samples&#39;)
                        if indLastNotNan != L:
                                ax.plot((0, maxSp), (indLastNotNan+1, indLastNotNan+1), &#39;r-&#39;)
                                ax.plot((0, maxSp), (L, L), &#39;r-&#39;)
                        ax.set_xlim(0, maxSp)
                        ax.set_ylim(0, L)
                        ax.plot((0, maxSp), (indMedian, indMedian), &#39;b&#39;, lw=1)
                        ax.plot((grandMedian, grandMedian), (0, indMedian), &#39;b-&#39;)
                        ax.plot(grandMedian, indMedian, &#39;bo&#39;, ms=12)
                        ax.plot((0, maxSp), (indFirstOverThresh, indFirstOverThresh), &#39;b&#39;, lw=1)
                        ax.plot((min_speed, min_speed), (0, indFirstOverThresh), &#39;b--&#39;)
                        ax.plot(min_speed, indFirstOverThresh, &#39;bo&#39;, ms=12)
                return sortedSpIdx[indMedian-halfWidth:indMedian+halfWidth]

        def plotRateVSpeed(self, tetrode, cluster, minSpeed=0.0, maxSpeed = 40.0, 
                                           sigma=3.0, shuffle=False, nShuffles=100, plot=False, ax=None,
                                           verbose=False, getShuffledData=False, getData=False, **kwargs):
                &#39;&#39;&#39;
                Plots the instantaneous firing rate of a cell against running speed
                Also outputs a couple of measures as with Kropff et al., 2015; the
                Pearsons correlation and the depth of modulation (dom) - see below for
                details

                Parameters
                -------------------
                tetrode : int
                        the tetrode to use
                cluster : int
                        the cluster to use
                minSpeed : float
                        speeds below this value are masked and not used
                maxSpeed : float
                        speeds above this value are masked and not used
                sigma : float
                        the standard deviation of the gaussian used to smooth the spike
                        train
                shuffle : bool, default False
                        Whether to calculate the significance of the speed score or not
                        This is done by calculating the correlation between speed and
                        the shuffled spike train for nShuffles where the shuffles are only allowed with the
                        window (trial_start + minTime) : (trial_end - minTime). Default is
                        30 seconds as with Kropff et al., 2015. Default False
                nShuffles : int
                        How many times to perform the shuffle. Defaults to 100 as with
                        Kropff et al., 2015
                plot : bool
                        Whether to plot output or not. Defaults to False
                &#39;&#39;&#39;

                speed = self.POS.speed.ravel()
                # Calculate histogram to see how much is accounted for in each bin
                if np.nanmax(speed) &lt; maxSpeed:
                        maxSpeed = np.nanmax(speed)
                        if verbose:
                                print(&#39;Capping speed to max in data: {:.2f}&#39;.format(maxSpeed))
                spd_bins = np.arange(minSpeed, maxSpeed, 1.0)
                # Construct the mask
                speed_filt = np.ma.MaskedArray(speed)
                speed_filt = np.ma.masked_where(speed_filt &lt; minSpeed, speed_filt)
                speed_filt = np.ma.masked_where(speed_filt &gt; maxSpeed, speed_filt)
                spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
                spk_sm = np.ma.MaskedArray(spk_sm, mask=np.ma.getmask(speed_filt))

                # res is the basic correlation between running speed and instantaneous
                # firing rate
                res = stats.mstats.pearsonr(spk_sm, speed_filt)
                if shuffle:
                        duration = self.POS.npos / self.POS.pos_sample_rate
                        shuffles = np.linspace(30, duration-30, nShuffles)
                        shuffled_rs = []
                        for time in shuffles:
                                shuffled_spks = self._getTimeSmoothedSpikes(tetrode, cluster, sigma, time)
                                shuffled_rs.append(stats.mstats.pearsonr(shuffled_spks, speed_filt)[0])
                        prob = np.array([.90, .95, .99])
                        qtiles = stats.mstats.mquantiles(shuffled_rs, prob)
                        if verbose:
                                print(&#34;Running speed vs firing rate correlation (PPMC): {0}&#34;.format(res[0]))
                                print(&#34;The {0} percentiles are {1}&#34;.format(prob*100, qtiles))
                spd_dig  = np.digitize(speed_filt, spd_bins, right=True)
                mn_rate = np.array([np.ma.mean(spk_sm[spd_dig==i]) for i in range(0,len(spd_bins))])
                if plot:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                        ax.plot(spd_bins, mn_rate * self.POS.pos_sample_rate, &#39;k&#39;)
                        ax.set_xlim(spd_bins[0], spd_bins[-1])
                        ax.set_ylabel(&#34;Firing rate(Hz)&#34;)
                        ax.set_xlabel(&#34;Speed(cm/s)&#34;)
                        ylabels = ax.get_yticklabels()
                        for i in range(1, len(ylabels)-1):
                                ylabels[i].set_visible(False)
                        yticks = ax.get_yticklines()
                        for i in range(1, len(yticks)-1):
                                yticks[i].set_visible(False)
                        xlabels = ax.get_xticklabels()
                        for i in range(1, len(xlabels)-1):
                                xlabels[i].set_visible(False)
                        xticks = ax.get_xticklines()
                        for i in range(1, len(xticks)-1):
                                xticks[i].set_visible(False)
                        ax.spines[&#39;right&#39;].set_visible(False)
                        ax.spines[&#39;top&#39;].set_visible(False)
                        ax.yaxis.set_ticks_position(&#39;left&#39;)
                        ax.xaxis.set_ticks_position(&#39;bottom&#39;)
                        if &#34;add_peak_rate&#34; in kwargs:
                                if kwargs[&#39;add_peak_rate&#39;]:
                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(res[0])), (0.15,0.9), \
                                                        xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

                if getData:
                        return res[0], spd_bins, mn_rate * self.POS.pos_sample_rate
                if getShuffledData:
                        return res[0], shuffled_rs
                else:
                        return res[0]

        def plotRollingCorrRateVSpeed(self, tetrode, cluster, minSpeed=2.0,
                                                                  sigma=3.0, **kwargs):
                &#39;&#39;&#39;
                Plots the rolling correlation of instantaneous firing rate of a given
                cell against running speed

                Parameters
                ----------
                tetrode : int
                cluster : int
                minSpeed : float
                sigma : float
                        The width of the smoothing kernel applied to the spike train to smooth it
                &#39;&#39;&#39;
                speed_filt = self.POS.speed.ravel()
                #filter for low speeds
                lowSpeedIdx = speed_filt &lt; minSpeed
                spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
                windowSize = 50
                runningCorr = np.ones_like(spk_sm)
                for i in range(len(spk_sm)):
                        runningCorr[i] = stats.pearsonr(spk_sm[i:i+windowSize],
                                                                                          speed_filt[i:i+windowSize])[0]
                speed_filt = np.ma.MaskedArray(speed_filt, lowSpeedIdx)
                spk_sm = np.ma.MaskedArray(spk_sm, lowSpeedIdx)
                # mask the running correlation where there is no rate (ie the cell fails
                # to fire)
                new_mask = np.ma.mask_or(lowSpeedIdx, spk_sm==0)
                runningCorr = np.ma.MaskedArray(runningCorr, new_mask)
                fig, ax = plt.subplots()
                fig.subplots_adjust(right=0.75)
                ax2 = ax.twinx()
                ax3 = ax.twinx()
                ax2.spines[&#34;right&#34;].set_position((&#34;axes&#34;, 1.2))
                ax3.set_frame_on(True)
                ax3.patch.set_visible(False)
                for sp in ax.spines.values():
                        sp.set_visible(False)
                ax3.spines[&#34;right&#34;].set_visible(True)

                p1, = ax.plot(speed_filt, &#39;b&#39;)
                p2, = ax2.plot(spk_sm, &#39;r&#39;)
                p3, = ax3.plot(runningCorr, &#39;k&#39;)

                ax.set_xlim(0, len(speed_filt))
                ax.set_ylim(0, np.max(speed_filt))
                ax2.set_ylim(0, np.max(spk_sm))
                ax3.set_ylim(-1, 1)

                ax.set_ylabel(&#39;Speed(cm/s)&#39;)
                ax2.set_ylabel(&#39;Instantaneous firing rate(Hz)&#39;)
                ax3.set_ylabel(&#39;Running correlation&#39;)

                ax.yaxis.label.set_color(p1.get_color())
                ax2.yaxis.label.set_color(p2.get_color())
                ax3.yaxis.label.set_color(p3.get_color())

                tkw = dict(size=4, width=1.5)
                ax.tick_params(axis=&#39;y&#39;, colors=p1.get_color(), **tkw)
                ax2.tick_params(axis=&#39;y&#39;, colors=p2.get_color(), **tkw)
                ax3.tick_params(axis=&#39;y&#39;, colors=p3.get_color(), **tkw)
                ax.tick_params(axis=&#39;x&#39;, **tkw)


        def _getTimeSmoothedSpikes(self, tetrode, cluster, sigma=3.0, shuffle=None):
                &#39;&#39;&#39;
                Returns a spike train the same length as num pos samples that has been
                smoothed in time with a gaussian kernel M in width and standard deviation
                equal to sigma

                Parameters
                --------------
                tetrode : int
                        the tetrode to use
                cluster : int
                        the cluster to use
                sigma : float
                        the standard deviation of the gaussian used to smooth the spike
                        train
                &#39;&#39;&#39;

                x1 = self.TETRODE[tetrode].getClustIdx(cluster)
                spk_sm = self.spikecalcs.smoothSpikePosCount(x1, self.POS.npos, sigma, shuffle)
                return spk_sm

        def plotFreqVSpeed(self, minSp=5, maxSp=50, spStep=5, ax=None, laserFilter=None, **kwargs):
                &#39;&#39;&#39;
                Plots running speed vs eeg frequencies and does linear regression. Also adds position sample histogram
                TODO: filter out negative frequencies - do this as default in EEG class
                Parameters
                ----------
                minSp : int
                        speeds below this are ignored
                maxSp : int
                        speeds above this are ignored
                spStep : int
                        the bin width for speed
                ax : matplotlib.axes
                        the axes in which to plot
                laser : int or None
                        whether to filter for laser on/ off events
                        None means no filtering at all
                        1 means laser is on and data is filtered for on periods
                        0 means filter for laser off periods

                &#39;&#39;&#39;

                sp = np.ma.compressed(self.POS.speed)
                if laserFilter:
                        eeg = self.EEG.eeg
                        EE = EEGCalcs(self.filename_root, thetaRange=[6,12])
                        if &#39;dip&#39; in kwargs:
                                d = kwargs[&#39;dip&#39;]
                        else:
                                d = 15.0
                        if &#39;width&#39; in kwargs:
                                w = kwargs[&#39;width&#39;]
                        else:
                                w = 0.125
                        if &#39;stimFreq&#39; in kwargs:
                                sf = kwargs[&#39;stimFreq&#39;]
                        else:
                                sf = 6.66
                        fx = EE.filterForLaser(E=eeg, width=w, dip=d, stimFreq=sf)#filters out laser stimulation artifact
                        fxx = self.EEG.eegfilter(fx)
                        self.EEG.thetaAmpPhase(fxx)#filters for theta
                        freq = self.EEG.EEGinstfreq
                else:
                        try:
                                freq = self.EEG.EEGinstfreq
                        except:
                                self.EEG.thetaAmpPhase()
                                freq = self.EEG.EEGinstfreq
                freq[freq&lt;0] = np.nan
                sp_bins = np.arange(minSp, maxSp, spStep)
                sp_dig = np.digitize(sp, sp_bins)
                freq = np.reshape(freq, (self.POS.npos, self.EEG.sample_rate/self.POS.pos_sample_rate))
                if np.ma.is_masked(self.POS.speed):
                        mask = np.ma.getmask(self.POS.speed)
                        mask = np.tile(mask.T, self.EEG.sample_rate/self.POS.pos_sample_rate)
                        freq = np.ma.MaskedArray(freq, mask=mask)
                mn_freq = np.nanmean(freq, 1)
                mn_freq = np.ma.compressed(mn_freq)
                X = [mn_freq[sp_dig==i] for i in range(len(sp_bins))]
                # remove any nans which will screw plt.boxplots ability to calculate means
                # and do the boxplot correctly
                for i,x in enumerate(X):
                        idx = ~np.isfinite(x)
                        X[i] = np.delete(x,np.nonzero(idx))
                if ax is None:
                        fig = plt.figure()
                        fig.set_facecolor(&#39;w&#39;)
                        ax = plt.gca()
                else:
                        fig = plt.gcf()
                        fig.set_facecolor(&#39;w&#39;)
                # set up some properties for the elements in the box plot
                bprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                wprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                ax.boxplot(X, positions=sp_bins, boxprops=bprops, whiskerprops=wprops)
                medians = np.array([stats.nanmedian(x) for x in X])
                nan_idx = np.isnan(medians)
                slope, intercept, r_value, p_value, std_err = stats.linregress(sp_bins[~nan_idx], medians[~nan_idx])
                minFreq = np.min(medians[~nan_idx]) - 1.0
                maxFreq = np.max(medians[~nan_idx]) + 1.0
                ax.set_ylim(minFreq, maxFreq)
#        ax.set_xlim(0, sp_bins[-1])
#               ylims = np.array(ax.get_ylim())
                xlims = np.array(ax.get_xlim())
                res = stats.theilslopes(medians[~nan_idx], sp_bins[~nan_idx], 0.90)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[0] * sp_bins[-1])), &#39;r-&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[2] * sp_bins[-1])), &#39;r--&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[3] * sp_bins[-1])), &#39;r--&#39;)
#        ax.plot([0,xlims[1]], (intercept, intercept + (sp_bins[-1] * slope)), &#39;k--&#39;, lw=2)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                ax.set_title(&#39;Intercept: {0:.3f}    Slope: {1:.5f}&#39;.format(intercept, slope))
                # add the right-hand y-axis and format
                ax1 = ax.twinx()
                # get a histogram of speed to be plotted against the right-hand y-axis
                h,e = np.histogram(np.ma.compressed(sp), bins=len(sp_bins)*10, range=(0, sp_bins[-1]))
                ax1.bar(e[0:-1], h, color=[0.6667, 0.6667, 0], linewidth=0, align=&#39;edge&#39;)
                ax1.set_ylim(0, np.max(h) * 4) # reduce the &#39;height&#39; of the secondary plot
#        ax1.set_xlim(0, sp_bins[-1]+spStep)
                ax1.set_ylabel(&#39;Position samples&#39;, color=[0.6667, 0.6667, 0])
                ax1.yaxis.set_label_coords(1.1,.15)
                ylabels = ax1.yaxis.get_majorticklabels()
                for i,xxx in enumerate(ylabels):
                        if i &gt; 1:
                                xxx.set_visible(False)
                        else:
                                xxx.set_color([0.6667, 0.6667, 0])
                yticks = ax1.yaxis.get_major_ticks()
                for i,xxx in enumerate(yticks):
                        if i &gt; 1:
                                xxx.set_visible(False)
                return ax, intercept, slope

        def plotPhaseOfFiring(self, tetrode, cluster, ax=None, **kwargs):
                &#34;&#34;&#34;
                Plots the phase of firing of a given cluster as a histogram

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.Axes
                &#34;&#34;&#34;

                phase = self._getClusterPhaseVals(tetrode, cluster)
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(211)
                        ax2 = fig.add_subplot(212)
                # make the plot like the Somogyi figures!
                fig.set_facecolor(&#39;#203C8A&#39;)
                phase = np.hstack((phase, phase + (2*np.pi)))
                ax2.hist(phase, bins=120, range=(-np.pi, 3*np.pi), color=&#39;w&#39;, histtype=&#39;stepfilled&#39;)
                t = np.arange(-np.pi, 3 * np.pi, 0.1)
                ax.plot(t, np.sin(t), &#39;w&#39;)
                ax.annotate(&#39;180&#39;, xy=(-np.pi-0.2, 0), xycoords=&#39;data&#39;, ha=&#39;right&#39;, va=&#39;center&#39;,
                                        color=&#39;w&#39;, fontsize=20)
                ax.set_axis_bgcolor(&#39;#203C8A&#39;)
                ax.set_ylim(-1.1, 1.1)
                ax.axis(&#39;off&#39;)
                ax2.set_axis_bgcolor(&#39;#203C8A&#39;)
                plt.axis(&#39;off&#39;)

        def plotPhaseInField(self, tetrode, cluster, ax=None, **kwargs):
                &#39;&#39;&#39;
                Plots theta phase of spikes in a place field (found using _getFieldLims)
                as individual colours for each run through the field
                TODO: broken
                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.Axes
                &#39;&#39;&#39;
                if not self.EEG:
                        self.EEG = EEG(self.filename_root)
                self.EEG.thetaAmpPhase()
                self.EEG.EEGphase = np.rad2deg(self.EEG.EEGphase)
                runs_to_keep, spk_in_run, run_duration = self.getFieldRuns(tetrode, cluster)
                if ax is None:
                        ax = plt.gca()
                else:
                        ax = ax
                for spks in spk_in_run:
                        ax.plot(self.POS.xy[0,spks], self.EEG.EEGphase[spks * self.pos2eegScale]+180,&#39;.&#39;)
                ax.set_title(self.filename_root.split(&#39;\\&#39;)[-1] + &#39; cluster &#39; + str(cluster) + &#39; on tetrode &#39; + str(tetrode))
                plt.show()

        def plotSpectrogram(self, eegType=&#39;eeg&#39;, ymin=0, ymax=50, ax=None, secsPerBin=2,
                                                laser=False, width=0.125, dip=15.0):
                &#39;&#39;&#39;
                Plots a spectrogram of the LFP of the whole trial

                Parameters
                --------------
                eegType : str
                        Whether to do use .eeg file or .egf file. Defaults to eeg
                ymin / ymax : int
                        Minimum/ maximum frequency (y-axis) to plot
                ax : matplotlib.pyplot.axis]
                        Which axis to add the plot to. If None a new figure window is produced
                secsPerBin : int
                        Size of the x-axis bins
                laser : bool
                        Whether to filter the eeg for laser stimulation events
                width/ dip : float
                        Parameters for Kaisser filter in eegcalcs.EEGCalcs - see there
                        for definition

                Returns
                ------------
                Plots the spectrogram
                &#39;&#39;&#39;

                if &#39;eeg&#39; in eegType:
                        E = self.EEG.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EEG.sample_rate
                elif &#39;egf&#39; in eegType:
                        E = self.EGF.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EGF.sample_rate

                EE = EEGCalcs(self.filename_root,thetaRange=[6,12])
                if laser:
                        &#39;&#39;&#39;
                        Split the eeg into the parts where the laser is on and off
                        and then reassemble for the spectrogram
                        NB this assumes the laser comes on at 600s for 20 minutes
                        and then goes off
                        &#39;&#39;&#39;
                        mask = np.ones_like(E).astype(bool)

                        mask[600*int(Fs):1800*int(Fs)] = False
                        # filter
#                       import pdb
#                       pdb.set_trace()
                        fx = EE.filterForLaser(E=E[~mask], width=width, dip=dip)
                        # reassemble
                        Etmp = np.zeros_like(E)
                        Etmp[~mask] = fx
                        Etmp[mask] = E[mask]
                        fx = Etmp

                else:
                        fx = E
                nperseg = int(Fs * secsPerBin)
                freqs, times, Sxx = signal.spectrogram(fx, Fs, nperseg=nperseg)
#               Sxx_sm = self.ratemap.blurImage(Sxx, (secsPerBin*2)+1)
                Sxx_sm = Sxx
                x, y = np.meshgrid(times, freqs)
                if ax is None:
                        plt.figure()
                        ax = plt.gca()
                        im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, cmap=&#39;RdBu&#39;,norm=colors.LogNorm())
                im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, norm=colors.LogNorm())
                ax.set_xlim(times[0], times[-1])
                ax.set_ylim(ymin, ymax)
                ax.set_xlabel(&#39;Time(s)&#39;)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                if laser:
                        ax.vlines(600,ymin,ymax)
                        ax.vlines(1800,ymin,ymax)

                        ax.set_xticks((0, 600, 1800, 2400))
                        ax.set_xticklabels((str(0), str(600), str(1800), str(2400)))
                return freqs, times, Sxx, im

        def plotEEGPower(self, E=None, eegType=&#39;eeg&#39;, smthKernelSigma=0.1875,
                                        freqBand=(6,12), outsideBand=(3,125), s2nWdth=2, xmax=125, 
                                        ymax=None, plot=True, ax=None, **kwargs):
                &#39;&#39;&#39;
                Plots the eeg power spectrum. Annotates graph around theta frequency band.

                Parameters
                -------------
                E : numpy.array
                        (Optional) numEEGSamples sized numpy array of raw eeg signal amplitude.
                eegType : str
                        (Optional) Either &#39;eeg&#39; or &#39;egf&#39;. The .eeg file type to use. Defaults to &#39;eeg&#39;
                smthKernelSigma : float
                        (Optional) number of points in the output window for gaussian filtering of eeg. This
                        value is multipled by the binsPerHz which comes from the length of the fft (derived from nextpow2 for speed).
                freqBand : two-tuple
                        (Optional) the theta-band to examine.
                outsideBand : two-tuple
                        (Optional): frequencies outside these values are ignored. NOT IMPLEMENTED.
                s2nWdth : int
                        (Optional) Determines the width of the window to calculate the signal-to-noise ratio.
                xmax : int
                        (Optional) Maximum x-value (frequency) to plot to. Defaults to 125
                ymax : int
                        (Optional) Maximum y-value to plot to. Defaults to None so plots full range
                plot : bool
                        (Optional) Whether to produce a plot
                ax : matplotlib.pyplot.axis instance
                        (Optional) The axis to plot in to.

                Returns
                -------------
                ax : matplotlib.pyplot.axis instance
                        The axis containing the plot.
                &#39;&#39;&#39;

                if E is None:
                        if &#39;eeg&#39; in eegType:
                                E = self.EEG.eeg
                                freqBand = (self.EEG.x1, self.EEG.x2)
                                if np.ma.is_masked(E):
                                        E = E.compressed()
                                sample_rate = self.EEG.sample_rate
                        elif &#39;egf&#39; in eegType:
                                E = self.EGF.eeg
                                freqBand = (self.EEG.x1, self.EEG.x2)
                                if np.ma.is_masked(E):
                                        E = E.compressed()
                                sample_rate = self.EGF.sample_rate
                else:
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        sample_rate = kwargs[&#39;sample_rate&#39;]
                nqLim = 0
                nqLim = sample_rate / 2
                origLength = len(E)
                fftLength = 2 ** self.EEG.nextpow2(origLength).astype(int)
                freqs, power = signal.periodogram(E, fs=sample_rate, return_onesided=True, nfft=fftLength)
                fftHalfLength = fftLength / 2+1
                # calculate the number of points in the gaussian window - gleaned from gaussian_filter1d
                # which lives in scipy/ndimage/filters.py
                binsPerHz = (fftHalfLength-1) / nqLim
                kernelSigma = smthKernelSigma * binsPerHz
                smthKernelWidth = 2 * int(4.0 * kernelSigma + 0.5) + 1
                gaussWin = signal.gaussian(smthKernelWidth, kernelSigma)
                # smooth the power
                sm_power = signal.fftconvolve(power, gaussWin, &#39;same&#39;)
                # normalize the smoothed power by the length of the fft
                sm_power = sm_power / np.sqrt(len(sm_power))
                # calculate some metrics
                spectrumMaskBand = np.logical_and(freqs&gt;freqBand[0], freqs&lt;freqBand[1])
                bandMaxPower = np.max(sm_power[spectrumMaskBand])
                maxBinInBand = np.argmax(sm_power[spectrumMaskBand])
                bandFreqs = freqs[spectrumMaskBand]
                freqAtBandMaxPower = bandFreqs[maxBinInBand]
                # find power in windows around peak, divide by power in rest of spectrum
                # to get SNR
                spectrumMaskPeak = np.logical_and(freqs&gt;freqAtBandMaxPower-s2nWdth/2, freqs &lt; freqAtBandMaxPower + s2nWdth/2)
                snr = np.nanmean(sm_power[spectrumMaskPeak]) / np.nanmean(sm_power[~spectrumMaskPeak])
                # collect all the following keywords into a dict for output
                dictKeys = (&#39;sm_power&#39;,&#39;freqs&#39;, &#39;spectrumMaskPeak&#39;, &#39;power&#39;,&#39;freqBand&#39;,
                &#39;freqAtBandMaxPower&#39;, &#39;bandMaxPower&#39;, &#39;xmax&#39;, &#39;ymax&#39;, &#39;snr&#39;, &#39;kernelSigma&#39;, &#39;binsPerHz&#39;)
                outDict = dict.fromkeys(dictKeys,np.nan)
                for thiskey in outDict.keys():
                        outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
                if plot:
                        if ax is None:
                                plt.figure()
                                ax = plt.gca()
                        ax.plot(freqs, power, alpha=0.5, color=[0.8627, 0.8627, 0.8627])
                        # ax.hold(1)
                        ax.plot(freqs, sm_power)
                        r = Rectangle((freqBand[0],0), width=np.diff(freqBand)[0], height=np.diff(ax.get_ylim())[0], alpha=0.25, color=&#39;r&#39;, ec=&#39;none&#39;)
                        ax.add_patch(r)
                        ax.set_xlim(0,xmax)
                        ax.set_ylim(0, bandMaxPower / 0.8)
                        ax.set_xlabel(&#39;Frequency&#39;)
                        ax.set_ylabel(&#39;Power&#39;)
                        ax.text(x = freqBand[1] / 0.9, y = bandMaxPower, s = str(freqAtBandMaxPower)[0:4], fontsize=20)
                return ax

        def plotClusterSpace(self, tetrode, clusters=None, ax=None, bins=256,**kwargs):
                &#39;&#39;&#39;
                Plots the cluster space for the given tetrode

                Parameters
                ----------
                tetrode : int
                        the tetrode cluster space to plot
                clusters : int or list or np.array
                        the clusters to colour in
                ax : matplotlib.pyplot.axis
                        the axis to plot into
                bins : int
                        the number of bins to use in the histogram
                **kwargs :
                        can include a param keyword for the parameter to construct the
                        histogram from - this defaults to amplitude (&#39;Amp&#39;) but can be any
                        valid key in the getParam method of the Tetrode class

                Returns
                -------
                fig: handle to figure window
                &#39;&#39;&#39;

                if clusters is not None and not isinstance(clusters, (np.ndarray, list)):
                        clusters = [clusters]  # ie needs to be iterable
                waves = self.TETRODE[tetrode].waveforms
                if self.TETRODE[tetrode].volts:
                        waves = (waves * 128) / self.TETRODE[tetrode].scaling[:, np.newaxis]
                        waves = waves.astype(int)
                cutfile = self.TETRODE[tetrode].cut

                if cutfile is not None:
                        cutfile = np.array(cutfile)
                if &#39;param&#39; in kwargs.keys():
                        param = kwargs[&#39;param&#39;]
                else:
                        param = &#39;Amp&#39;
                amps = self.TETRODE[tetrode].getParam(waves, param=param)
                bad_electrodes = np.setdiff1d(np.array(range(4)),np.array(np.sum(amps,0).nonzero())[0])
                cmap = np.tile(tcols.colours[0],(bins,1))
                cmap[0] = (1,1,1)
                cmap = colors.ListedColormap(cmap)
                cmap._init()
                alpha_vals = np.ones(cmap.N+3)
                alpha_vals[0] = 0
                cmap._lut[:,-1] = alpha_vals
                cmb = combinations(range(4),2)
                if &#39;figure&#39; in kwargs.keys():
                        fig = kwargs.pop(&#39;figure&#39;)
                else:
                        fig = plt.figure()
                if ax is None:
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax.axis(&#39;off&#39;)
#        fig = plt.gcf()
                rect = ax.get_position().bounds
                grid = ImageGrid(fig, rect, nrows_ncols= (2,3), axes_pad=0.1)
                if &#39;Amp&#39; in param:
                        myRange = [[0,256],[0,256]]
                else:
                        myRange = None
                for i, c in enumerate(cmb):
                        if c not in bad_electrodes:
                                H = np.histogram2d(amps[:,c[0]], amps[:,c[1]], range = myRange, bins=bins)
                                grid[i].imshow(H[0], cmap=cmap, interpolation=&#39;nearest&#39;)
                                if clusters is not None:
                                        for thisclust in clusters:
                                                if &#39;clustColour&#39; in kwargs.keys():
                                                        clustColour = kwargs[&#39;clustColour&#39;]
                                                else:
                                                        clustColour = tcols.colours[thisclust]
                                                clustidx = (cutfile==thisclust).nonzero()[0]
                                                H = np.histogram2d(amps[clustidx,c[0]],amps[clustidx,c[1]], range=myRange, bins=bins)
                                                H = H[0]
                                                H = signal.convolve2d(H, np.ones((3, 3)), mode=&#39;same&#39;)
                                                clustCMap = np.tile(clustColour,(bins,1))
                                                clustCMap[0] = (1,1,1)
                                                clustCMap = colors.ListedColormap(clustCMap)
                                                clustCMap._init()
                                                clustCMap._lut[:,-1] = alpha_vals
                                                grid[i].imshow(H, cmap=clustCMap, interpolation=&#39;nearest&#39;)
                        s = str(c[0]+1) + &#39; v &#39; + str(c[1]+1)
                        grid[i].text(0.05,0.95, s, va=&#39;top&#39;, ha=&#39;left&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)
                        grid[i].set_xlim([0,bins])
                        grid[i].set_ylim([0,bins])
                        grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                plt.setp([a.get_xticklabels() for a in grid], visible=False)
                plt.setp([a.get_yticklabels() for a in grid], visible=False)
                return fig

        def plotXCorr(self, tetrode, clusters, ax=None, Trange=(-500,500), bins=None, annotate=True, **kwargs):
                &#39;&#39;&#39;
                Plots the temporal autocorrelogram (defaults to +/- 500ms)
                TODO: needs to be able to take in two tetrodes &amp; make sure Trange in ms

                Parameters
                ----------
                tetrode : int
                clusters : int or list
                ax : matplotlib.Axes
                        The axes to plot into. If None a new figure window is created
                TRange : two-tuple
                        The range over which to examine the events. Zero time is the occurance of the event
                bins : int
                        The number of bins to assign the data to
                annotate : bool
                        Whether to add the cluster identities to the figure axis
                **kwargs
                        if &#39;add_peak_rate&#39; is in the kwargs then that is also added to the axes
                &#39;&#39;&#39;
                if isinstance(clusters, (np.ndarray, list, int)):
                        clusters = [clusters]
                if isinstance(tetrode, (np.ndarray, list, int)):
                        tetrode = [tetrode]
                duration = np.diff(Trange)
                if bins is None:
                        bins = 201
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                if len(clusters) == 1:
                        cluster_a = cluster_b = clusters[0]
                elif len(clusters) == 2:
                        cluster_a = clusters[0]
                        cluster_b = clusters[1]
                if len(tetrode) == 1:
                        tetrode_a = tetrode[0]
                        tetrode_b = None
                elif len(tetrode) == 2:
                        tetrode_a = tetrode[0]
                        tetrode_b = tetrode[1]
                Trange = np.array(Trange)
                timebase = self.TETRODE[tetrode_a].timebase
                x1 = self.TETRODE[tetrode_a].getClustTS(cluster_a) / (timebase/1000)
                if tetrode_b is None:
                        if cluster_b is None:
                                x2 = x1
                                cluster_b = cluster_a
                        else:
                                x2 = self.TETRODE[tetrode_a].getClustTS(cluster_b) / (timebase/1000)
                else:
                        x2 = self.TETRODE[tetrode_b].getClustTS(cluster_b) / (timebase/1000)
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                        if cluster_b is not None:
                                x2PosSamp = (x2 / (1000 / self.POS.pos_sample_rate)).astype(int)
                                x2 = x2[np.in1d(x2PosSamp, idx)]
                y = self.spikecalcs.xcorr(x1, x2, Trange=Trange)
                h = ax.hist(y[y != 0], bins=bins, range=Trange, color=&#39;k&#39;, histtype=&#39;stepfilled&#39;)
                ax.set_xlim(Trange)
                if annotate:
                        if cluster_b is None:
                                cond_rate = np.count_nonzero(y == 0) / np.float(duration)
                                ax.text(0.55, .9, &#34;{0:.4}&#34;.format(str(cond_rate)), ha=&#39;center&#39;, va=&#39;center&#39;,
                                                transform=ax.transAxes)
                        else:
                                if np.logical_or((tetrode_a == tetrode_b), tetrode_b is None):
                                        if (cluster_a == cluster_b):
                                                #autocorr being done so get theta modulation
                                                modIdx = self.spikecalcs.thetaModIdx(x1)
                                                ax.set_title(&#39;Cluster {0} vs Cluster {1}\ntheta modulation: {2:.4f}&#39;.format(cluster_a, cluster_b, modIdx))
                                                if &#34;add_peak_rate&#34; in kwargs:
                                                        if kwargs[&#39;add_peak_rate&#39;]:
                                                                ax.annotate(&#39;{:.2f}&#39;.format(np.max(modIdx)), (0.15,0.9), \
                                                                                xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

        #                    ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b) +&#39;\ntheta modulation=&#39; + str(modIdx))
                                else:
                                        ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b))
                ax.set_xlabel(&#39;Time(ms)&#39;)
                ax.set_xticks((Trange[0], 0, Trange[1]))
                ax.set_xticklabels((str(Trange[0]), &#39;0&#39;, str(Trange[1])))
                ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                ax.set_yticklabels(&#39;&#39;)
                ax.spines[&#39;right&#39;].set_visible(False)
                ax.spines[&#39;top&#39;].set_visible(False)
                ax.spines[&#39;left&#39;].set_visible(False)
                ax.xaxis.set_ticks_position(&#39;bottom&#39;)
                return ax, h

        def getThetaModIdx(self, tetrode, cluster):
                &#39;&#39;&#39;
                Calculates the theta modulation index of a clusters autocorrelogram
                as the difference between the first trough and second peak of the
                autocorrelogram (actually the difference over their sum)

                Parameters
                --------------
                tetrode : int
                        The tetrode the cluster is on
                cluster : int
                        The cluster identity
                Returns
                -------------
                thetaModulation : int
                        The depth of theta modulation
                &#39;&#39;&#39;
                x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                thetaMod = self.spikecalcs.thetaModIdx(x1)
                return thetaMod

        def getThetaModIdx2(self, tetrode, cluster):
                &#39;&#39;&#39;
                Wrapper for thetaModIdxV2 in spikecalcs.py

                Parameters
                --------------
                tetrode : int
                        The tetrode the cluster is on
                cluster : int
                        The cluster identity
                Returns
                -------------
                thetaModulation : int
                        The depth of theta modulation
                &#39;&#39;&#39;

                x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
                if self.posFilter:
                        idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                        x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x1 = x1[np.in1d(x1PosSamp, idx)]
                thetaMod = self.spikecalcs.thetaModIdxV2(x1)
                return thetaMod

        def plotWaveforms(self, tetrode, clusters, ax=None, **kwargs):
                &#34;&#34;&#34;
                Plots spike waveforms on all four wires for a given tetrode/ cluster
                The units for the plots are *real* in the sense that the x-axis is in
                ms and the y-axis is in micro-volts. The axes limits are set up so the 
                ratio between the x and y axes is 100

                Parameters
                ----------
                tetrode : int
                clusters : int or list
                ax : matplotlib.Axes
                        the axes to plot into. If None a new figure window is created.
                &#34;&#34;&#34;
                waves = self.TETRODE[tetrode].waveforms
                clust_idx = self.TETRODE[tetrode].cut == clusters
                clust_waves = waves[clust_idx, :, :]
                gains = self.TETRODE[tetrode].gains
                samps_per_spike = int(self.TETRODE[tetrode].header[&#39;samples_per_spike&#39;])
                clust_waves = clust_waves * 1e6 # now in uv
                ADC_scale = int(self.setheader[&#39;ADC_fullscale_mv&#39;])
                axes_scales = (ADC_scale / gains.astype(float)) * 1000 # axes limits in uv
                if ~np.any(clust_idx):
                        return
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        fig = kwargs[&#39;figure&#39;]
                        ax = ax
                ax.axis(&#39;off&#39;)
                rect = ax.get_position().bounds
                x = np.linspace(0, 0.001, samps_per_spike)
                if &#39;clustColour&#39; in kwargs.keys():
                        clustColour = kwargs[&#39;clustColour&#39;]
                else:
                        if clusters is None:
                                clustColour = tcols.colours[0]
                        else:
                                clustColour = tcols.colours[clusters]
                grid = ImageGrid(fig, rect, nrows_ncols= (1, 4), axes_pad=0.1, add_all=True, share_all=True)
                for i in range(4):
                        lc = LineCollection(list(zip(x,y) for y in np.squeeze(clust_waves[:, i, :])))
                        lc.set_rasterized(True)
                        lc.set_color(clustColour)
                        grid[i].add_collection(lc)
                        grid[i].plot(x, np.squeeze(np.mean(clust_waves[:, i, :], 0)), &#39;w-&#39;)
                        grid[i].set_aspect(2.5e-6*(ADC_scale/1000.))
                        grid[i].set_xlim(0, 0.001)
                        grid[i].set_ylim(-axes_scales[i], axes_scales[i])
                        grid[i].set_rasterized(True)
                        grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                        grid[i].text(0.9,0.95, str(i+1), va=&#39;top&#39;, ha=&#39;right&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)

                plt.setp([a.get_xticklabels() for a in grid], visible=False)
                plt.setp([a.get_yticklabels() for a in grid], visible=False)


        def plotSAC(self, tetrode, clusters, ax=None, binsize=3, **kwargs):
                &#34;&#34;&#34;
                Plots the spatial autocorrelogram of the given tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.pyplot.axis
                        plots into this axis
                binsize : int
                        size of bins (cms)

                See Also
                --------
                        plotFullSAC

                &#34;&#34;&#34;
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, **kwargs)[0]
                nodwell = ~np.isfinite(rmap)
                ret = self.autoCorr2D(rmap, nodwell)
                ax.imshow(ret, interpolation=&#39;nearest&#39;, origin=&#39;lower&#39;)
                ax.set_aspect(&#39;equal&#39;)
                plt.setp(ax.get_xticklabels(), visible=False)
                plt.setp(ax.get_yticklabels(), visible=False)
                return ax

        def plotFullSAC(self, tetrode, clusters, ax=None, binsize=3, limit2mask=False, plot=True, **kwargs):
                &#34;&#34;&#34;
                Plots the full SAC ie including the edges and colours the central area in colour
                and the outlying bits (outside the mask area used to calculate gridness) in black and white

                Parameters
                ----------
                tetrode : int
                cluster : int
                ax : matplotlib.pyplot.axis
                        plots into this axis
                binsize : int
                        size of bins (cms)

                &#34;&#34;&#34;
                if plot:
                        if ax is None:
                                fig = plt.figure()
                                ax = fig.add_subplot(111)
                if &#39;step&#39; in kwargs.keys():
                        step = kwargs.pop(&#39;step&#39;)
                else:
                        step = 30
                rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, limit2mask=limit2mask, **kwargs)[0]
                nodwell = np.isnan(rmap)
                ret = self.autoCorr2D(rmap, nodwell)
                dct = self.getMeasures(ret, step=step)
                if &#39;gaussian&#39; in kwargs.keys():
                        kwargs.pop(&#39;gaussian&#39;)
                if plot:
                        print(&#39;\nGridness: {0}\nOrientation: {1}\nScale: {2}&#39;.format(dct[&#39;gridness&#39;], dct[&#39;orientation&#39;], dct[&#39;scale&#39;]))
                        self.show(ret, dct, ax=ax, **kwargs)
                return dct

        def getFieldRuns(self, tetrode, cluster, binsize=3):
                &#39;&#39;&#39;
                Extracts the runs through a place field of a given cluster on a given
                tetrode and returns the indices of the runs that are kept (defaults to
                at least 5 spikes needing to be fired) and the indices of the spikes in
                the run and the duration of each run

                Parameters
                ----------
                tetrode : int
                cluster : int
                binsize : int
                        size of bins (cms)

                Returns
                -------
                data : tuple
                        The runs retained, the spikes in the run and the run duration
                &#39;&#39;&#39;

                # label is a mask of the place field - this could be hijacked to cover the whole track
                label, xe, ye = self._getFieldLims(tetrode, cluster, binsize)
                S = skimage.measure.regionprops(label)
                areas = [s[&#39;area&#39;] for s in S]# get the biggest field
                bigFieldIdx = np.argmax(areas)
                bigFieldProps = S[bigFieldIdx]
                binCoords = bigFieldProps.coords
                min_field_edge = np.min(binCoords[:,1])
                max_field_edge = np.max(binCoords[:,1])
                x_coord_field_min = xe[min_field_edge]
                x_coord_field_max = xe[max_field_edge]
                xy = self._getPath()
                x_field_bool = np.logical_and(xy[0] &gt; x_coord_field_min,
                                                                  xy[0] &lt; x_coord_field_max)
                # find the runs with spikes
                run_indices = x_field_bool.nonzero()
                # get a list of runs
                runs = np.array_split(run_indices[0], np.where(np.diff(run_indices[0])&gt;10)[0]+1)
                # there might be short runs through the field so calculate the min distance
                # across the largest part of the field - done so this method can hopefully
                # account for runs in open fields as well as linear tracks
                ppb = int(self.POS.header[&#39;pixels_per_metre&#39;]) / 100. # pixels per bin
                dist2CrossField = bigFieldProps[&#39;major_axis_length&#39;] * ppb
                # get the spike indices into position data
                idx = self.TETRODE[tetrode].getClustIdx(cluster)
                runs_to_keep = []
                spks_in_run = []
                run_duration = []
                for run in runs:
                        if np.nansum(np.hypot(np.diff(xy[0,run]),np.diff(xy[1,run]))) &gt; (dist2CrossField / 2): # be conservative and take 1/2 dist
                                if np.intersect1d(run, idx).any():
                                        if len(np.intersect1d(run, idx)) &gt; self._min_spks:# if there are &gt;5 spikes keep run
                                                runs_to_keep.append(run)
                                                spks_in_run.append(np.intersect1d(run, idx))
                                                run_duration.append((run[-1] - run[0])/float(self.POS.pos_sample_rate))
                return runs_to_keep, spks_in_run, run_duration

        def tortuosity(self, xy=None):
                &#39;&#39;&#39;
                Parameters
                -----------
                xy - numpy.array
                        2xm matrix of xy positions. Default is None so will use this
                        instances xy array in POS

                Returns
                --------
                tortuosity : float
                        tortuosity index calculated as follows:
                        T = sum(path_segment / segment_straight_line) / n_segments
                        n_segments is the number of one second segments per trial
                &#39;&#39;&#39;

                if xy is None:
                        xy = self._getPath()
                T = np.zeros(int(np.shape(xy)[1]/50))
                idx = 0
                for i in xrange(0, xy.shape[1]-50, 50):
                        straight_line = np.hypot(xy[0,i] - xy[0,i+50], xy[1,i] - xy[1,i+50])
                        path_segment = np.nansum(np.hypot(np.diff(xy[0,i:i+50]),np.diff(xy[1,i:i+50])))
                        T[idx] = path_segment / straight_line
                        idx += 1
                toobigbool = T &gt; 100
                T = np.delete(T, toobigbool.nonzero())
                zerobool = T==0
                T = np.delete(T, zerobool.nonzero())
                T = np.delete(T, np.isinf(T).nonzero())
                T = np.delete(T, np.isnan(T).nonzero())
                return np.sum(T) / len(T)

        def getThigmotaxisIndex(self):
                &#39;&#39;&#39;
                Currently fucked
                Calculates the ratio of time spent in the middle of the environment
                to the amount of time spent in the central part
                &#39;&#39;&#39;
                dwellmap = self._getMap(smooth=False)[0] # unsmoothed dwell map
                # simply calculate the sums in the corners and see if this 
                # goes above some threshold
                corner_sz = 3
                tl = dwellmap[0:corner_sz, 0:corner_sz]
                tr = dwellmap[0:corner_sz, -corner_sz:]
                bl = dwellmap[-corner_sz:, 0:corner_sz]
                br = dwellmap[-corner_sz:, -corner_sz:]
                corner_dwell = np.sum([tl, tr, bl, br])

                if corner_dwell &gt; 20:
                        shape = &#39;square&#39;

                else:
                        shape = &#39;circle&#39;

        def getBorderScore(self, tetrode, cluster, debug=False, **kwargs):
                &#39;&#39;&#39;
                Calculates the border score in a similar way to how the Moser group did
                but can also deal with circular environments as well as square ones

                Wrapper for fieldcalcs getBorderScore - see there for docs

                Parameters
                ----------
                tetrode : int
                cluster : int
                debug : bool

                See Also
                --------
                fieldcalcs.FieldCalcs.getBorderScore
                &#39;&#39;&#39;

                A = self._getMap(tetrode, cluster, **kwargs)[0]
                dwellmap = self._getMap(smooth=None)[0]
                # simply calculate the sums in the corners and see if this
                # goes above some threshold
                corner_sz = 3
                tl = dwellmap[0:corner_sz, 0:corner_sz]
                tr = dwellmap[0:corner_sz, -corner_sz:]
                bl = dwellmap[-corner_sz:, 0:corner_sz]
                br = dwellmap[-corner_sz:, -corner_sz:]
                corner_dwell = np.sum([tl, tr, bl, br])

                A_rows, A_cols = np.shape(A)

                if corner_dwell &gt; 20:
                        shape = &#39;square&#39;
                else:
                        shape = &#39;circle&#39;
                return self.fieldcalcs.getBorderScore(A, shape=shape, debug=debug)

        def plotDirFilteredRmaps(self, tetrode, cluster, maptype=&#39;rmap&#39;, **kwargs):
                &#39;&#39;&#39;
                Plots out directionally filtered ratemaps for the tetrode/ cluster

                Parameters
                ----------
                tetrode : int
                cluster : int
                maptype : str
                        Valid values include &#39;rmap&#39;, &#39;polar&#39;, &#39;xcorr&#39;
                &#39;&#39;&#39;
                inc = 8.0
                step = 360/inc
                dirs_st = np.arange(-step/2, 360-(step/2), step)
                dirs_en = np.arange(step/2, 360, step)
                dirs_st[0] = dirs_en[-1]

                if &#39;polar&#39; in maptype:
                        fig, axes = plt.subplots(nrows=3, ncols=3, subplot_kw={&#39;projection&#39;: &#39;polar&#39;})
                else:
                        fig, axes = plt.subplots(nrows=3, ncols=3)
                ax0 = axes[0][0] # top-left
                ax1 = axes[0][1] # top-middle
                ax2 = axes[0][2] # top-right
                ax3 = axes[1][0] # middle-left
                ax4 = axes[1][1] # middle
                ax5 = axes[1][2] # middle-right
                ax6 = axes[2][0] # bottom-left
                ax7 = axes[2][1] # bottom-middle
                ax8 = axes[2][2] # bottom-right

                max_rate = 0
                for d in zip(dirs_st, dirs_en):
                        self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                        if &#39;polar&#39; in maptype:
                                rmap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;)[0]
                        elif &#39;xcorr&#39; in maptype:
                                x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                                rmap = self.spikecalcs.xcorr(x1, x1, Trange=np.array([-500, 500]))
                        else:
                                rmap = self._getMap(tetrode=tetrode, cluster=cluster)[0]
                        if np.nanmax(rmap) &gt; max_rate:
                                max_rate = np.nanmax(rmap)

                from collections import OrderedDict
                dir_rates = OrderedDict.fromkeys(dirs_st, None)

                for d in zip(dirs_st, dirs_en, [ax5,ax2,ax1,ax0,ax3,ax6,ax7,ax8]):
                        self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                        npos = np.count_nonzero(np.ma.compressed(~self.POS.dir.mask))
                        print(&#34;npos = {}&#34;.format(npos))
                        nspikes = np.count_nonzero(np.ma.compressed(~self.TETRODE[tetrode].getClustSpks(cluster).mask[:,0,0]))
                        print(&#34;nspikes = {}&#34;.format(nspikes))
                        dir_rates[d[0]] = nspikes# / (npos/50.0)
                        if &#39;spikes&#39; in maptype:
                                self.plotSpikesOnPath(tetrode, cluster, ax=d[2], markersize=4)
                        elif &#39;rmap&#39; in maptype:
                                self._plotMap(tetrode, cluster, ax=d[2], vmax=max_rate)
                        elif &#39;polar&#39; in maptype:
                                self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=d[2], vmax=max_rate)
                        elif &#39;xcorr&#39; in maptype:
                                self.plotXCorr(tetrode, cluster, ax=d[2])
                                x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                                print(&#34;x1 len = {}&#34;.format(len(x1)))
                                dir_rates[d[0]] = self.spikecalcs.thetaBandMaxFreq(x1)
                                d[2].set_xlabel(&#39;&#39;)
                                d[2].set_title(&#39;&#39;)
                                d[2].set_xticklabels(&#39;&#39;)
                        d[2].set_title(&#34;nspikes = {}&#34;.format(nspikes))
                self.posFilter = None
                if &#39;spikes&#39; in maptype:
                        self.plotSpikesOnPath(tetrode, cluster, ax=ax4)
                elif &#39;rmap&#39; in maptype:
                        self._plotMap(tetrode, cluster, ax=ax4)
                elif &#39;polar&#39; in maptype:
                        self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=ax4)
                elif &#39;xcorr&#39; in maptype:
                        self.plotXCorr(tetrode, cluster, ax=ax4)
                        ax4.set_xlabel(&#39;&#39;)
                        ax4.set_title(&#39;&#39;)
                        ax4.set_xticklabels(&#39;&#39;)
                return dir_rates</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ephysiopy.dacq2py.axonaIO.IO" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO">IO</a></li>
<li><a title="ephysiopy.dacq2py.gridcell.SAC" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC">SAC</a></li>
<li>builtins.dict</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ephysiopy.dacq2py.OptoCluster.OptoClusterSummary" href="OptoCluster.html#ephysiopy.dacq2py.OptoCluster.OptoClusterSummary">OptoClusterSummary</a></li>
<li><a title="ephysiopy.dacq2py.lineartrack.LTrack" href="lineartrack.html#ephysiopy.dacq2py.lineartrack.LTrack">LTrack</a></li>
<li><a title="ephysiopy.dacq2py.lineartrack.LinearTrackTrial" href="lineartrack.html#ephysiopy.dacq2py.lineartrack.LinearTrackTrial">LinearTrackTrial</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.EEG"><code class="name">var <span class="ident">EEG</span></code></dt>
<dd>
<section class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>self.EEG</code>:</dt>
<dd>eeg data and header</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def EEG(self):
        &#39;&#39;&#39;
        Returns
        ------------
        self.EEG:
                eeg data and header
        &#39;&#39;&#39;
        if self._EEG is None:
                try:
                        self._EEG = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file)
                        self.pos2eegScale = int(self.EEG.sample_rate /
                                                                        self.POS.pos_sample_rate)
                except IOError:
                        self._EEG = None
        return self._EEG</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.EGF"><code class="name">var <span class="ident">EGF</span></code></dt>
<dd>
<section class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>self.EGF</code>:</dt>
<dd>eeg data and header from .egf file</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def EGF(self):
        &#39;&#39;&#39;
        Returns
        ------------
        self.EGF:
                eeg data and header from .egf file
        &#39;&#39;&#39;
        if self._EGF is None:
                try:
                        self._EGF = axonaIO.EEG(self.filename_root, eeg_file=self.eeg_file, egf=1)
                        self.pos2egfScale = int(self.EGF.sample_rate /
                                                                        self.POS.pos_sample_rate)
                except IOError:
                        self._EGF = None
        return self._EGF</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.POS"><code class="name">var <span class="ident">POS</span></code></dt>
<dd>
<section class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>self.POS</code>:</dt>
<dd>Contains raw and post-processed position data</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def POS(self):
        &#39;&#39;&#39;
        Returns
        -----------
        self.POS:
                Contains raw and post-processed position data
        &#39;&#39;&#39;

        if self._POS is None:
                try:
                        self._POS = axonaIO.Pos(self.filename_root, cm=self.useCm)
                        self._POS.postprocesspos()
                        self._xlims = (int(self.POS.xy[0,:].min()),
                                                   int(self.POS.xy[0,:].max()))
                        self._ylims = (int(self.POS.xy[1,:].min()),
                                                   int(self.POS.xy[1,:].max()))
                        self.pos_weights = np.ravel(np.ones((1, self.POS.npos), dtype=np.float) / self.POS.pos_sample_rate)
                        self.ratemap = binning.RateMap(self.POS.xy, self.POS.dir, self.POS.speed, self.pos_weights, self.POS.ppm, self.useCm)
                except IOError:
                        self._POS = None
        return self._POS</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.STM"><code class="name">var <span class="ident">STM</span></code></dt>
<dd>
<section class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>self.Stim</code>:</dt>
<dd>Stimulation data and header + some extras parsed from pos, eeg and set files</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def STM(self):
        &#39;&#39;&#39;
        Returns
        ------------
        self.Stim:
                Stimulation data and header + some extras parsed from pos, eeg and set files
        &#39;&#39;&#39;
        if self._STM is None:
                try:
                        self._STM = axonaIO.Stim(self.filename_root)
                        &#39;&#39;&#39;
                        update the STM dict with some relevant values from the .set file and the headers
                        of the eeg and pos files
                        &#39;&#39;&#39;
                        posHdr = self.getHeader(self.filename_root + &#39;.pos&#39;)
                        eegHdr = self.getHeader(self.filename_root + &#39;.eeg&#39;)
                        self._STM[&#39;posSampRate&#39;] = self.getHeaderVal(posHdr, &#39;sample_rate&#39;)
                        self._STM[&#39;eegSampRate&#39;] = self.getHeaderVal(eegHdr, &#39;sample_rate&#39;)
                        try:
                                egfHdr = self.getHeader(self.filename_root + &#39;.egf&#39;)
                                self._STM[&#39;egfSampRate&#39;] = self.getHeaderVal(egfHdr, &#39;sample_rate&#39;)
                        except:
                                pass
                        stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;]) / int(1000) # get into ms
                        self._STM[&#39;off&#39;] = self._STM[&#39;on&#39;] + int(stim_pwidth)
                        &#34;&#34;&#34;
                        There are a set of key / value pairs in the set file that
                        correspond to the patterns/ protocols specified in the
                        Stimulator menu in DACQ. Extract those items now...
                        There are five possibe &#34;patterns&#34; that can be used in a trial. Those patterns 
                        consist of either &#34;Pause (no stimulation)&#34; or some user-defined stimulation pattern.
                        Whether or not one of the five was used is specified in &#34;stim_patternmask_n&#34; where n 
                        is 1-5. Confusingly in dacqUSB these 5 things are called &#34;Protocols&#34; accessed from
                        the menu Stimulator/Protocols... within that window they are actually called &#34;Phase 1&#34;,
                        &#34;Phase 2&#34; etc. To keep everything in order it&#39;s best to iterate through using a for loop
                        as a dict is not guaranteed to be ordered and I cba to use an OrderedDict.
                        In dacqUSB nomencalture the pattern is actually the stimulation you 
                        want to apply i.e. 10ms pulse every 150ms or whatever. The &#34;pattern&#34; is what is applied
                        within every Phase.
                        &#34;&#34;&#34;
                        # phase_info : a dict for each phase that is active
                        phase_info = {&#39;startTime&#39;: None, &#39;duration&#39;: None, &#39;name&#39;: None, &#39;pulseWidth&#39;: None, &#39;pulsePause&#39;: None};
                        stim_dict = {};
                        stim_patt_dict = {};
                        for k,v in self.setheader.iteritems():
                                if k.startswith(&#34;stim_patternmask_&#34;):
                                        if (int(v) == 1):
                                                # get the number of the phase
                                                phase_num = k[-1]
                                                stim_dict[&#39;Phase_&#39; + phase_num] = phase_info.copy();
                                if k.startswith(&#34;stim_patt_&#34;):
                                        stim_patt_dict[k] = v;
                        self.patt_dict = stim_patt_dict
                        for k,v in stim_dict.iteritems():
                                phase_num = k[-1]
                                stim_dict[k][&#39;duration&#39;] = int(self.setheader[&#39;stim_patterntimes_&#39; + phase_num])
                                phase_name = self.setheader[&#39;stim_patternnames_&#39; + phase_num]
                                stim_dict[k][&#39;name&#39;] = phase_name
                                if not (phase_name.startswith(&#34;Pause&#34;)):
                                        # find the matching string in the stim_patt_dict
                                        for kk,vv in stim_patt_dict.iteritems():
                                                split_str = vv.split(&#39;&#34;&#39;);
                                                patt_name = split_str[1]
                                                if (patt_name == phase_name):
                                                        ss = split_str[2].split()
                                                        stim_dict[k][&#39;pulseWidth&#39;] = int(ss[0])
                                                        stim_dict[k][&#39;pulsePause&#39;] = int(ss[2])
                        # make the dict ordered by Phase number
                        self.STM[&#39;stim_params&#39;] = OrderedDict(sorted(stim_dict.items()));
                except IOError:
                        self._STM = None
        return self._STM</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.posFilter"><code class="name">var <span class="ident">posFilter</span></code></dt>
<dd>
<section class="desc"><p>self.posFilter : dict
Keys are strings such as 'speed', 'time' etc. Values are n x 2 arrays of values <em>to keep</em></p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def posFilter(self):
        &#39;&#39;&#39;
        self.posFilter : dict
                Keys are strings such as &#39;speed&#39;, &#39;time&#39; etc. Values are n x 2 arrays of values *to keep*
        &#39;&#39;&#39;
        return self._posFilter</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.ppm"><code class="name">var <span class="ident">ppm</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def ppm(self):
        return self.__ppm</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.setheader"><code class="name">var <span class="ident">setheader</span></code></dt>
<dd>
<section class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>self.dict</code>: <code>dict</code></dt>
<dd>Matches contents of .set file with keys and values all mapped as strings</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def setheader(self):
        &#39;&#39;&#39;
        Returns
        ----------
        self.dict: dict
                Matches contents of .set file with keys and values all mapped as strings
        &#39;&#39;&#39;

        if self._setheader is None:
                try:
                        self._setheader = self.getHeader(self.filename_root + &#39;.set&#39;)
                except IOError:
                        self._setheader = None
        return self._setheader</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.adjust_median_speed"><code class="name flex">
<span>def <span class="ident">adjust_median_speed</span></span>(<span>self, min_speed=5, plot=True)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>min_speed</code></strong> :&ensp;<code>float</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_median_speed(self, min_speed=5, plot=True):
        &#39;&#39;&#39;
        Parameters
        ----------
        min_speed : float
        plot : bool
        &#39;&#39;&#39;
        grandMedian = stats.nanmedian(self.POS.speed, 1)
        sortedSpIdx = np.argsort(self.POS.speed)
        sortedSp = np.sort(self.POS.speed)
        indMedian = np.nonzero(sortedSp &gt;= grandMedian)[1][0]
        indFirstOverThresh = np.nonzero(sortedSp &gt;= min_speed)[1][0]
        indLastNotNan = np.nonzero(~np.isnan(sortedSp))[1][-1]
        halfWidth = np.min([indMedian-indFirstOverThresh, indLastNotNan-indMedian])
        if plot:
                fig = plt.figure()
                ax = fig.add_subplot(111)
                maxSp = sortedSp[0, indLastNotNan]
                L = sortedSp.shape[1]
                rect = Rectangle(xy=(0, indMedian-halfWidth), width=maxSp, height=indMedian+halfWidth/2, color=&#39;b&#39;, alpha=0.5)
                ax.add_patch(rect)
                ax.plot(sortedSp[0, 0:indLastNotNan], np.arange(indLastNotNan), &#39;k&#39;, lw=2)
                ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                ax.set_ylabel(&#39;Cumulative number of samples&#39;)
                if indLastNotNan != L:
                        ax.plot((0, maxSp), (indLastNotNan+1, indLastNotNan+1), &#39;r-&#39;)
                        ax.plot((0, maxSp), (L, L), &#39;r-&#39;)
                ax.set_xlim(0, maxSp)
                ax.set_ylim(0, L)
                ax.plot((0, maxSp), (indMedian, indMedian), &#39;b&#39;, lw=1)
                ax.plot((grandMedian, grandMedian), (0, indMedian), &#39;b-&#39;)
                ax.plot(grandMedian, indMedian, &#39;bo&#39;, ms=12)
                ax.plot((0, maxSp), (indFirstOverThresh, indFirstOverThresh), &#39;b&#39;, lw=1)
                ax.plot((min_speed, min_speed), (0, indFirstOverThresh), &#39;b--&#39;)
                ax.plot(min_speed, indFirstOverThresh, &#39;bo&#39;, ms=12)
        return sortedSpIdx[indMedian-halfWidth:indMedian+halfWidth]</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getBorderScore"><code class="name flex">
<span>def <span class="ident">getBorderScore</span></span>(<span>self, tetrode, cluster, debug=False, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates the border score in a similar way to how the Moser group did
but can also deal with circular environments as well as square ones</p>
<p>Wrapper for fieldcalcs getBorderScore - see there for docs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>fieldcalcs.FieldCalcs.getBorderScore</code></p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBorderScore(self, tetrode, cluster, debug=False, **kwargs):
        &#39;&#39;&#39;
        Calculates the border score in a similar way to how the Moser group did
        but can also deal with circular environments as well as square ones

        Wrapper for fieldcalcs getBorderScore - see there for docs

        Parameters
        ----------
        tetrode : int
        cluster : int
        debug : bool

        See Also
        --------
        fieldcalcs.FieldCalcs.getBorderScore
        &#39;&#39;&#39;

        A = self._getMap(tetrode, cluster, **kwargs)[0]
        dwellmap = self._getMap(smooth=None)[0]
        # simply calculate the sums in the corners and see if this
        # goes above some threshold
        corner_sz = 3
        tl = dwellmap[0:corner_sz, 0:corner_sz]
        tr = dwellmap[0:corner_sz, -corner_sz:]
        bl = dwellmap[-corner_sz:, 0:corner_sz]
        br = dwellmap[-corner_sz:, -corner_sz:]
        corner_dwell = np.sum([tl, tr, bl, br])

        A_rows, A_cols = np.shape(A)

        if corner_dwell &gt; 20:
                shape = &#39;square&#39;
        else:
                shape = &#39;circle&#39;
        return self.fieldcalcs.getBorderScore(A, shape=shape, debug=debug)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getFieldRuns"><code class="name flex">
<span>def <span class="ident">getFieldRuns</span></span>(<span>self, tetrode, cluster, binsize=3)</span>
</code></dt>
<dd>
<section class="desc"><p>Extracts the runs through a place field of a given cluster on a given
tetrode and returns the indices of the runs that are kept (defaults to
at least 5 spikes needing to be fired) and the indices of the spikes in
the run and the duration of each run</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>binsize</code></strong> :&ensp;<code>int</code></dt>
<dd>size of bins (cms)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The runs retained, the spikes in the run and the run duration</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getFieldRuns(self, tetrode, cluster, binsize=3):
        &#39;&#39;&#39;
        Extracts the runs through a place field of a given cluster on a given
        tetrode and returns the indices of the runs that are kept (defaults to
        at least 5 spikes needing to be fired) and the indices of the spikes in
        the run and the duration of each run

        Parameters
        ----------
        tetrode : int
        cluster : int
        binsize : int
                size of bins (cms)

        Returns
        -------
        data : tuple
                The runs retained, the spikes in the run and the run duration
        &#39;&#39;&#39;

        # label is a mask of the place field - this could be hijacked to cover the whole track
        label, xe, ye = self._getFieldLims(tetrode, cluster, binsize)
        S = skimage.measure.regionprops(label)
        areas = [s[&#39;area&#39;] for s in S]# get the biggest field
        bigFieldIdx = np.argmax(areas)
        bigFieldProps = S[bigFieldIdx]
        binCoords = bigFieldProps.coords
        min_field_edge = np.min(binCoords[:,1])
        max_field_edge = np.max(binCoords[:,1])
        x_coord_field_min = xe[min_field_edge]
        x_coord_field_max = xe[max_field_edge]
        xy = self._getPath()
        x_field_bool = np.logical_and(xy[0] &gt; x_coord_field_min,
                                                          xy[0] &lt; x_coord_field_max)
        # find the runs with spikes
        run_indices = x_field_bool.nonzero()
        # get a list of runs
        runs = np.array_split(run_indices[0], np.where(np.diff(run_indices[0])&gt;10)[0]+1)
        # there might be short runs through the field so calculate the min distance
        # across the largest part of the field - done so this method can hopefully
        # account for runs in open fields as well as linear tracks
        ppb = int(self.POS.header[&#39;pixels_per_metre&#39;]) / 100. # pixels per bin
        dist2CrossField = bigFieldProps[&#39;major_axis_length&#39;] * ppb
        # get the spike indices into position data
        idx = self.TETRODE[tetrode].getClustIdx(cluster)
        runs_to_keep = []
        spks_in_run = []
        run_duration = []
        for run in runs:
                if np.nansum(np.hypot(np.diff(xy[0,run]),np.diff(xy[1,run]))) &gt; (dist2CrossField / 2): # be conservative and take 1/2 dist
                        if np.intersect1d(run, idx).any():
                                if len(np.intersect1d(run, idx)) &gt; self._min_spks:# if there are &gt;5 spikes keep run
                                        runs_to_keep.append(run)
                                        spks_in_run.append(np.intersect1d(run, idx))
                                        run_duration.append((run[-1] - run[0])/float(self.POS.pos_sample_rate))
        return runs_to_keep, spks_in_run, run_duration</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getFullFile"><code class="name flex">
<span>def <span class="ident">getFullFile</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<section class="desc"><p>Used to constuct filename_root in <strong>init</strong></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>The absolute path the files being analysed here without any suffix</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getFullFile(self, filename):
        &#39;&#39;&#39;
        Used to constuct filename_root in __init__

        Parameters
        -------------
        filename : str
                The absolute path the files being analysed here without any suffix
        &#39;&#39;&#39;
        if os.path.isdir(r&#39;/home/robin/Dropbox/Science/Recordings&#39;):
                pname, fname = os.path.split(filename)
                if len(pname) == 0:
                        defaultDir = r&#39;/home/robin/Dropbox/Science/Recordings&#39;
                        animal = filename.split(&#39;_&#39;)[0]
                        filename = os.path.join(defaultDir, animal, filename)
        return filename</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getRasterHist"><code class="name flex">
<span>def <span class="ident">getRasterHist</span></span>(<span>self, tetrode, cluster, dt=(-50, 100), hist=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates the histogram of the raster of spikes during a series of events</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>tuple</code></dt>
<dd>the window of time in ms to examine zeroed on the event of interest
i.e. the first value will probably be negative as in the default example</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code></dt>
<dd>not sure</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getRasterHist(self, tetrode, cluster, dt=(-50, 100), hist=True):
        &#39;&#39;&#39;
        Calculates the histogram of the raster of spikes during a series of events

        Parameters
        ----------
        tetrode : int
        cluster : int
        dt : tuple
                the window of time in ms to examine zeroed on the event of interest
                i.e. the first value will probably be negative as in the default example
        hist : bool
                not sure
        &#39;&#39;&#39;
        x1 = self.TETRODE[tetrode].getClustTS(cluster)
        x1 = x1 / int(self.TETRODE[tetrode].timebase / 1000.) #in ms
        x1.sort()
        on_good = self.STM.getTS()
        dt = np.array(dt)
        irange = on_good[:, np.newaxis] + dt[np.newaxis, :]
        dts = np.searchsorted(x1, irange)
        y = []
        x = []
        for i, t in enumerate(dts):
                tmp = x1[t[0]:t[1]] - on_good[i]
                x.extend(tmp)
                y.extend(np.repeat(i, len(tmp)))

        if hist:
                nEvents = int(self.STM[&#34;num_stm_samples&#34;])
                return np.histogram2d(x, y, bins=[np.arange(dt[0],dt[1]+1,1), np.arange(0,nEvents+1, 1)])[0]
        else:
                return np.histogram(x, bins=np.arange(dt[0],dt[1]+1,1), range=dt)[0]</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx"><code class="name flex">
<span>def <span class="ident">getThetaModIdx</span></span>(<span>self, tetrode, cluster)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates the theta modulation index of a clusters autocorrelogram
as the difference between the first trough and second peak of the
autocorrelogram (actually the difference over their sum)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>The tetrode the cluster is on</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>The cluster identity</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>thetaModulation</code></strong> :&ensp;<code>int</code></dt>
<dd>The depth of theta modulation</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getThetaModIdx(self, tetrode, cluster):
        &#39;&#39;&#39;
        Calculates the theta modulation index of a clusters autocorrelogram
        as the difference between the first trough and second peak of the
        autocorrelogram (actually the difference over their sum)

        Parameters
        --------------
        tetrode : int
                The tetrode the cluster is on
        cluster : int
                The cluster identity
        Returns
        -------------
        thetaModulation : int
                The depth of theta modulation
        &#39;&#39;&#39;
        x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
        if self.posFilter:
                idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                x1 = x1[np.in1d(x1PosSamp, idx)]
        thetaMod = self.spikecalcs.thetaModIdx(x1)
        return thetaMod</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx2"><code class="name flex">
<span>def <span class="ident">getThetaModIdx2</span></span>(<span>self, tetrode, cluster)</span>
</code></dt>
<dd>
<section class="desc"><p>Wrapper for thetaModIdxV2 in spikecalcs.py</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>The tetrode the cluster is on</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>The cluster identity</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>thetaModulation</code></strong> :&ensp;<code>int</code></dt>
<dd>The depth of theta modulation</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getThetaModIdx2(self, tetrode, cluster):
        &#39;&#39;&#39;
        Wrapper for thetaModIdxV2 in spikecalcs.py

        Parameters
        --------------
        tetrode : int
                The tetrode the cluster is on
        cluster : int
                The cluster identity
        Returns
        -------------
        thetaModulation : int
                The depth of theta modulation
        &#39;&#39;&#39;

        x1 = self.TETRODE[tetrode].getClustTS(cluster) / float(self.TETRODE[tetrode].timebase) * 1000
        if self.posFilter:
                idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                x1 = x1[np.in1d(x1PosSamp, idx)]
        thetaMod = self.spikecalcs.thetaModIdxV2(x1)
        return thetaMod</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getThigmotaxisIndex"><code class="name flex">
<span>def <span class="ident">getThigmotaxisIndex</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Currently fucked
Calculates the ratio of time spent in the middle of the environment
to the amount of time spent in the central part</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getThigmotaxisIndex(self):
        &#39;&#39;&#39;
        Currently fucked
        Calculates the ratio of time spent in the middle of the environment
        to the amount of time spent in the central part
        &#39;&#39;&#39;
        dwellmap = self._getMap(smooth=False)[0] # unsmoothed dwell map
        # simply calculate the sums in the corners and see if this 
        # goes above some threshold
        corner_sz = 3
        tl = dwellmap[0:corner_sz, 0:corner_sz]
        tr = dwellmap[0:corner_sz, -corner_sz:]
        bl = dwellmap[-corner_sz:, 0:corner_sz]
        br = dwellmap[-corner_sz:, -corner_sz:]
        corner_dwell = np.sum([tl, tr, bl, br])

        if corner_dwell &gt; 20:
                shape = &#39;square&#39;

        else:
                shape = &#39;circle&#39;</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getTsAndCs"><code class="name flex">
<span>def <span class="ident">getTsAndCs</span></span>(<span>self, verbose=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Prints out the available tetrodes and clusters</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getTsAndCs(self, verbose=False):
        &#34;&#34;&#34;
        Prints out the available tetrodes and clusters
        &#34;&#34;&#34;
        cut_files = [(f) for f in glob(self.filename_root + &#39;*&#39;) if &#39;cut&#39; in f]
        m = re.compile(&#39;(.*)_(.*).cut&#39;, re.M|re.I)
        tAndCdict = {}
        if cut_files:
                for f in cut_files:
                        tet = int(m.match(f).group(2))
                        try:
                                data = self.getCut(tet)
                                clusters = list(np.unique(data))
                                if clusters[0]==0:
                                        clusters.pop(0)
                                        if clusters:
                                                tAndCdict[tet] = clusters
                                if verbose:
                                        print(&#39;\nTetrode {0} contains clusters: {1}&#39;.format(tet, clusters))
                        except:
                                if verbose:
                                        print(&#39;\nTetrode{0} has no cut&#39;.format(tet))
        else:
                pass
        if tAndCdict:
                tets = []
                clusts = []
                for t,c in tAndCdict.items():
                        for cc in c:
                                tets.append(str(t))
                                clusts.append(str(cc))
                &#39;&#39;&#39;
                The two fucking stupid lines below are so yaml can
                serialize the object correctly
                &#39;&#39;&#39;
                self.tetrodes = map(int,tets)
                self.clusters = map(int,clusts)
                return tAndCdict</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getcircR"><code class="name flex">
<span>def <span class="ident">getcircR</span></span>(<span>self, tetrode, cluster, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculate the mean resultant vector length of circular data
Unlike getmrv (above) this only returns the vector length. This is
calculated differently (using complex numbers) but is a) faster, b)
works with binned data and, c) plays nicer/ easier with shuffles of
the spike train</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>The tetrode to exmaine</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>The cluster to examine</dd>
</dl>
<p>**kwargs:
Legal values of interest:
shuffle: int
the number of seconds to shift the spike train</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>r</code></strong> :&ensp;<code>float</code></dt>
<dd>the mean resultant vector length (range = 0-1)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getcircR(self, tetrode, cluster, **kwargs):
        &#39;&#39;&#39;
        Calculate the mean resultant vector length of circular data
        Unlike getmrv (above) this only returns the vector length. This is
        calculated differently (using complex numbers) but is a) faster, b)
        works with binned data and, c) plays nicer/ easier with shuffles of
        the spike train

        Parameters
        ---------------
        tetrode : int
                The tetrode to exmaine
        cluster : int
                The cluster to examine
        **kwargs:
                Legal values of interest:
                shuffle: int
                the number of seconds to shift the spike train

        Returns
        ----------
        r : float
                the mean resultant vector length (range = 0-1)
        &#39;&#39;&#39;

        idx = self.TETRODE[tetrode].getClustIdx(cluster)
        spk_weights = np.bincount(idx, minlength=self.POS.npos)

        if &#39;shuffle&#39; in kwargs.keys():
                spk_weights = np.roll(spk_weights, int(kwargs[&#39;shuffle&#39;] * 50))
        inc = (np.pi*2) / 120.0
        h = self.ratemap._RateMap__binData(np.deg2rad(self.POS.dir), np.arange(0, np.pi*2+inc, inc), spk_weights)
        from statscalcs import StatsCalcs
        S = StatsCalcs()
        R = S.circ_r(h[1][0][0:-1], h[0])
        return R</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getcoherence"><code class="name flex">
<span>def <span class="ident">getcoherence</span></span>(<span>self, tetrode, cluster, binsize=3, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Wrapper for fieldcalcs.coherence - see docs there</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getcoherence(self, tetrode, cluster, binsize=3, **kwargs):
        &#34;&#34;&#34;
        Wrapper for fieldcalcs.coherence - see docs there
        &#34;&#34;&#34;
        smthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                binsize=binsize, smooth_sz=5,
                                                smooth=True, **kwargs)

        unsmthd = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;pos&#39;,
                                                binsize=binsize, smooth_sz=5,
                                                smooth=False, **kwargs)

        return self.fieldcalcs.coherence(smthd[0], unsmthd[0])</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getkldiv"><code class="name flex">
<span>def <span class="ident">getkldiv</span></span>(<span>self, tetrode, cluster, binsize=3, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Wrapper for fieldcalcs.kldiv - see there for explanation</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getkldiv(self, tetrode, cluster, binsize=3, **kwargs):
        &#34;&#34;&#34;
        Wrapper for fieldcalcs.kldiv - see there for explanation
        &#34;&#34;&#34;
        polarMap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;,
                                                binsize=binsize, smooth_sz=5,
                                                smooth=True, **kwargs)
        return self.fieldcalcs.kldiv_dir(polarMap[0])</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getmrv"><code class="name flex">
<span>def <span class="ident">getmrv</span></span>(<span>self, tetrode, cluster, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculate the mean resultant vector length and direction for a given
cluster/ cell</p>
<p>A wrapper for statscalcs.Statscalcs.mean_resultant_vector (see
statscalcs.py)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>The tetrode to exmaine</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>The cluster to examine</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>r</code></strong> :&ensp;<code>float</code></dt>
<dd>the mean resultant vector length (range = 0-1)</dd>
<dt><strong><code>th</code></strong> :&ensp;<code>float</code></dt>
<dd>the mean resultant vector direction (in radians)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getmrv(self, tetrode, cluster, **kwargs):
        &#39;&#39;&#39;
        Calculate the mean resultant vector length and direction for a given
        cluster/ cell

        A wrapper for statscalcs.Statscalcs.mean_resultant_vector (see
        statscalcs.py)

        Parameters
        ----------
        tetrode : int
                The tetrode to exmaine
        cluster : int
                The cluster to examine

        Returns
        ----------
        r : float
                the mean resultant vector length (range = 0-1)
        th : float
                the mean resultant vector direction (in radians)
        &#39;&#39;&#39;

        idx = self.TETRODE[tetrode].getClustIdx(cluster)
        angsInRads = np.deg2rad(self.POS.dir[idx])
        from statscalcs import StatsCalcs
        S = StatsCalcs()
        r, th = S.mean_resultant_vector(angsInRads)
        return r, th</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.getskaggsInfo"><code class="name flex">
<span>def <span class="ident">getskaggsInfo</span></span>(<span>self, tetrode, cluster, binsize=3, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Wrapper for fieldcalcs.skaggsInfo see there for docs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>The tetrode to exmaine</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>The cluster to examine</dd>
<dt><strong><code>binsize</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of bins in cms</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bits</code> <code>per</code> <code>spike</code> : <code>float</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>binning could be over any single spatial variable (e.g. location, direction, speed).</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getskaggsInfo(self, tetrode, cluster, binsize=3, **kwargs):
        &#39;&#39;&#39;
        Wrapper for fieldcalcs.skaggsInfo see there for docs

        Parameters
        ---------------
        tetrode : int
                The tetrode to exmaine
        cluster : int
                The cluster to examine
        binsize : int
                Size of bins in cms
        Returns
        --------------
        bits per spike : float

        Notes
        -----
        binning could be over any single spatial variable (e.g. location, direction, speed).
        &#39;&#39;&#39;
        ratemap = self._getMap(tetrode, cluster, binsize=binsize, **kwargs)[0]
        dwelltimes = self._getMap(binsize=binsize, **kwargs)[0]
        ratemap, _, dwelltimes = self.ratemap._RateMap__adaptiveMap(ratemap, dwelltimes)
        return self.fieldcalcs.skaggsInfo(ratemap, dwelltimes)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.hasFiles"><code class="name flex">
<span>def <span class="ident">hasFiles</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks for some automated yaml processing (see Dropbox/Science/Analysis/)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hasFiles(self):
        &#39;&#39;&#39;
        Checks for some automated yaml processing (see Dropbox/Science/Analysis/)
        &#39;&#39;&#39;

        for i in self.axona_files.iterkeys():
                if os.path.isfile(self.filename_root + i):
                        self[&#39;has_&#39; + i[1:]] = True
                else:
                        self[&#39;has_&#39; + i[1:]] = False</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.klustakwik"><code class="name flex">
<span>def <span class="ident">klustakwik</span></span>(<span>self, d)</span>
</code></dt>
<dd>
<section class="desc"><p>Calls two methods below (kluster and getPC) to run klustakwik on
a given tetrode with nFet number of features (for the PCA)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>d</code></strong> :&ensp;<code>dict</code></dt>
<dd>Specifies the vector of features to be used in
clustering. Each key is the identity of a tetrode (i.e. 1, 2 etc)
and the values are the features used to do the clustering for that tetrode (i.e.
'PC1', 'PC2', 'Amp' (amplitude) etc</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def klustakwik(self, d):
        &#34;&#34;&#34;
        Calls two methods below (kluster and getPC) to run klustakwik on
        a given tetrode with nFet number of features (for the PCA)

        Parameters
        ----------
        d : dict
                Specifies the vector of features to be used in
                clustering. Each key is the identity of a tetrode (i.e. 1, 2 etc)
                 and the values are the features used to do the clustering for that tetrode (i.e.
                &#39;PC1&#39;, &#39;PC2&#39;, &#39;Amp&#39; (amplitude) etc
        &#34;&#34;&#34;

        legal_values = [&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;, &#39;PC4&#39;, &#39;Amp&#39;,
                                        &#39;Vt&#39;, &#39;P&#39;, &#39;T&#39;, &#39;tP&#39;, &#39;tT&#39;, &#39;En&#39;, &#39;Ar&#39;]
        reg = re.compile(&#34;.*(PC).*&#34;)  # check for number of principal comps
        # check for any input errors in whole dictionary first
        for i_tetrode in d.keys():
                for v in d[i_tetrode]:
                        if v not in legal_values:
                                raise ValueError(&#39;Could not find %s in %s&#39; % (v, legal_values))
        # iterate through features and see what the max principal component is
        for i_tetrode in d.keys():
                pcs = [m.group(0) for l in d[i_tetrode] for m in [reg.search(l)] if m]
                waves = self.TETRODE[i_tetrode].waveforms
                princomp = None
                if pcs:
                        max_pc = []
                        for pc in pcs:
                                max_pc.append(int(pc[2]))
                        num_pcs = np.max(max_pc)  # get max number of prin comps
                        princomp = self.TETRODE[i_tetrode].getParam(waves,
                                                                          param=&#39;PCA&#39;, fet=num_pcs)
                        # Rearrange the output from PCA calc to match the 
                        # number of requested principal components
                        inds2keep = []
                        for m in max_pc:
                                inds2keep.append(np.arange((m-1)*4, (m)*4))
                        inds2keep = np.hstack(inds2keep)
                        princomp = np.take(princomp, inds2keep, axis=1)
                out = []
                for value in d[i_tetrode]:
                        if &#39;PC&#39; not in value:
                                out.append(self.TETRODE[i_tetrode].getParam(waves, param=value))
                if princomp is not None:
                        out.append(princomp)
                out = np.hstack(out)

                c = Kluster(self.filename_root, i_tetrode, out)
                c.make_fet()
                mask = c.get_mask()
                c.make_fmask(mask)
                c.kluster()</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotClusterSpace"><code class="name flex">
<span>def <span class="ident">plotClusterSpace</span></span>(<span>self, tetrode, clusters=None, ax=None, bins=256, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the cluster space for the given tetrode</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>the tetrode cluster space to plot</dd>
<dt><strong><code>clusters</code></strong> :&ensp;<code>int</code> or <code>list</code> or <code>np.array</code></dt>
<dd>the clusters to colour in</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code></dt>
<dd>the axis to plot into</dd>
<dt><strong><code>bins</code></strong> :&ensp;<code>int</code></dt>
<dd>the number of bins to use in the histogram</dd>
</dl>
<p>**kwargs :
can include a param keyword for the parameter to construct the
histogram from - this defaults to amplitude ('Amp') but can be any
valid key in the getParam method of the Tetrode class</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>handle</code> <code>to</code> <code>figure</code> <code>window</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plotClusterSpace(self, tetrode, clusters=None, ax=None, bins=256,**kwargs):
                &#39;&#39;&#39;
                Plots the cluster space for the given tetrode

                Parameters
                ----------
                tetrode : int
                        the tetrode cluster space to plot
                clusters : int or list or np.array
                        the clusters to colour in
                ax : matplotlib.pyplot.axis
                        the axis to plot into
                bins : int
                        the number of bins to use in the histogram
                **kwargs :
                        can include a param keyword for the parameter to construct the
                        histogram from - this defaults to amplitude (&#39;Amp&#39;) but can be any
                        valid key in the getParam method of the Tetrode class

                Returns
                -------
                fig: handle to figure window
                &#39;&#39;&#39;

                if clusters is not None and not isinstance(clusters, (np.ndarray, list)):
                        clusters = [clusters]  # ie needs to be iterable
                waves = self.TETRODE[tetrode].waveforms
                if self.TETRODE[tetrode].volts:
                        waves = (waves * 128) / self.TETRODE[tetrode].scaling[:, np.newaxis]
                        waves = waves.astype(int)
                cutfile = self.TETRODE[tetrode].cut

                if cutfile is not None:
                        cutfile = np.array(cutfile)
                if &#39;param&#39; in kwargs.keys():
                        param = kwargs[&#39;param&#39;]
                else:
                        param = &#39;Amp&#39;
                amps = self.TETRODE[tetrode].getParam(waves, param=param)
                bad_electrodes = np.setdiff1d(np.array(range(4)),np.array(np.sum(amps,0).nonzero())[0])
                cmap = np.tile(tcols.colours[0],(bins,1))
                cmap[0] = (1,1,1)
                cmap = colors.ListedColormap(cmap)
                cmap._init()
                alpha_vals = np.ones(cmap.N+3)
                alpha_vals[0] = 0
                cmap._lut[:,-1] = alpha_vals
                cmb = combinations(range(4),2)
                if &#39;figure&#39; in kwargs.keys():
                        fig = kwargs.pop(&#39;figure&#39;)
                else:
                        fig = plt.figure()
                if ax is None:
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax.axis(&#39;off&#39;)
#        fig = plt.gcf()
                rect = ax.get_position().bounds
                grid = ImageGrid(fig, rect, nrows_ncols= (2,3), axes_pad=0.1)
                if &#39;Amp&#39; in param:
                        myRange = [[0,256],[0,256]]
                else:
                        myRange = None
                for i, c in enumerate(cmb):
                        if c not in bad_electrodes:
                                H = np.histogram2d(amps[:,c[0]], amps[:,c[1]], range = myRange, bins=bins)
                                grid[i].imshow(H[0], cmap=cmap, interpolation=&#39;nearest&#39;)
                                if clusters is not None:
                                        for thisclust in clusters:
                                                if &#39;clustColour&#39; in kwargs.keys():
                                                        clustColour = kwargs[&#39;clustColour&#39;]
                                                else:
                                                        clustColour = tcols.colours[thisclust]
                                                clustidx = (cutfile==thisclust).nonzero()[0]
                                                H = np.histogram2d(amps[clustidx,c[0]],amps[clustidx,c[1]], range=myRange, bins=bins)
                                                H = H[0]
                                                H = signal.convolve2d(H, np.ones((3, 3)), mode=&#39;same&#39;)
                                                clustCMap = np.tile(clustColour,(bins,1))
                                                clustCMap[0] = (1,1,1)
                                                clustCMap = colors.ListedColormap(clustCMap)
                                                clustCMap._init()
                                                clustCMap._lut[:,-1] = alpha_vals
                                                grid[i].imshow(H, cmap=clustCMap, interpolation=&#39;nearest&#39;)
                        s = str(c[0]+1) + &#39; v &#39; + str(c[1]+1)
                        grid[i].text(0.05,0.95, s, va=&#39;top&#39;, ha=&#39;left&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)
                        grid[i].set_xlim([0,bins])
                        grid[i].set_ylim([0,bins])
                        grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                        bottom=&#39;off&#39;, top=&#39;off&#39;)
                plt.setp([a.get_xticklabels() for a in grid], visible=False)
                plt.setp([a.get_yticklabels() for a in grid], visible=False)
                return fig</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotDirFilteredRmaps"><code class="name flex">
<span>def <span class="ident">plotDirFilteredRmaps</span></span>(<span>self, tetrode, cluster, maptype='rmap', **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots out directionally filtered ratemaps for the tetrode/ cluster</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>maptype</code></strong> :&ensp;<code>str</code></dt>
<dd>Valid values include 'rmap', 'polar', 'xcorr'</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotDirFilteredRmaps(self, tetrode, cluster, maptype=&#39;rmap&#39;, **kwargs):
        &#39;&#39;&#39;
        Plots out directionally filtered ratemaps for the tetrode/ cluster

        Parameters
        ----------
        tetrode : int
        cluster : int
        maptype : str
                Valid values include &#39;rmap&#39;, &#39;polar&#39;, &#39;xcorr&#39;
        &#39;&#39;&#39;
        inc = 8.0
        step = 360/inc
        dirs_st = np.arange(-step/2, 360-(step/2), step)
        dirs_en = np.arange(step/2, 360, step)
        dirs_st[0] = dirs_en[-1]

        if &#39;polar&#39; in maptype:
                fig, axes = plt.subplots(nrows=3, ncols=3, subplot_kw={&#39;projection&#39;: &#39;polar&#39;})
        else:
                fig, axes = plt.subplots(nrows=3, ncols=3)
        ax0 = axes[0][0] # top-left
        ax1 = axes[0][1] # top-middle
        ax2 = axes[0][2] # top-right
        ax3 = axes[1][0] # middle-left
        ax4 = axes[1][1] # middle
        ax5 = axes[1][2] # middle-right
        ax6 = axes[2][0] # bottom-left
        ax7 = axes[2][1] # bottom-middle
        ax8 = axes[2][2] # bottom-right

        max_rate = 0
        for d in zip(dirs_st, dirs_en):
                self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                if &#39;polar&#39; in maptype:
                        rmap = self._getMap(tetrode=tetrode, cluster=cluster, var2bin=&#39;dir&#39;)[0]
                elif &#39;xcorr&#39; in maptype:
                        x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                        rmap = self.spikecalcs.xcorr(x1, x1, Trange=np.array([-500, 500]))
                else:
                        rmap = self._getMap(tetrode=tetrode, cluster=cluster)[0]
                if np.nanmax(rmap) &gt; max_rate:
                        max_rate = np.nanmax(rmap)

        from collections import OrderedDict
        dir_rates = OrderedDict.fromkeys(dirs_st, None)

        for d in zip(dirs_st, dirs_en, [ax5,ax2,ax1,ax0,ax3,ax6,ax7,ax8]):
                self.posFilter = {&#39;dir&#39;: (d[0], d[1])}
                npos = np.count_nonzero(np.ma.compressed(~self.POS.dir.mask))
                print(&#34;npos = {}&#34;.format(npos))
                nspikes = np.count_nonzero(np.ma.compressed(~self.TETRODE[tetrode].getClustSpks(cluster).mask[:,0,0]))
                print(&#34;nspikes = {}&#34;.format(nspikes))
                dir_rates[d[0]] = nspikes# / (npos/50.0)
                if &#39;spikes&#39; in maptype:
                        self.plotSpikesOnPath(tetrode, cluster, ax=d[2], markersize=4)
                elif &#39;rmap&#39; in maptype:
                        self._plotMap(tetrode, cluster, ax=d[2], vmax=max_rate)
                elif &#39;polar&#39; in maptype:
                        self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=d[2], vmax=max_rate)
                elif &#39;xcorr&#39; in maptype:
                        self.plotXCorr(tetrode, cluster, ax=d[2])
                        x1 = self.TETRODE[tetrode].getClustTS(cluster) / (96000/1000)
                        print(&#34;x1 len = {}&#34;.format(len(x1)))
                        dir_rates[d[0]] = self.spikecalcs.thetaBandMaxFreq(x1)
                        d[2].set_xlabel(&#39;&#39;)
                        d[2].set_title(&#39;&#39;)
                        d[2].set_xticklabels(&#39;&#39;)
                d[2].set_title(&#34;nspikes = {}&#34;.format(nspikes))
        self.posFilter = None
        if &#39;spikes&#39; in maptype:
                self.plotSpikesOnPath(tetrode, cluster, ax=ax4)
        elif &#39;rmap&#39; in maptype:
                self._plotMap(tetrode, cluster, ax=ax4)
        elif &#39;polar&#39; in maptype:
                self._plotMap(tetrode, cluster, var2bin=&#39;dir&#39;, ax=ax4)
        elif &#39;xcorr&#39; in maptype:
                self.plotXCorr(tetrode, cluster, ax=ax4)
                ax4.set_xlabel(&#39;&#39;)
                ax4.set_title(&#39;&#39;)
                ax4.set_xticklabels(&#39;&#39;)
        return dir_rates</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotEEGPower"><code class="name flex">
<span>def <span class="ident">plotEEGPower</span></span>(<span>self, E=None, eegType='eeg', smthKernelSigma=0.1875, freqBand=(6, 12), outsideBand=(3, 125), s2nWdth=2, xmax=125, ymax=None, plot=True, ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the eeg power spectrum. Annotates graph around theta frequency band.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>E</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd>(Optional) numEEGSamples sized numpy array of raw eeg signal amplitude.</dd>
<dt><strong><code>eegType</code></strong> :&ensp;<code>str</code></dt>
<dd>(Optional) Either 'eeg' or 'egf'. The .eeg file type to use. Defaults to 'eeg'</dd>
<dt><strong><code>smthKernelSigma</code></strong> :&ensp;<code>float</code></dt>
<dd>(Optional) number of points in the output window for gaussian filtering of eeg. This
value is multipled by the binsPerHz which comes from the length of the fft (derived from nextpow2 for speed).</dd>
<dt><strong><code>freqBand</code></strong> :&ensp;<code>two</code>-<code>tuple</code></dt>
<dd>(Optional) the theta-band to examine.</dd>
<dt><strong><code>outsideBand</code></strong> :&ensp;<code>two</code>-<code>tuple</code></dt>
<dd>(Optional): frequencies outside these values are ignored. NOT IMPLEMENTED.</dd>
<dt><strong><code>s2nWdth</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) Determines the width of the window to calculate the signal-to-noise ratio.</dd>
<dt><strong><code>xmax</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) Maximum x-value (frequency) to plot to. Defaults to 125</dd>
<dt><strong><code>ymax</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) Maximum y-value to plot to. Defaults to None so plots full range</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>(Optional) Whether to produce a plot</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code> <code>instance</code></dt>
<dd>(Optional) The axis to plot in to.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code> <code>instance</code></dt>
<dd>The axis containing the plot.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotEEGPower(self, E=None, eegType=&#39;eeg&#39;, smthKernelSigma=0.1875,
                                freqBand=(6,12), outsideBand=(3,125), s2nWdth=2, xmax=125, 
                                ymax=None, plot=True, ax=None, **kwargs):
        &#39;&#39;&#39;
        Plots the eeg power spectrum. Annotates graph around theta frequency band.

        Parameters
        -------------
        E : numpy.array
                (Optional) numEEGSamples sized numpy array of raw eeg signal amplitude.
        eegType : str
                (Optional) Either &#39;eeg&#39; or &#39;egf&#39;. The .eeg file type to use. Defaults to &#39;eeg&#39;
        smthKernelSigma : float
                (Optional) number of points in the output window for gaussian filtering of eeg. This
                value is multipled by the binsPerHz which comes from the length of the fft (derived from nextpow2 for speed).
        freqBand : two-tuple
                (Optional) the theta-band to examine.
        outsideBand : two-tuple
                (Optional): frequencies outside these values are ignored. NOT IMPLEMENTED.
        s2nWdth : int
                (Optional) Determines the width of the window to calculate the signal-to-noise ratio.
        xmax : int
                (Optional) Maximum x-value (frequency) to plot to. Defaults to 125
        ymax : int
                (Optional) Maximum y-value to plot to. Defaults to None so plots full range
        plot : bool
                (Optional) Whether to produce a plot
        ax : matplotlib.pyplot.axis instance
                (Optional) The axis to plot in to.

        Returns
        -------------
        ax : matplotlib.pyplot.axis instance
                The axis containing the plot.
        &#39;&#39;&#39;

        if E is None:
                if &#39;eeg&#39; in eegType:
                        E = self.EEG.eeg
                        freqBand = (self.EEG.x1, self.EEG.x2)
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        sample_rate = self.EEG.sample_rate
                elif &#39;egf&#39; in eegType:
                        E = self.EGF.eeg
                        freqBand = (self.EEG.x1, self.EEG.x2)
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        sample_rate = self.EGF.sample_rate
        else:
                if np.ma.is_masked(E):
                        E = E.compressed()
                sample_rate = kwargs[&#39;sample_rate&#39;]
        nqLim = 0
        nqLim = sample_rate / 2
        origLength = len(E)
        fftLength = 2 ** self.EEG.nextpow2(origLength).astype(int)
        freqs, power = signal.periodogram(E, fs=sample_rate, return_onesided=True, nfft=fftLength)
        fftHalfLength = fftLength / 2+1
        # calculate the number of points in the gaussian window - gleaned from gaussian_filter1d
        # which lives in scipy/ndimage/filters.py
        binsPerHz = (fftHalfLength-1) / nqLim
        kernelSigma = smthKernelSigma * binsPerHz
        smthKernelWidth = 2 * int(4.0 * kernelSigma + 0.5) + 1
        gaussWin = signal.gaussian(smthKernelWidth, kernelSigma)
        # smooth the power
        sm_power = signal.fftconvolve(power, gaussWin, &#39;same&#39;)
        # normalize the smoothed power by the length of the fft
        sm_power = sm_power / np.sqrt(len(sm_power))
        # calculate some metrics
        spectrumMaskBand = np.logical_and(freqs&gt;freqBand[0], freqs&lt;freqBand[1])
        bandMaxPower = np.max(sm_power[spectrumMaskBand])
        maxBinInBand = np.argmax(sm_power[spectrumMaskBand])
        bandFreqs = freqs[spectrumMaskBand]
        freqAtBandMaxPower = bandFreqs[maxBinInBand]
        # find power in windows around peak, divide by power in rest of spectrum
        # to get SNR
        spectrumMaskPeak = np.logical_and(freqs&gt;freqAtBandMaxPower-s2nWdth/2, freqs &lt; freqAtBandMaxPower + s2nWdth/2)
        snr = np.nanmean(sm_power[spectrumMaskPeak]) / np.nanmean(sm_power[~spectrumMaskPeak])
        # collect all the following keywords into a dict for output
        dictKeys = (&#39;sm_power&#39;,&#39;freqs&#39;, &#39;spectrumMaskPeak&#39;, &#39;power&#39;,&#39;freqBand&#39;,
        &#39;freqAtBandMaxPower&#39;, &#39;bandMaxPower&#39;, &#39;xmax&#39;, &#39;ymax&#39;, &#39;snr&#39;, &#39;kernelSigma&#39;, &#39;binsPerHz&#39;)
        outDict = dict.fromkeys(dictKeys,np.nan)
        for thiskey in outDict.keys():
                outDict[thiskey] = locals()[thiskey]# neat trick: locals is a dict that holds all locally scoped variables
        if plot:
                if ax is None:
                        plt.figure()
                        ax = plt.gca()
                ax.plot(freqs, power, alpha=0.5, color=[0.8627, 0.8627, 0.8627])
                # ax.hold(1)
                ax.plot(freqs, sm_power)
                r = Rectangle((freqBand[0],0), width=np.diff(freqBand)[0], height=np.diff(ax.get_ylim())[0], alpha=0.25, color=&#39;r&#39;, ec=&#39;none&#39;)
                ax.add_patch(r)
                ax.set_xlim(0,xmax)
                ax.set_ylim(0, bandMaxPower / 0.8)
                ax.set_xlabel(&#39;Frequency&#39;)
                ax.set_ylabel(&#39;Power&#39;)
                ax.text(x = freqBand[1] / 0.9, y = bandMaxPower, s = str(freqAtBandMaxPower)[0:4], fontsize=20)
        return ax</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotEventEEGRange"><code class="name flex">
<span>def <span class="ident">plotEventEEGRange</span></span>(<span>self, eeg_type='egf', stimTrials=[0, 1], ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calls plot_event_eeg with defaults and no plotting and then plots out
a time period in seconds from x1 to x2 and overlays the correct time in
seconds on the x-axis - meant for manual inspection of the effect of
stimulation events on the eeg</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>eeg_type</code></strong> :&ensp;<code>str</code></dt>
<dd>either 'egf' or 'eeg' although probably no point
using 'eeg' as sample rate too low</dd>
<dt><strong><code>stimTrials</code></strong> :&ensp;<code>list</code></dt>
<dd>the stimulation 'trial' to plot, starting at 0
NB stimulating every 150ms for 10ms for 20 minutes gets
you 8000 trials</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axis</code></dt>
<dd>the axis to plot into. A new figure is
produced if this is None</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotEventEEGRange(self, eeg_type=&#39;egf&#39;, stimTrials=[0,1], ax=None, **kwargs):
        &#34;&#34;&#34;
        Calls plot_event_eeg with defaults and no plotting and then plots out
        a time period in seconds from x1 to x2 and overlays the correct time in
        seconds on the x-axis - meant for manual inspection of the effect of
        stimulation events on the eeg

        Parameters
        ------------
        eeg_type : str
                either &#39;egf&#39; or &#39;eeg&#39; although probably no point
                using &#39;eeg&#39; as sample rate too low
        stimTrials : list
                the stimulation &#39;trial&#39; to plot, starting at 0
                NB stimulating every 150ms for 10ms for 20 minutes gets
                you 8000 trials
        ax : matplotlib.axis
                the axis to plot into. A new figure is
                produced if this is None
        &#34;&#34;&#34;

        result, idx = self.plot_event_EEG(eeg_type=eeg_type, plot=False)
        eeg_samp_rate = self.STM[eeg_type + &#39;SampRate&#39;]
        time_ms = idx / float(eeg_samp_rate / 1000.)
        eeg_blocks = []
        time_blocks = []
        for t in stimTrials:
                eeg_blocks.append(result[:, t])
                time_blocks.append(time_ms[:, t])

        speed_idx = (idx / (eeg_samp_rate / self.POS.pos_sample_rate)).astype(int)
        speed = self.POS.speed[0, np.ravel(speed_idx, &#39;F&#39;)]
        max_speed = np.max(speed)
        speed = np.reshape(speed, idx.shape, &#39;F&#39;)
        # filter the eeg data in the theta and gamma bands
        E = EEGCalcs(self.filename_root)
        eeg = self.EGF.eeg
        eeg = eeg - np.ma.mean(eeg)
        sampRate = self.EGF.sample_rate
        theta_eeg = E.filterWithButter(eeg, 4, 8, sampRate, 2)
        gamma_eeg = E.filterWithButter(eeg, 30, 80, sampRate, 2)

        theta = theta_eeg[np.ravel(idx, &#39;F&#39;)]
        theta = np.reshape(theta, idx.shape, &#39;F&#39;)
        gamma = gamma_eeg[np.ravel(idx, &#39;F&#39;)]
        gamma = np.reshape(gamma, idx.shape, &#39;F&#39;)
        #dt is (-50, 150)
        rectStart = int((eeg_samp_rate / 1000.) * 50)
        rectEnd = int((eeg_samp_rate / 1000.) * 60)
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        else:
                ax = ax
        ax1 = ax.twinx()
        for block in zip(time_blocks, eeg_blocks, stimTrials):
                ax.plot(block[0], block[1], color=[0.8627, 0.8627, 0.8627])
                ax.hold(True)
                ax.plot(block[0], theta[:, block[2]], &#39;r&#39;)
                ax.plot(block[0], gamma[:, block[2]], &#39;g&#39;)
                ax1.plot(block[0], speed[:, block[2]], &#39;y&#39;)
                ax1.set_ylim(0, np.max(max_speed) * 4)
                axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                           ax.transAxes)
                i = block[0][rectStart]
                j = block[0][rectEnd] - block[0][rectStart]
                ax.add_patch(Rectangle((i,0), width=j, height=1,
                                                 transform=axTrans,
                                                 color=[41./256, 161./256, 230./256], alpha=0.5))
        ax.set_xlim(time_blocks[0][0], time_blocks[-1][-1])
        ylabels = ax1.yaxis.get_majorticklabels()
        for i,xxx in enumerate(ylabels):
                if i &gt; 1:
                        xxx.set_visible(False)
                else:
                        xxx.set_color(&#39;k&#39;)
        yticks = ax1.yaxis.get_major_ticks()
        for i,xxx in enumerate(yticks):
                if i &gt; 1:
                        xxx.set_visible(False)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotFreqVSpeed"><code class="name flex">
<span>def <span class="ident">plotFreqVSpeed</span></span>(<span>self, minSp=5, maxSp=50, spStep=5, ax=None, laserFilter=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots running speed vs eeg frequencies and does linear regression. Also adds position sample histogram
TODO: filter out negative frequencies - do this as default in EEG class
Parameters</p>
<hr>
<dl>
<dt><strong><code>minSp</code></strong> :&ensp;<code>int</code></dt>
<dd>speeds below this are ignored</dd>
<dt><strong><code>maxSp</code></strong> :&ensp;<code>int</code></dt>
<dd>speeds above this are ignored</dd>
<dt><strong><code>spStep</code></strong> :&ensp;<code>int</code></dt>
<dd>the bin width for speed</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes</code></dt>
<dd>the axes in which to plot</dd>
<dt><strong><code>laser</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>whether to filter for laser on/ off events
None means no filtering at all
1 means laser is on and data is filtered for on periods
0 means filter for laser off periods</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plotFreqVSpeed(self, minSp=5, maxSp=50, spStep=5, ax=None, laserFilter=None, **kwargs):
                &#39;&#39;&#39;
                Plots running speed vs eeg frequencies and does linear regression. Also adds position sample histogram
                TODO: filter out negative frequencies - do this as default in EEG class
                Parameters
                ----------
                minSp : int
                        speeds below this are ignored
                maxSp : int
                        speeds above this are ignored
                spStep : int
                        the bin width for speed
                ax : matplotlib.axes
                        the axes in which to plot
                laser : int or None
                        whether to filter for laser on/ off events
                        None means no filtering at all
                        1 means laser is on and data is filtered for on periods
                        0 means filter for laser off periods

                &#39;&#39;&#39;

                sp = np.ma.compressed(self.POS.speed)
                if laserFilter:
                        eeg = self.EEG.eeg
                        EE = EEGCalcs(self.filename_root, thetaRange=[6,12])
                        if &#39;dip&#39; in kwargs:
                                d = kwargs[&#39;dip&#39;]
                        else:
                                d = 15.0
                        if &#39;width&#39; in kwargs:
                                w = kwargs[&#39;width&#39;]
                        else:
                                w = 0.125
                        if &#39;stimFreq&#39; in kwargs:
                                sf = kwargs[&#39;stimFreq&#39;]
                        else:
                                sf = 6.66
                        fx = EE.filterForLaser(E=eeg, width=w, dip=d, stimFreq=sf)#filters out laser stimulation artifact
                        fxx = self.EEG.eegfilter(fx)
                        self.EEG.thetaAmpPhase(fxx)#filters for theta
                        freq = self.EEG.EEGinstfreq
                else:
                        try:
                                freq = self.EEG.EEGinstfreq
                        except:
                                self.EEG.thetaAmpPhase()
                                freq = self.EEG.EEGinstfreq
                freq[freq&lt;0] = np.nan
                sp_bins = np.arange(minSp, maxSp, spStep)
                sp_dig = np.digitize(sp, sp_bins)
                freq = np.reshape(freq, (self.POS.npos, self.EEG.sample_rate/self.POS.pos_sample_rate))
                if np.ma.is_masked(self.POS.speed):
                        mask = np.ma.getmask(self.POS.speed)
                        mask = np.tile(mask.T, self.EEG.sample_rate/self.POS.pos_sample_rate)
                        freq = np.ma.MaskedArray(freq, mask=mask)
                mn_freq = np.nanmean(freq, 1)
                mn_freq = np.ma.compressed(mn_freq)
                X = [mn_freq[sp_dig==i] for i in range(len(sp_bins))]
                # remove any nans which will screw plt.boxplots ability to calculate means
                # and do the boxplot correctly
                for i,x in enumerate(X):
                        idx = ~np.isfinite(x)
                        X[i] = np.delete(x,np.nonzero(idx))
                if ax is None:
                        fig = plt.figure()
                        fig.set_facecolor(&#39;w&#39;)
                        ax = plt.gca()
                else:
                        fig = plt.gcf()
                        fig.set_facecolor(&#39;w&#39;)
                # set up some properties for the elements in the box plot
                bprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                wprops = {&#39;c&#39;: [0.8627, 0.8627, 0.8627]}
                ax.boxplot(X, positions=sp_bins, boxprops=bprops, whiskerprops=wprops)
                medians = np.array([stats.nanmedian(x) for x in X])
                nan_idx = np.isnan(medians)
                slope, intercept, r_value, p_value, std_err = stats.linregress(sp_bins[~nan_idx], medians[~nan_idx])
                minFreq = np.min(medians[~nan_idx]) - 1.0
                maxFreq = np.max(medians[~nan_idx]) + 1.0
                ax.set_ylim(minFreq, maxFreq)
#        ax.set_xlim(0, sp_bins[-1])
#               ylims = np.array(ax.get_ylim())
                xlims = np.array(ax.get_xlim())
                res = stats.theilslopes(medians[~nan_idx], sp_bins[~nan_idx], 0.90)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[0] * sp_bins[-1])), &#39;r-&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[2] * sp_bins[-1])), &#39;r--&#39;)
                ax.plot([0,xlims[1]], (res[1], res[1] + (res[3] * sp_bins[-1])), &#39;r--&#39;)
#        ax.plot([0,xlims[1]], (intercept, intercept + (sp_bins[-1] * slope)), &#39;k--&#39;, lw=2)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                ax.set_xlabel(&#39;Speed (cm/s)&#39;)
                ax.set_title(&#39;Intercept: {0:.3f}    Slope: {1:.5f}&#39;.format(intercept, slope))
                # add the right-hand y-axis and format
                ax1 = ax.twinx()
                # get a histogram of speed to be plotted against the right-hand y-axis
                h,e = np.histogram(np.ma.compressed(sp), bins=len(sp_bins)*10, range=(0, sp_bins[-1]))
                ax1.bar(e[0:-1], h, color=[0.6667, 0.6667, 0], linewidth=0, align=&#39;edge&#39;)
                ax1.set_ylim(0, np.max(h) * 4) # reduce the &#39;height&#39; of the secondary plot
#        ax1.set_xlim(0, sp_bins[-1]+spStep)
                ax1.set_ylabel(&#39;Position samples&#39;, color=[0.6667, 0.6667, 0])
                ax1.yaxis.set_label_coords(1.1,.15)
                ylabels = ax1.yaxis.get_majorticklabels()
                for i,xxx in enumerate(ylabels):
                        if i &gt; 1:
                                xxx.set_visible(False)
                        else:
                                xxx.set_color([0.6667, 0.6667, 0])
                yticks = ax1.yaxis.get_major_ticks()
                for i,xxx in enumerate(yticks):
                        if i &gt; 1:
                                xxx.set_visible(False)
                return ax, intercept, slope</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotFullSAC"><code class="name flex">
<span>def <span class="ident">plotFullSAC</span></span>(<span>self, tetrode, clusters, ax=None, binsize=3, limit2mask=False, plot=True, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the full SAC ie including the edges and colours the central area in colour
and the outlying bits (outside the mask area used to calculate gridness) in black and white</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code></dt>
<dd>plots into this axis</dd>
<dt><strong><code>binsize</code></strong> :&ensp;<code>int</code></dt>
<dd>size of bins (cms)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotFullSAC(self, tetrode, clusters, ax=None, binsize=3, limit2mask=False, plot=True, **kwargs):
        &#34;&#34;&#34;
        Plots the full SAC ie including the edges and colours the central area in colour
        and the outlying bits (outside the mask area used to calculate gridness) in black and white

        Parameters
        ----------
        tetrode : int
        cluster : int
        ax : matplotlib.pyplot.axis
                plots into this axis
        binsize : int
                size of bins (cms)

        &#34;&#34;&#34;
        if plot:
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
        if &#39;step&#39; in kwargs.keys():
                step = kwargs.pop(&#39;step&#39;)
        else:
                step = 30
        rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, limit2mask=limit2mask, **kwargs)[0]
        nodwell = np.isnan(rmap)
        ret = self.autoCorr2D(rmap, nodwell)
        dct = self.getMeasures(ret, step=step)
        if &#39;gaussian&#39; in kwargs.keys():
                kwargs.pop(&#39;gaussian&#39;)
        if plot:
                print(&#39;\nGridness: {0}\nOrientation: {1}\nScale: {2}&#39;.format(dct[&#39;gridness&#39;], dct[&#39;orientation&#39;], dct[&#39;scale&#39;]))
                self.show(ret, dct, ax=ax, **kwargs)
        return dct</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotMap"><code class="name flex">
<span>def <span class="ident">plotMap</span></span>(<span>self, tetrode, clusters, ax=None, var2bin='pos', *args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots a ratemap for a given tetrode and cluster
Wrapper for _plotMap() so multiple clusters can be plotted</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>the tetrode you want to look at</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code>, <code>1xn</code> <code>array</code>/ <code>list</code></dt>
<dd>a single number or list (or 1xn array) of the clusters to plot</dd>
<dt><strong><code>ax</code></strong> :&ensp;optional, <code>defaults</code> <code>to</code> <code>None.</code> <code>Which</code> <code>axis</code> <code>to</code> <code>add</code> <code>the</code> <code>plot</code> <code>to</code>; <code>if</code> <code>None</code></dt>
<dd>then a new figure window is produced</dd>
</dl>
<p><strong>kwargs :
extra arguments include:
'bar' - for use with directional data to produce a polar
histogram plot
'add_peak_rate' - bool
adds the peak rate (to 2 decimal places) to the figure
binsize : int, optional
size of bins. Defaults to 3
smooth_sz : the width of the smoothing kernel (see </strong>kwargs for more)
var2bin: optional, defaults to 'pos'. Which variable to bin.
Can be either 'pos', 'dir' or 'speed'. Works with masked
arrays
smooth : bool, optional. Defaults to true. Whether to smooth the data or
not</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ratemap</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>depending on whether a directional (1d) or positional (2d) map was
asked for an ndarray is returned</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; T = dacq2py_util.Trial('M845_141003t1rh')
&gt;&gt;&gt; # Plot the ratemap for cluster 1 on tetrode 1
&gt;&gt;&gt; T.plotMap(1,1)
&gt;&gt;&gt; # Add the peak rate to the figure window
&gt;&gt;&gt; T.plotMap(1,1,add_peak_rate=True)
&gt;&gt;&gt; # Plot the polar map for same cluster
&gt;&gt;&gt; T.plotMap(1,1,var2bin='dir')
&gt;&gt;&gt; # Plot the unsmoothed dwell map for the trial
&gt;&gt;&gt; T.plotMap(None,None,smooth=False)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plotMap(self, tetrode, clusters, ax=None, var2bin=&#39;pos&#39;, *args, **kwargs):
                &#34;&#34;&#34;
                Plots a ratemap for a given tetrode and cluster
                Wrapper for _plotMap() so multiple clusters can be plotted

                Parameters
                ----------
                tetrode : int
                                 the tetrode you want to look at
                cluster : int, 1xn array/ list
                                 a single number or list (or 1xn array) of the clusters to plot
                ax : optional, defaults to None. Which axis to add the plot to; if None
                                        then a new figure window is produced
                **kwargs :
                        extra arguments include:
                        &#39;bar&#39; - for use with directional data to produce a polar
                        histogram plot
                        &#39;add_peak_rate&#39; - bool
                        adds the peak rate (to 2 decimal places) to the figure
                        binsize : int, optional
                                size of bins. Defaults to 3
                        smooth_sz : the width of the smoothing kernel (see **kwargs for more)
                                var2bin: optional, defaults to &#39;pos&#39;. Which variable to bin.
                                Can be either &#39;pos&#39;, &#39;dir&#39; or &#39;speed&#39;. Works with masked
                                arrays
                        smooth : bool, optional. Defaults to true. Whether to smooth the data or
                                not

                Returns
                -------
                ratemap : numpy.ndarray
                        depending on whether a directional (1d) or positional (2d) map was
                        asked for an ndarray is returned

                Examples
                --------
                &gt;&gt;&gt; T = dacq2py_util.Trial(&#39;M845_141003t1rh&#39;)
                &gt;&gt;&gt; # Plot the ratemap for cluster 1 on tetrode 1
                &gt;&gt;&gt; T.plotMap(1,1)
                &gt;&gt;&gt; # Add the peak rate to the figure window
                &gt;&gt;&gt; T.plotMap(1,1,add_peak_rate=True)
                &gt;&gt;&gt; # Plot the polar map for same cluster
                &gt;&gt;&gt; T.plotMap(1,1,var2bin=&#39;dir&#39;)
                &gt;&gt;&gt; # Plot the unsmoothed dwell map for the trial
                &gt;&gt;&gt; T.plotMap(None,None,smooth=False)
                &#34;&#34;&#34;

                for key in (&#39;var2bin&#39;, &#39;ax&#39;, &#39;binsize&#39;,&#39;smooth_sz&#39;, &#39;smooth&#39;):
                        if key in kwargs:
                                setattr(self, key, kwargs[key])
                if isinstance(clusters, int):
                        setattr(self, &#39;clusters&#39;, [clusters])
                elif isinstance(clusters, list):
                        setattr(self, &#39;clusters&#39;, clusters)
                elif isinstance(clusters, str):
                        if &#39;all&#39; in clusters:
                                tetDict = self.getTsAndCs()
                                setattr(self, &#39;clusters&#39;, tetDict[tetrode])
                clusters = getattr(self, &#39;clusters&#39;, None)
#               var2bin = getattr(self, &#39;var2bin&#39;, &#39;pos&#39;)
                ax = getattr(self, &#39;ax&#39;, None)
                binsize = getattr(self, &#39;binsize&#39;, 3)
                smooth_sz = getattr(self.ratemap, &#39;smooth_sz&#39;, 5)
                smooth = getattr(self, &#39;smooth&#39;, True)

                if len(clusters) == 1:
                        ncols = 1
                        nrows = 1
                elif np.logical_and(len(clusters) &gt; 1, len(clusters) &lt; 6):
                        ncols = len(clusters)
                        nrows = 1
                else:
                        ncols = 5
                        nrows = int(np.floor(len(clusters) / 5) + 1)
                if ax is None:
                        fig = plt.figure()
                        if &#39;dir&#39; in var2bin:
                                ax = fig.add_subplot(nrows, ncols, 1, projection=&#39;polar&#39;)
                        else:
                                ax = fig.add_subplot(nrows, ncols, 1)
                axes_out = []
                if clusters is None:
                        axes = fig.add_subplot(1, 1, 1)
                        ax, ratemap = self._plotMap(None, None, var2bin=var2bin, ax=ax,
                                                  binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        self._set_ax_title(axes, tetrode, clusters)
                        axes_out.append(ax)
                if len(clusters) == 1:
                        cluster = clusters[0]

                        ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin, ax=ax,
                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth, *args, **kwargs)
                        axes = ax
#                       # check kwargs to see if we want to add peak rate to axes
                        if &#34;add_peak_rate&#34; in kwargs:
                                if kwargs[&#39;add_peak_rate&#39;]:
                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(ratemap)), (0.9,0.15), \
                                                        xycoords=&#39;figure fraction&#39;, textcoords=&#39;figure fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)


                        self._set_ax_title(axes, tetrode, cluster)
                        axes_out.append(ax)
                else:
                        fig.set_facecolor(&#39;w&#39;)
                        fig.set_frameon(False)
                        plt.setp(ax.get_xticklabels(), visible=False)
                        plt.setp(ax.get_yticklabels(), visible=False)
                        for iax, cluster in enumerate(clusters):
                                inax = fig.add_subplot(nrows, ncols, iax+1)
                                ax, ratemap = self._plotMap(tetrode=tetrode, cluster=cluster, var2bin=var2bin,
                                                          binsize=binsize, smooth_sz=smooth_sz, smooth=smooth,
                                                          ax=inax)
                                self._set_ax_title(inax, tetrode, cluster)
                                axes_out.append(ax)
                return axes_out</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotPath"><code class="name flex">
<span>def <span class="ident">plotPath</span></span>(<span>self, ax=None, clamp=False, label=False, applyStm=False, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the animals path during a trial. Default is to limit plot range
to the min/ max of x/y extent of path</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>The axes to plot into. If none a new figure window is created</dd>
<dt><strong><code>clamp</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether the axes are clamped to self._xlims and self._ylims or not</dd>
<dt><strong><code>applyStm</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to overlay r crosses on the path where the laser events occurred</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotPath(self, ax=None, clamp=False, label=False, applyStm=False, **kwargs):
        &#39;&#39;&#39;
        Plots the animals path during a trial. Default is to limit plot range
        to the min/ max of x/y extent of path

        Parameters
        ----------
        ax : matplotlib.Axes
                The axes to plot into. If none a new figure window is created
        clamp : bool
                whether the axes are clamped to self._xlims and self._ylims or not
        applyStm : bool
                Whether to overlay r crosses on the path where the laser events occurred
        &#39;&#39;&#39;
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        else:
                fig = plt.gcf()
        fig.set_facecolor(&#39;w&#39;)
        xy = self._getPath()
        ax.plot(xy[0], xy[1], color=[0.8627, 0.8627, 0.8627],**kwargs)
        ax.invert_yaxis()
        if applyStm:
                stmTS = self.STM.getPosTS()
                stmXY = xy[:, stmTS.astype(int)]
                ax.plot(stmXY[0], stmXY[1], &#39;rx&#39;, ms=2)
        if clamp:
                ax.set_xlim(self._xlims)
                ax.set_ylim(self._ylims)
        ax.set_aspect(&#39;equal&#39;)
        if not label:
                plt.setp(ax.get_xticklabels(), visible=False)
                plt.setp(ax.get_yticklabels(), visible=False)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseInField"><code class="name flex">
<span>def <span class="ident">plotPhaseInField</span></span>(<span>self, tetrode, cluster, ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots theta phase of spikes in a place field (found using _getFieldLims)
as individual colours for each run through the field
TODO: broken
Parameters</p>
<hr>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotPhaseInField(self, tetrode, cluster, ax=None, **kwargs):
        &#39;&#39;&#39;
        Plots theta phase of spikes in a place field (found using _getFieldLims)
        as individual colours for each run through the field
        TODO: broken
        Parameters
        ----------
        tetrode : int
        cluster : int
        ax : matplotlib.Axes
        &#39;&#39;&#39;
        if not self.EEG:
                self.EEG = EEG(self.filename_root)
        self.EEG.thetaAmpPhase()
        self.EEG.EEGphase = np.rad2deg(self.EEG.EEGphase)
        runs_to_keep, spk_in_run, run_duration = self.getFieldRuns(tetrode, cluster)
        if ax is None:
                ax = plt.gca()
        else:
                ax = ax
        for spks in spk_in_run:
                ax.plot(self.POS.xy[0,spks], self.EEG.EEGphase[spks * self.pos2eegScale]+180,&#39;.&#39;)
        ax.set_title(self.filename_root.split(&#39;\\&#39;)[-1] + &#39; cluster &#39; + str(cluster) + &#39; on tetrode &#39; + str(tetrode))
        plt.show()</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseOfFiring"><code class="name flex">
<span>def <span class="ident">plotPhaseOfFiring</span></span>(<span>self, tetrode, cluster, ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the phase of firing of a given cluster as a histogram</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotPhaseOfFiring(self, tetrode, cluster, ax=None, **kwargs):
        &#34;&#34;&#34;
        Plots the phase of firing of a given cluster as a histogram

        Parameters
        ----------
        tetrode : int
        cluster : int
        ax : matplotlib.Axes
        &#34;&#34;&#34;

        phase = self._getClusterPhaseVals(tetrode, cluster)
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(211)
                ax2 = fig.add_subplot(212)
        # make the plot like the Somogyi figures!
        fig.set_facecolor(&#39;#203C8A&#39;)
        phase = np.hstack((phase, phase + (2*np.pi)))
        ax2.hist(phase, bins=120, range=(-np.pi, 3*np.pi), color=&#39;w&#39;, histtype=&#39;stepfilled&#39;)
        t = np.arange(-np.pi, 3 * np.pi, 0.1)
        ax.plot(t, np.sin(t), &#39;w&#39;)
        ax.annotate(&#39;180&#39;, xy=(-np.pi-0.2, 0), xycoords=&#39;data&#39;, ha=&#39;right&#39;, va=&#39;center&#39;,
                                color=&#39;w&#39;, fontsize=20)
        ax.set_axis_bgcolor(&#39;#203C8A&#39;)
        ax.set_ylim(-1.1, 1.1)
        ax.axis(&#39;off&#39;)
        ax2.set_axis_bgcolor(&#39;#203C8A&#39;)
        plt.axis(&#39;off&#39;)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotRaster"><code class="name flex">
<span>def <span class="ident">plotRaster</span></span>(<span>self, tetrode, clusters, ax=None, dt=(-50, 100), prc_max=0.5, ms_per_bin=1, histtype='count', hist=True, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Wrapper for _plotRaster allowing multiple clusters to be plotted in
separate figure windows</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>2</code>-<code>tuple</code></dt>
<dd>the window of time in ms to examine zeroed on the event of interest
i.e. the first value will probably be negative as in the default example</dd>
<dt><strong><code>prc_max</code></strong> :&ensp;<code>float</code></dt>
<dd>the proportion of firing the cell has to 'lose' to count as
silent; a float between 0 and 1</dd>
<dt>ax - matplotlib.Axes</dt>
<dt>the axes to plot into. If not provided a new figure is created</dt>
<dt><strong><code>ms_per_bin</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of milliseconds in each bin of the raster plot</dd>
<dt><strong><code>histtype</code></strong> :&ensp;<code>str</code></dt>
<dd>either 'count' or 'rate' - the resulting histogram plotted above the raster plot will
consist of either the counts of spikes in ms_per_bin or the mean rate
in ms_per_bin</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotRaster(self, tetrode, clusters, ax=None, dt=(-50, 100), prc_max = 0.5, ms_per_bin=1, histtype=&#39;count&#39;, hist=True, **kwargs):
        &#34;&#34;&#34;
        Wrapper for _plotRaster allowing multiple clusters to be plotted in
        separate figure windows

        Parameters
        ----------
        tetrode : int
        cluster : int
        dt : 2-tuple
                the window of time in ms to examine zeroed on the event of interest
                i.e. the first value will probably be negative as in the default example
        prc_max : float
                the proportion of firing the cell has to &#39;lose&#39; to count as
                silent; a float between 0 and 1
        ax - matplotlib.Axes
                the axes to plot into. If not provided a new figure is created
        ms_per_bin : int
                The number of milliseconds in each bin of the raster plot
        histtype : str
                either &#39;count&#39; or &#39;rate&#39; - the resulting histogram plotted above the raster plot will
                consist of either the counts of spikes in ms_per_bin or the mean rate
                in ms_per_bin
        &#34;&#34;&#34;
        if isinstance(clusters, int):
                clusters = [clusters]
        elif isinstance(clusters, str):
                if &#39;all&#39; in clusters:
                        tetDict = self.getTsAndCs()
                        clusters = tetDict[tetrode]
        for cluster in clusters:
                # Calculate the stimulation ratio
                stim_histo = self.getRasterHist(tetrode, cluster, dt=dt, hist=hist)
                mean_stim_spikes = np.sum(stim_histo, 1)
                pre_stim_spks = np.mean(mean_stim_spikes[0:50])
                post_stim_spks = np.mean(mean_stim_spikes[50:60])
                ratio = (post_stim_spks-pre_stim_spks) / (post_stim_spks+pre_stim_spks)
                print(&#34;Stimulation ratio = {}&#34;.format(ratio))
                self._plotRaster(tetrode=tetrode, cluster=cluster, dt=dt,prc_max=prc_max, ax=ax, ms_per_bin=ms_per_bin,histtype=histtype, **kwargs)
        return ratio</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotRateVSpeed"><code class="name flex">
<span>def <span class="ident">plotRateVSpeed</span></span>(<span>self, tetrode, cluster, minSpeed=0.0, maxSpeed=40.0, sigma=3.0, shuffle=False, nShuffles=100, plot=False, ax=None, verbose=False, getShuffledData=False, getData=False, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the instantaneous firing rate of a cell against running speed
Also outputs a couple of measures as with Kropff et al., 2015; the
Pearsons correlation and the depth of modulation (dom) - see below for
details</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>the tetrode to use</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>the cluster to use</dd>
<dt><strong><code>minSpeed</code></strong> :&ensp;<code>float</code></dt>
<dd>speeds below this value are masked and not used</dd>
<dt><strong><code>maxSpeed</code></strong> :&ensp;<code>float</code></dt>
<dd>speeds above this value are masked and not used</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code></dt>
<dd>the standard deviation of the gaussian used to smooth the spike
train</dd>
<dt><strong><code>shuffle</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to calculate the significance of the speed score or not
This is done by calculating the correlation between speed and
the shuffled spike train for nShuffles where the shuffles are only allowed with the
window (trial_start + minTime) : (trial_end - minTime). Default is
30 seconds as with Kropff et al., 2015. Default False</dd>
<dt><strong><code>nShuffles</code></strong> :&ensp;<code>int</code></dt>
<dd>How many times to perform the shuffle. Defaults to 100 as with
Kropff et al., 2015</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to plot output or not. Defaults to False</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotRateVSpeed(self, tetrode, cluster, minSpeed=0.0, maxSpeed = 40.0, 
                                   sigma=3.0, shuffle=False, nShuffles=100, plot=False, ax=None,
                                   verbose=False, getShuffledData=False, getData=False, **kwargs):
        &#39;&#39;&#39;
        Plots the instantaneous firing rate of a cell against running speed
        Also outputs a couple of measures as with Kropff et al., 2015; the
        Pearsons correlation and the depth of modulation (dom) - see below for
        details

        Parameters
        -------------------
        tetrode : int
                the tetrode to use
        cluster : int
                the cluster to use
        minSpeed : float
                speeds below this value are masked and not used
        maxSpeed : float
                speeds above this value are masked and not used
        sigma : float
                the standard deviation of the gaussian used to smooth the spike
                train
        shuffle : bool, default False
                Whether to calculate the significance of the speed score or not
                This is done by calculating the correlation between speed and
                the shuffled spike train for nShuffles where the shuffles are only allowed with the
                window (trial_start + minTime) : (trial_end - minTime). Default is
                30 seconds as with Kropff et al., 2015. Default False
        nShuffles : int
                How many times to perform the shuffle. Defaults to 100 as with
                Kropff et al., 2015
        plot : bool
                Whether to plot output or not. Defaults to False
        &#39;&#39;&#39;

        speed = self.POS.speed.ravel()
        # Calculate histogram to see how much is accounted for in each bin
        if np.nanmax(speed) &lt; maxSpeed:
                maxSpeed = np.nanmax(speed)
                if verbose:
                        print(&#39;Capping speed to max in data: {:.2f}&#39;.format(maxSpeed))
        spd_bins = np.arange(minSpeed, maxSpeed, 1.0)
        # Construct the mask
        speed_filt = np.ma.MaskedArray(speed)
        speed_filt = np.ma.masked_where(speed_filt &lt; minSpeed, speed_filt)
        speed_filt = np.ma.masked_where(speed_filt &gt; maxSpeed, speed_filt)
        spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
        spk_sm = np.ma.MaskedArray(spk_sm, mask=np.ma.getmask(speed_filt))

        # res is the basic correlation between running speed and instantaneous
        # firing rate
        res = stats.mstats.pearsonr(spk_sm, speed_filt)
        if shuffle:
                duration = self.POS.npos / self.POS.pos_sample_rate
                shuffles = np.linspace(30, duration-30, nShuffles)
                shuffled_rs = []
                for time in shuffles:
                        shuffled_spks = self._getTimeSmoothedSpikes(tetrode, cluster, sigma, time)
                        shuffled_rs.append(stats.mstats.pearsonr(shuffled_spks, speed_filt)[0])
                prob = np.array([.90, .95, .99])
                qtiles = stats.mstats.mquantiles(shuffled_rs, prob)
                if verbose:
                        print(&#34;Running speed vs firing rate correlation (PPMC): {0}&#34;.format(res[0]))
                        print(&#34;The {0} percentiles are {1}&#34;.format(prob*100, qtiles))
        spd_dig  = np.digitize(speed_filt, spd_bins, right=True)
        mn_rate = np.array([np.ma.mean(spk_sm[spd_dig==i]) for i in range(0,len(spd_bins))])
        if plot:
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                ax.plot(spd_bins, mn_rate * self.POS.pos_sample_rate, &#39;k&#39;)
                ax.set_xlim(spd_bins[0], spd_bins[-1])
                ax.set_ylabel(&#34;Firing rate(Hz)&#34;)
                ax.set_xlabel(&#34;Speed(cm/s)&#34;)
                ylabels = ax.get_yticklabels()
                for i in range(1, len(ylabels)-1):
                        ylabels[i].set_visible(False)
                yticks = ax.get_yticklines()
                for i in range(1, len(yticks)-1):
                        yticks[i].set_visible(False)
                xlabels = ax.get_xticklabels()
                for i in range(1, len(xlabels)-1):
                        xlabels[i].set_visible(False)
                xticks = ax.get_xticklines()
                for i in range(1, len(xticks)-1):
                        xticks[i].set_visible(False)
                ax.spines[&#39;right&#39;].set_visible(False)
                ax.spines[&#39;top&#39;].set_visible(False)
                ax.yaxis.set_ticks_position(&#39;left&#39;)
                ax.xaxis.set_ticks_position(&#39;bottom&#39;)
                if &#34;add_peak_rate&#34; in kwargs:
                        if kwargs[&#39;add_peak_rate&#39;]:
                                ax.annotate(&#39;{:.2f}&#39;.format(np.max(res[0])), (0.15,0.9), \
                                                xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

        if getData:
                return res[0], spd_bins, mn_rate * self.POS.pos_sample_rate
        if getShuffledData:
                return res[0], shuffled_rs
        else:
                return res[0]</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotRollingCorrRateVSpeed"><code class="name flex">
<span>def <span class="ident">plotRollingCorrRateVSpeed</span></span>(<span>self, tetrode, cluster, minSpeed=2.0, sigma=3.0, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the rolling correlation of instantaneous firing rate of a given
cell against running speed</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>minSpeed</code></strong> :&ensp;<code>float</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code></dt>
<dd>The width of the smoothing kernel applied to the spike train to smooth it</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotRollingCorrRateVSpeed(self, tetrode, cluster, minSpeed=2.0,
                                                          sigma=3.0, **kwargs):
        &#39;&#39;&#39;
        Plots the rolling correlation of instantaneous firing rate of a given
        cell against running speed

        Parameters
        ----------
        tetrode : int
        cluster : int
        minSpeed : float
        sigma : float
                The width of the smoothing kernel applied to the spike train to smooth it
        &#39;&#39;&#39;
        speed_filt = self.POS.speed.ravel()
        #filter for low speeds
        lowSpeedIdx = speed_filt &lt; minSpeed
        spk_sm = self._getTimeSmoothedSpikes(tetrode, cluster, sigma)
        windowSize = 50
        runningCorr = np.ones_like(spk_sm)
        for i in range(len(spk_sm)):
                runningCorr[i] = stats.pearsonr(spk_sm[i:i+windowSize],
                                                                                  speed_filt[i:i+windowSize])[0]
        speed_filt = np.ma.MaskedArray(speed_filt, lowSpeedIdx)
        spk_sm = np.ma.MaskedArray(spk_sm, lowSpeedIdx)
        # mask the running correlation where there is no rate (ie the cell fails
        # to fire)
        new_mask = np.ma.mask_or(lowSpeedIdx, spk_sm==0)
        runningCorr = np.ma.MaskedArray(runningCorr, new_mask)
        fig, ax = plt.subplots()
        fig.subplots_adjust(right=0.75)
        ax2 = ax.twinx()
        ax3 = ax.twinx()
        ax2.spines[&#34;right&#34;].set_position((&#34;axes&#34;, 1.2))
        ax3.set_frame_on(True)
        ax3.patch.set_visible(False)
        for sp in ax.spines.values():
                sp.set_visible(False)
        ax3.spines[&#34;right&#34;].set_visible(True)

        p1, = ax.plot(speed_filt, &#39;b&#39;)
        p2, = ax2.plot(spk_sm, &#39;r&#39;)
        p3, = ax3.plot(runningCorr, &#39;k&#39;)

        ax.set_xlim(0, len(speed_filt))
        ax.set_ylim(0, np.max(speed_filt))
        ax2.set_ylim(0, np.max(spk_sm))
        ax3.set_ylim(-1, 1)

        ax.set_ylabel(&#39;Speed(cm/s)&#39;)
        ax2.set_ylabel(&#39;Instantaneous firing rate(Hz)&#39;)
        ax3.set_ylabel(&#39;Running correlation&#39;)

        ax.yaxis.label.set_color(p1.get_color())
        ax2.yaxis.label.set_color(p2.get_color())
        ax3.yaxis.label.set_color(p3.get_color())

        tkw = dict(size=4, width=1.5)
        ax.tick_params(axis=&#39;y&#39;, colors=p1.get_color(), **tkw)
        ax2.tick_params(axis=&#39;y&#39;, colors=p2.get_color(), **tkw)
        ax3.tick_params(axis=&#39;y&#39;, colors=p3.get_color(), **tkw)
        ax.tick_params(axis=&#39;x&#39;, **tkw)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotSAC"><code class="name flex">
<span>def <span class="ident">plotSAC</span></span>(<span>self, tetrode, clusters, ax=None, binsize=3, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the spatial autocorrelogram of the given tetrode/ cluster</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code></dt>
<dd>plots into this axis</dd>
<dt><strong><code>binsize</code></strong> :&ensp;<code>int</code></dt>
<dd>size of bins (cms)</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>plotFullSAC</code></p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotSAC(self, tetrode, clusters, ax=None, binsize=3, **kwargs):
        &#34;&#34;&#34;
        Plots the spatial autocorrelogram of the given tetrode/ cluster

        Parameters
        ----------
        tetrode : int
        cluster : int
        ax : matplotlib.pyplot.axis
                plots into this axis
        binsize : int
                size of bins (cms)

        See Also
        --------
                plotFullSAC

        &#34;&#34;&#34;
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        rmap = self._getMap(tetrode=tetrode, cluster=clusters, binsize=binsize, **kwargs)[0]
        nodwell = ~np.isfinite(rmap)
        ret = self.autoCorr2D(rmap, nodwell)
        ax.imshow(ret, interpolation=&#39;nearest&#39;, origin=&#39;lower&#39;)
        ax.set_aspect(&#39;equal&#39;)
        plt.setp(ax.get_xticklabels(), visible=False)
        plt.setp(ax.get_yticklabels(), visible=False)
        return ax</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotSpectrogram"><code class="name flex">
<span>def <span class="ident">plotSpectrogram</span></span>(<span>self, eegType='eeg', ymin=0, ymax=50, ax=None, secsPerBin=2, laser=False, width=0.125, dip=15.0)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots a spectrogram of the LFP of the whole trial</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>eegType</code></strong> :&ensp;<code>str</code></dt>
<dd>Whether to do use .eeg file or .egf file. Defaults to eeg</dd>
<dt>ymin / ymax : int</dt>
<dt>Minimum/ maximum frequency (y-axis) to plot</dt>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.pyplot.axis</code>]</dt>
<dd>Which axis to add the plot to. If None a new figure window is produced</dd>
<dt><strong><code>secsPerBin</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of the x-axis bins</dd>
<dt><strong><code>laser</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to filter the eeg for laser stimulation events</dd>
</dl>
<p>width/ dip : float
Parameters for Kaisser filter in eegcalcs.EEGCalcs - see there
for definition</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Plots</code> <code>the</code> <code>spectrogram</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plotSpectrogram(self, eegType=&#39;eeg&#39;, ymin=0, ymax=50, ax=None, secsPerBin=2,
                                                laser=False, width=0.125, dip=15.0):
                &#39;&#39;&#39;
                Plots a spectrogram of the LFP of the whole trial

                Parameters
                --------------
                eegType : str
                        Whether to do use .eeg file or .egf file. Defaults to eeg
                ymin / ymax : int
                        Minimum/ maximum frequency (y-axis) to plot
                ax : matplotlib.pyplot.axis]
                        Which axis to add the plot to. If None a new figure window is produced
                secsPerBin : int
                        Size of the x-axis bins
                laser : bool
                        Whether to filter the eeg for laser stimulation events
                width/ dip : float
                        Parameters for Kaisser filter in eegcalcs.EEGCalcs - see there
                        for definition

                Returns
                ------------
                Plots the spectrogram
                &#39;&#39;&#39;

                if &#39;eeg&#39; in eegType:
                        E = self.EEG.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EEG.sample_rate
                elif &#39;egf&#39; in eegType:
                        E = self.EGF.eeg
                        if np.ma.is_masked(E):
                                E = E.compressed()
                        Fs = self.EGF.sample_rate

                EE = EEGCalcs(self.filename_root,thetaRange=[6,12])
                if laser:
                        &#39;&#39;&#39;
                        Split the eeg into the parts where the laser is on and off
                        and then reassemble for the spectrogram
                        NB this assumes the laser comes on at 600s for 20 minutes
                        and then goes off
                        &#39;&#39;&#39;
                        mask = np.ones_like(E).astype(bool)

                        mask[600*int(Fs):1800*int(Fs)] = False
                        # filter
#                       import pdb
#                       pdb.set_trace()
                        fx = EE.filterForLaser(E=E[~mask], width=width, dip=dip)
                        # reassemble
                        Etmp = np.zeros_like(E)
                        Etmp[~mask] = fx
                        Etmp[mask] = E[mask]
                        fx = Etmp

                else:
                        fx = E
                nperseg = int(Fs * secsPerBin)
                freqs, times, Sxx = signal.spectrogram(fx, Fs, nperseg=nperseg)
#               Sxx_sm = self.ratemap.blurImage(Sxx, (secsPerBin*2)+1)
                Sxx_sm = Sxx
                x, y = np.meshgrid(times, freqs)
                if ax is None:
                        plt.figure()
                        ax = plt.gca()
                        im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, cmap=&#39;RdBu&#39;,norm=colors.LogNorm())
                im = ax.pcolormesh(x, y, Sxx_sm, edgecolors=&#39;face&#39;, norm=colors.LogNorm())
                ax.set_xlim(times[0], times[-1])
                ax.set_ylim(ymin, ymax)
                ax.set_xlabel(&#39;Time(s)&#39;)
                ax.set_ylabel(&#39;Frequency(Hz)&#39;)
                if laser:
                        ax.vlines(600,ymin,ymax)
                        ax.vlines(1800,ymin,ymax)

                        ax.set_xticks((0, 600, 1800, 2400))
                        ax.set_xticklabels((str(0), str(600), str(1800), str(2400)))
                return freqs, times, Sxx, im</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotSpikesOnPath"><code class="name flex">
<span>def <span class="ident">plotSpikesOnPath</span></span>(<span>self, tetrode, clusters, ax=None, clamp=False, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the spikes on the path during a trial for a particular tetrode/
cluster(s)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>the tetrode you want to look at</dd>
<dt><strong><code>cluster</code></strong> :&ensp;<code>int</code>, <code>1xn</code> <code>array</code>/ <code>list</code></dt>
<dd>a single number or list (or 1xn array) of the clusters to plot</dd>
<dt><strong><code>clamp</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>whether to restrict the plot to the self._xlims and self_ylims
property</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>defaults to None. Which axis to add the plot to.
If None a new figure window is produced</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotSpikesOnPath(self, tetrode, clusters, ax=None, clamp=False, **kwargs):
        &#39;&#39;&#39;
        Plots the spikes on the path during a trial for a particular tetrode/
        cluster(s)

        Parameters
        ----------
        tetrode: int
                        the tetrode you want to look at
        cluster : int, 1xn array/ list
                        a single number or list (or 1xn array) of the clusters to plot
        clamp : bool, optional
                        whether to restrict the plot to the self._xlims and self_ylims
                        property
        ax : matplotlib.Axes
                defaults to None. Which axis to add the plot to.
                If None a new figure window is produced

        &#39;&#39;&#39;
        if not isinstance(clusters, (np.ndarray, list)):
                if isinstance(clusters, str):
                        clusters = self.availableClusters
                else:
                        clusters = [clusters]
        xy = self.POS.xy
        for i, clust in enumerate(clusters):
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                ax.plot(xy[0], xy[1], c=tcols.colours[0], zorder=1)
                idx = self.TETRODE[tetrode].getClustIdx(clust)
                # useful to override default colour scheme for publication figures
                if &#39;mec&#39; in kwargs.keys():
                        mec = kwargs.pop(&#39;mec&#39;)
                else:
                        mec = tcols.colours[clust]
                ax.plot(xy[0, idx], xy[1, idx], &#39;s&#39;, c=mec, mec=mec, **kwargs)
                if clamp:
                        ax.set_xlim(self._xlims)
                        ax.set_ylim(self._ylims)
                ax.set_aspect(&#39;equal&#39;)
                ax.invert_yaxis()
                plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                bottom=&#39;off&#39;, top=&#39;off&#39;)
                plt.setp(ax.get_xticklabels() + ax.get_yticklabels(),
                                 visible=False)
        return ax</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotWaveforms"><code class="name flex">
<span>def <span class="ident">plotWaveforms</span></span>(<span>self, tetrode, clusters, ax=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots spike waveforms on all four wires for a given tetrode/ cluster
The units for the plots are <em>real</em> in the sense that the x-axis is in
ms and the y-axis is in micro-volts. The axes limits are set up so the
ratio between the x and y axes is 100</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>clusters</code></strong> :&ensp;<code>int</code> or <code>list</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>the axes to plot into. If None a new figure window is created.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotWaveforms(self, tetrode, clusters, ax=None, **kwargs):
        &#34;&#34;&#34;
        Plots spike waveforms on all four wires for a given tetrode/ cluster
        The units for the plots are *real* in the sense that the x-axis is in
        ms and the y-axis is in micro-volts. The axes limits are set up so the 
        ratio between the x and y axes is 100

        Parameters
        ----------
        tetrode : int
        clusters : int or list
        ax : matplotlib.Axes
                the axes to plot into. If None a new figure window is created.
        &#34;&#34;&#34;
        waves = self.TETRODE[tetrode].waveforms
        clust_idx = self.TETRODE[tetrode].cut == clusters
        clust_waves = waves[clust_idx, :, :]
        gains = self.TETRODE[tetrode].gains
        samps_per_spike = int(self.TETRODE[tetrode].header[&#39;samples_per_spike&#39;])
        clust_waves = clust_waves * 1e6 # now in uv
        ADC_scale = int(self.setheader[&#39;ADC_fullscale_mv&#39;])
        axes_scales = (ADC_scale / gains.astype(float)) * 1000 # axes limits in uv
        if ~np.any(clust_idx):
                return
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        else:
                fig = kwargs[&#39;figure&#39;]
                ax = ax
        ax.axis(&#39;off&#39;)
        rect = ax.get_position().bounds
        x = np.linspace(0, 0.001, samps_per_spike)
        if &#39;clustColour&#39; in kwargs.keys():
                clustColour = kwargs[&#39;clustColour&#39;]
        else:
                if clusters is None:
                        clustColour = tcols.colours[0]
                else:
                        clustColour = tcols.colours[clusters]
        grid = ImageGrid(fig, rect, nrows_ncols= (1, 4), axes_pad=0.1, add_all=True, share_all=True)
        for i in range(4):
                lc = LineCollection(list(zip(x,y) for y in np.squeeze(clust_waves[:, i, :])))
                lc.set_rasterized(True)
                lc.set_color(clustColour)
                grid[i].add_collection(lc)
                grid[i].plot(x, np.squeeze(np.mean(clust_waves[:, i, :], 0)), &#39;w-&#39;)
                grid[i].set_aspect(2.5e-6*(ADC_scale/1000.))
                grid[i].set_xlim(0, 0.001)
                grid[i].set_ylim(-axes_scales[i], axes_scales[i])
                grid[i].set_rasterized(True)
                grid[i].tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                bottom=&#39;off&#39;, top=&#39;off&#39;)
                grid[i].text(0.9,0.95, str(i+1), va=&#39;top&#39;, ha=&#39;right&#39;, size=&#39;small&#39;, color=&#39;k&#39;, transform=grid[i].transAxes)

        plt.setp([a.get_xticklabels() for a in grid], visible=False)
        plt.setp([a.get_yticklabels() for a in grid], visible=False)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plotXCorr"><code class="name flex">
<span>def <span class="ident">plotXCorr</span></span>(<span>self, tetrode, clusters, ax=None, Trange=(-500, 500), bins=None, annotate=True, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots the temporal autocorrelogram (defaults to +/- 500ms)
TODO: needs to be able to take in two tetrodes &amp; make sure Trange in ms</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tetrode</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>clusters</code></strong> :&ensp;<code>int</code> or <code>list</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.Axes</code></dt>
<dd>The axes to plot into. If None a new figure window is created</dd>
<dt><strong><code>TRange</code></strong> :&ensp;<code>two</code>-<code>tuple</code></dt>
<dd>The range over which to examine the events. Zero time is the occurance of the event</dd>
<dt><strong><code>bins</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of bins to assign the data to</dd>
<dt><strong><code>annotate</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to add the cluster identities to the figure axis</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>if 'add_peak_rate' is in the kwargs then that is also added to the axes</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotXCorr(self, tetrode, clusters, ax=None, Trange=(-500,500), bins=None, annotate=True, **kwargs):
        &#39;&#39;&#39;
        Plots the temporal autocorrelogram (defaults to +/- 500ms)
        TODO: needs to be able to take in two tetrodes &amp; make sure Trange in ms

        Parameters
        ----------
        tetrode : int
        clusters : int or list
        ax : matplotlib.Axes
                The axes to plot into. If None a new figure window is created
        TRange : two-tuple
                The range over which to examine the events. Zero time is the occurance of the event
        bins : int
                The number of bins to assign the data to
        annotate : bool
                Whether to add the cluster identities to the figure axis
        **kwargs
                if &#39;add_peak_rate&#39; is in the kwargs then that is also added to the axes
        &#39;&#39;&#39;
        if isinstance(clusters, (np.ndarray, list, int)):
                clusters = [clusters]
        if isinstance(tetrode, (np.ndarray, list, int)):
                tetrode = [tetrode]
        duration = np.diff(Trange)
        if bins is None:
                bins = 201
        if ax is None:
                fig = plt.figure()
                ax = fig.add_subplot(111)
        if len(clusters) == 1:
                cluster_a = cluster_b = clusters[0]
        elif len(clusters) == 2:
                cluster_a = clusters[0]
                cluster_b = clusters[1]
        if len(tetrode) == 1:
                tetrode_a = tetrode[0]
                tetrode_b = None
        elif len(tetrode) == 2:
                tetrode_a = tetrode[0]
                tetrode_b = tetrode[1]
        Trange = np.array(Trange)
        timebase = self.TETRODE[tetrode_a].timebase
        x1 = self.TETRODE[tetrode_a].getClustTS(cluster_a) / (timebase/1000)
        if tetrode_b is None:
                if cluster_b is None:
                        x2 = x1
                        cluster_b = cluster_a
                else:
                        x2 = self.TETRODE[tetrode_a].getClustTS(cluster_b) / (timebase/1000)
        else:
                x2 = self.TETRODE[tetrode_b].getClustTS(cluster_b) / (timebase/1000)
        if self.posFilter:
                idx = np.nonzero(~self.POS.xy.mask[0])[0] # indices to keep
                x1PosSamp = (x1 / (1000 / self.POS.pos_sample_rate)).astype(int)
                x1 = x1[np.in1d(x1PosSamp, idx)]
                if cluster_b is not None:
                        x2PosSamp = (x2 / (1000 / self.POS.pos_sample_rate)).astype(int)
                        x2 = x2[np.in1d(x2PosSamp, idx)]
        y = self.spikecalcs.xcorr(x1, x2, Trange=Trange)
        h = ax.hist(y[y != 0], bins=bins, range=Trange, color=&#39;k&#39;, histtype=&#39;stepfilled&#39;)
        ax.set_xlim(Trange)
        if annotate:
                if cluster_b is None:
                        cond_rate = np.count_nonzero(y == 0) / np.float(duration)
                        ax.text(0.55, .9, &#34;{0:.4}&#34;.format(str(cond_rate)), ha=&#39;center&#39;, va=&#39;center&#39;,
                                        transform=ax.transAxes)
                else:
                        if np.logical_or((tetrode_a == tetrode_b), tetrode_b is None):
                                if (cluster_a == cluster_b):
                                        #autocorr being done so get theta modulation
                                        modIdx = self.spikecalcs.thetaModIdx(x1)
                                        ax.set_title(&#39;Cluster {0} vs Cluster {1}\ntheta modulation: {2:.4f}&#39;.format(cluster_a, cluster_b, modIdx))
                                        if &#34;add_peak_rate&#34; in kwargs:
                                                if kwargs[&#39;add_peak_rate&#39;]:
                                                        ax.annotate(&#39;{:.2f}&#39;.format(np.max(modIdx)), (0.15,0.9), \
                                                                        xycoords=&#39;axes fraction&#39;, textcoords=&#39;axes fraction&#39;, color=&#39;k&#39;, size=30, weight=&#39;bold&#39;, ha=&#39;center&#39;, va=&#39;center&#39;)

#                    ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b) +&#39;\ntheta modulation=&#39; + str(modIdx))
                        else:
                                ax.set_title(&#39;Cluster &#39; + str(cluster_a) + &#39; vs Cluster &#39; + str(cluster_b))
        ax.set_xlabel(&#39;Time(ms)&#39;)
        ax.set_xticks((Trange[0], 0, Trange[1]))
        ax.set_xticklabels((str(Trange[0]), &#39;0&#39;, str(Trange[1])))
        ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, left=&#39;off&#39;, right=&#39;off&#39;,
                                                bottom=&#39;off&#39;, top=&#39;off&#39;)
        ax.set_yticklabels(&#39;&#39;)
        ax.spines[&#39;right&#39;].set_visible(False)
        ax.spines[&#39;top&#39;].set_visible(False)
        ax.spines[&#39;left&#39;].set_visible(False)
        ax.xaxis.set_ticks_position(&#39;bottom&#39;)
        return ax, h</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.plot_event_EEG"><code class="name flex">
<span>def <span class="ident">plot_event_EEG</span></span>(<span>self, eeg_type='egf', dt=(-50, 100), plot=True, ax=None, evenOnsets=True, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Plots out the eeg record following an 'on' event in the log file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>eeg_type</code></strong> :&ensp;<code>str</code></dt>
<dd>either 'eeg' or 'egf'</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>tuple</code></dt>
<dd>time to look before and after an onset event</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether to plot the stimulus-triggered-eeg</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axis</code></dt>
<dd>will plot into this axis if supplied
(new figure produced if plot is None and ax is None)</dd>
<dt><strong><code>evenOnsets</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True assume there is supposed to be an even
difference between the events in the .stm file. If events are
found that have an uneven difference they are thrown out.
NB The difference is calculated from information gleaned from
the trial.STM field. If False this is ignored.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_event_EEG(self, eeg_type=&#39;egf&#39;, dt=(-50, 100), plot=True, ax=None, 
                                   evenOnsets=True, **kwargs):
        &#34;&#34;&#34;
        Plots out the eeg record following an &#39;on&#39; event in the log file

        Parameters
        ----------
        eeg_type : str
                either &#39;eeg&#39; or &#39;egf&#39;
        dt : tuple
                time to look before and after an onset event
        plot : bool
                whether to plot the stimulus-triggered-eeg
        ax : matplotlib.axis
                will plot into this axis if supplied
                (new figure produced if plot is None and ax is None)
        evenOnsets: bool
                if True assume there is supposed to be an even 
                difference between the events in the .stm file. If events are 
                found that have an uneven difference they are thrown out.
                NB The difference is calculated from information gleaned from 
                the trial.STM field. If False this is ignored.
        &#34;&#34;&#34;
        on_good = self.STM.getTS()#timestamps in ms
        &#34;&#34;&#34;
        Check for inter-stimulus time differences to make sure that the large
        majority (99%) of on pulses are regularly spaced - otherwise issue a warning
        &#34;&#34;&#34;
        df = np.diff(np.diff(on_good))
        if np.count_nonzero(df) / float(len(on_good)) * 100 &gt; 1:
                warnings.warn(&#39;More than 1% of on events differ in size&#39;, UserWarning)
        #check for abnormally large number of stim events and abort
        if len(on_good) &gt; 100000:
                raise Exception(&#39;Very large number of stimulation events. Aborting plot_event_EEG&#39;)
        #get the eeg data and indices to use
        if &#39;egf&#39; in eeg_type:
                eeg = self.EGF.eeg
                on_idx = self.STM.getEGFIdx()
                eeg_samps_per_ms = self.EGF.sample_rate / 1000.0
        elif &#39;eeg&#39; in eeg_type:
                eeg = self.EEG.eeg
                on_idx = self.STM.getEEGIdx()
                eeg_samps_per_ms = self.EEG.sample_rate / 1000.0

        &#34;&#34;&#34;
        NB the following conditional assumes there is only one phase of the 
        stimulation that actually contains stim events. If there is more than 
        one then the last one will be the one used
        &#34;&#34;&#34;
        df = np.diff(on_good)
        &#34;&#34;&#34;
        keep pulsePause here as used lower down to plot multiple Rectangle
        patches in case the dt tuple specifies a range of values higher than
        the pause between stimulation events
        &#34;&#34;&#34;
        pulsePause = 0
        if evenOnsets:
                for k, v in self.STM.iteritems():
                        if isinstance(v, OrderedDict):
                                for kk, vv in v.iteritems():
                                        for kkk, vvv in vv.iteritems():
                                                if &#39;Pause&#39; in kkk:
                                                        if vvv is not None:
                                                                pulsePause = vvv
                pulsePause_ms = pulsePause / 1000#this is the desired
                unequalPausesIdx = np.nonzero(df!=pulsePause_ms)[0]
                on_good = np.delete(on_good, unequalPausesIdx)
                on_idx = np.delete(on_idx, unequalPausesIdx)
        eeg = eeg - np.ma.mean(eeg)
        dt_eeg = eeg_samps_per_ms * np.array(dt)
        rng = np.arange(dt_eeg[0], dt_eeg[1], 1)
        idx = (on_idx[np.newaxis, :] + rng[:, np.newaxis]).astype(int)
        result = np.zeros((len(rng), len(on_good)))
        result = eeg[idx]
        if not plot:
                return result, idx
        else:
                mn = np.mean(result, 1)
                se = np.std(result, 1) / np.sqrt(len(on_good))
                if ax is None:
                        fig = plt.figure()
                        ax = fig.add_subplot(111)
                else:
                        ax = ax
                ax.errorbar(np.linspace(dt[0], dt[1], len(mn)), mn * 1e6,
                                        yerr=se*1e6, rasterized=False)
                ax.set_xlim(dt)
                axTrans = transforms.blended_transform_factory(ax.transData,
                                                                                                           ax.transAxes)
                stim_pwidth = int(self.setheader[&#39;stim_pwidth&#39;])
                if pulsePause &gt; 0:
                        a = np.arange(0, dt[1], pulsePause_ms)
                        b = np.arange(0, dt[0], -pulsePause_ms)
                        patchStarts = np.unique(np.concatenate((a, b)))
                for p in patchStarts:
                        ax.add_patch(Rectangle((p, 0), width=stim_pwidth/1000., height=1,
                                                 transform=axTrans,
                                                 color=[1, 1, 0], alpha=0.5))
                ax.set_ylabel(&#39;LFP ($\mu$V)&#39;)
                ax.set_xlabel(&#39;Time(ms)&#39;)
                return result</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.print_stim_dict"><code class="name flex">
<span>def <span class="ident">print_stim_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Prints out keys/ values of STM dict</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_stim_dict(self):
        &#39;&#39;&#39;
        Prints out keys/ values of STM dict
        &#39;&#39;&#39;
        for k,v in self.STM.iteritems():
                print(k, v)</code></pre>
</details>
</dd>
<dt id="ephysiopy.dacq2py.dacq2py_util.Trial.tortuosity"><code class="name flex">
<span>def <span class="ident">tortuosity</span></span>(<span>self, xy=None)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<p>xy - numpy.array
2xm matrix of xy positions. Default is None so will use this
instances xy array in POS</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tortuosity</code></strong> :&ensp;<code>float</code></dt>
<dd>tortuosity index calculated as follows:
T = sum(path_segment / segment_straight_line) / n_segments
n_segments is the number of one second segments per trial</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tortuosity(self, xy=None):
        &#39;&#39;&#39;
        Parameters
        -----------
        xy - numpy.array
                2xm matrix of xy positions. Default is None so will use this
                instances xy array in POS

        Returns
        --------
        tortuosity : float
                tortuosity index calculated as follows:
                T = sum(path_segment / segment_straight_line) / n_segments
                n_segments is the number of one second segments per trial
        &#39;&#39;&#39;

        if xy is None:
                xy = self._getPath()
        T = np.zeros(int(np.shape(xy)[1]/50))
        idx = 0
        for i in xrange(0, xy.shape[1]-50, 50):
                straight_line = np.hypot(xy[0,i] - xy[0,i+50], xy[1,i] - xy[1,i+50])
                path_segment = np.nansum(np.hypot(np.diff(xy[0,i:i+50]),np.diff(xy[1,i:i+50])))
                T[idx] = path_segment / straight_line
                idx += 1
        toobigbool = T &gt; 100
        T = np.delete(T, toobigbool.nonzero())
        zerobool = T==0
        T = np.delete(T, zerobool.nonzero())
        T = np.delete(T, np.isinf(T).nonzero())
        T = np.delete(T, np.isnan(T).nonzero())
        return np.sum(T) / len(T)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ephysiopy.dacq2py.axonaIO.IO" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO">IO</a></b></code>:
<ul class="hlist">
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.getCluCut" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.getCluCut">getCluCut</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.getCut" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.getCut">getCut</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.getData" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.getData">getData</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.getHeader" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.getHeader">getHeader</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.getHeaderVal" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.getHeaderVal">getHeaderVal</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.setData" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.setData">setData</a></code></li>
<li><code><a title="ephysiopy.dacq2py.axonaIO.IO.setHeader" href="axonaIO.html#ephysiopy.dacq2py.axonaIO.IO.setHeader">setHeader</a></code></li>
</ul>
</li>
<li><code><b><a title="ephysiopy.dacq2py.gridcell.SAC" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC">SAC</a></b></code>:
<ul class="hlist">
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.autoCorr2D" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC.autoCorr2D">autoCorr2D</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getMeasures" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC.getMeasures">getMeasures</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.getextrema" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC.getextrema">getextrema</a></code></li>
<li><code><a title="ephysiopy.dacq2py.gridcell.SAC.t_win_SAC" href="gridcell.html#ephysiopy.dacq2py.gridcell.SAC.t_win_SAC">t_win_SAC</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ephysiopy.dacq2py" href="index.html">ephysiopy.dacq2py</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial" href="#ephysiopy.dacq2py.dacq2py_util.Trial">Trial</a></code></h4>
<ul class="">
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.EEG" href="#ephysiopy.dacq2py.dacq2py_util.Trial.EEG">EEG</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.EGF" href="#ephysiopy.dacq2py.dacq2py_util.Trial.EGF">EGF</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.POS" href="#ephysiopy.dacq2py.dacq2py_util.Trial.POS">POS</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.STM" href="#ephysiopy.dacq2py.dacq2py_util.Trial.STM">STM</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.adjust_median_speed" href="#ephysiopy.dacq2py.dacq2py_util.Trial.adjust_median_speed">adjust_median_speed</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getBorderScore" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getBorderScore">getBorderScore</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getFieldRuns" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getFieldRuns">getFieldRuns</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getFullFile" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getFullFile">getFullFile</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getRasterHist" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getRasterHist">getRasterHist</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx">getThetaModIdx</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx2" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getThetaModIdx2">getThetaModIdx2</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getThigmotaxisIndex" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getThigmotaxisIndex">getThigmotaxisIndex</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getTsAndCs" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getTsAndCs">getTsAndCs</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getcircR" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getcircR">getcircR</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getcoherence" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getcoherence">getcoherence</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getkldiv" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getkldiv">getkldiv</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getmrv" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getmrv">getmrv</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.getskaggsInfo" href="#ephysiopy.dacq2py.dacq2py_util.Trial.getskaggsInfo">getskaggsInfo</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.hasFiles" href="#ephysiopy.dacq2py.dacq2py_util.Trial.hasFiles">hasFiles</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.klustakwik" href="#ephysiopy.dacq2py.dacq2py_util.Trial.klustakwik">klustakwik</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotClusterSpace" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotClusterSpace">plotClusterSpace</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotDirFilteredRmaps" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotDirFilteredRmaps">plotDirFilteredRmaps</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotEEGPower" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotEEGPower">plotEEGPower</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotEventEEGRange" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotEventEEGRange">plotEventEEGRange</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotFreqVSpeed" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotFreqVSpeed">plotFreqVSpeed</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotFullSAC" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotFullSAC">plotFullSAC</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotMap" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotMap">plotMap</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotPath" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotPath">plotPath</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseInField" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseInField">plotPhaseInField</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseOfFiring" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotPhaseOfFiring">plotPhaseOfFiring</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotRaster" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotRaster">plotRaster</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotRateVSpeed" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotRateVSpeed">plotRateVSpeed</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotRollingCorrRateVSpeed" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotRollingCorrRateVSpeed">plotRollingCorrRateVSpeed</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotSAC" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotSAC">plotSAC</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotSpectrogram" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotSpectrogram">plotSpectrogram</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotSpikesOnPath" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotSpikesOnPath">plotSpikesOnPath</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotWaveforms" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotWaveforms">plotWaveforms</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plotXCorr" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plotXCorr">plotXCorr</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.plot_event_EEG" href="#ephysiopy.dacq2py.dacq2py_util.Trial.plot_event_EEG">plot_event_EEG</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.posFilter" href="#ephysiopy.dacq2py.dacq2py_util.Trial.posFilter">posFilter</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.ppm" href="#ephysiopy.dacq2py.dacq2py_util.Trial.ppm">ppm</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.print_stim_dict" href="#ephysiopy.dacq2py.dacq2py_util.Trial.print_stim_dict">print_stim_dict</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.setheader" href="#ephysiopy.dacq2py.dacq2py_util.Trial.setheader">setheader</a></code></li>
<li><code><a title="ephysiopy.dacq2py.dacq2py_util.Trial.tortuosity" href="#ephysiopy.dacq2py.dacq2py_util.Trial.tortuosity">tortuosity</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>